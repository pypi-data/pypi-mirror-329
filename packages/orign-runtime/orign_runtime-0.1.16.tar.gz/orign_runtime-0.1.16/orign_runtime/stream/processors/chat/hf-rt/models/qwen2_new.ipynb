{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special tokens map: {'eos_token': '<|im_end|>', 'pad_token': '<|im_end|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}\n",
      "All special tokens: ['<|im_end|>', '<|im_start|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']\n",
      "All special token IDs: [151645, 151644, 151646, 151647, 151648, 151649, 151650, 151651, 151652, 151653, 151654, 151655, 151656]\n",
      "Added sequence 0 to active sequences\n",
      "Added sequence 1 to active sequences\n",
      "Added sequence 2 to active sequences\n",
      "Added sequence 3 to active sequences\n",
      "Calling model for initial sequences...\n",
      "Model call completed.\n",
      "Sequence 0 generated token id 9286\n",
      "Sequence 1 generated token id 198\n",
      "Sequence 2 generated token id 198\n",
      "Sequence 3 generated token id 31772\n",
      "Processing sequences with past_key_values seq_len = 28\n",
      "Model call completed.\n",
      "Sequence 0 generated token id 16488\n",
      "Sequence 1 generated token id 785\n",
      "Sequence 2 generated token id 785\n",
      "Sequence 3 generated token id 73667\n",
      "Processing sequences with past_key_values seq_len = 29\n",
      "Model call completed.\n",
      "Sequence 0 generated token id 11229\n",
      "Sequence 1 generated token id 6722\n",
      "Sequence 2 generated token id 10126\n",
      "Sequence 3 generated token id 374\n",
      "Processing sequences with past_key_values seq_len = 30\n",
      "Model call completed.\n",
      "Sequence 0 generated token id 320\n",
      "Sequence 1 generated token id 3283\n",
      "Sequence 2 generated token id 315\n",
      "Sequence 3 generated token id 279\n",
      "Processing sequences with past_key_values seq_len = 31\n",
      "Model call completed.\n",
      "Sequence 0 generated token id 15469\n",
      "Sequence 1 generated token id 315\n",
      "Sequence 2 generated token id 1351\n",
      "Sequence 3 generated token id 1882\n",
      "Processing sequences with past_key_values seq_len = 32\n",
      "Model call completed.\n",
      "Sequence 0 generated token id 8\n",
      "Sequence 1 generated token id 9625\n",
      "Sequence 2 generated token id 43415\n",
      "Sequence 3 generated token id 553\n",
      "Processing sequences with past_key_values seq_len = 33\n",
      "Model call completed.\n",
      "Sequence 0 generated token id 374\n",
      "Sequence 1 generated token id 374\n",
      "Sequence 2 generated token id 374\n",
      "Sequence 3 generated token id 892\n",
      "Processing sequences with past_key_values seq_len = 34\n",
      "Model call completed.\n",
      "Sequence 0 generated token id 264\n",
      "Sequence 1 generated token id 12095\n",
      "Sequence 2 generated token id 264\n",
      "Sequence 3 generated token id 10779\n",
      "Processing sequences with past_key_values seq_len = 35\n",
      "Model call completed.\n",
      "Sequence 0 generated token id 2070\n",
      "Sequence 1 generated token id 13\n",
      "Sequence 2 generated token id 12344\n",
      "Sequence 3 generated token id 11\n",
      "Processing sequences with past_key_values seq_len = 36\n",
      "Model call completed.\n",
      "Sequence 0 generated token id 315\n",
      "Sequence 1 finished generating.\n",
      "Sequence 2 generated token id 10126\n",
      "Sequence 3 generated token id 67851\n",
      "Formatted input in working script:\n",
      "<|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "What is the tallest mountain in the world?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "\n",
      "Added sequence 4 to active sequences\n",
      "Calling model for initial sequences...\n",
      "Model call completed.\n",
      "Sequence 4 generated token id 785\n",
      "Processing sequences with past_key_values seq_len = 37\n",
      "Model call completed.\n",
      "Sequence 0 generated token id 6366\n",
      "Sequence 2 generated token id 429\n",
      "Sequence 3 generated token id 11\n",
      "Processing sequences with past_key_values seq_len = 38\n",
      "Model call completed.\n",
      "Sequence 0 generated token id 8038\n",
      "Sequence 2 generated token id 16555\n",
      "Sequence 3 generated token id 323\n",
      "Processing sequences with past_key_values seq_len = 28\n",
      "Model call completed.\n",
      "Sequence 4 generated token id 81617\n",
      "Processing sequences with past_key_values seq_len = 39\n",
      "Model call completed.\n",
      "Sequence 0 generated token id 429\n",
      "Sequence 2 generated token id 279\n",
      "Sequence 3 generated token id 1045\n",
      "Processing sequences with past_key_values seq_len = 29\n",
      "Model call completed.\n",
      "Sequence 4 generated token id 16301\n",
      "Processing sequences with past_key_values seq_len = 40\n",
      "Model call completed.\n",
      "Sequence 0 generated token id 21538\n",
      "Sequence 2 generated token id 5025\n",
      "Sequence 3 generated token id 23157\n",
      "Processing sequences with past_key_values seq_len = 30\n",
      "Model call completed.\n",
      "Sequence 4 generated token id 304\n",
      "Processing sequences with past_key_values seq_len = 41\n",
      "Model call completed.\n",
      "Sequence 0 generated token id 311\n",
      "Sequence 2 generated token id 1948\n",
      "Sequence 3 generated token id 5508\n",
      "Processing sequences with past_key_values seq_len = 31\n",
      "Model call completed.\n",
      "Sequence 4 generated token id 279\n",
      "Processing sequences with past_key_values seq_len = 42\n",
      "Model call completed.\n",
      "Sequence 0 generated token id 1855\n",
      "Sequence 2 generated token id 3550\n",
      "Sequence 3 generated token id 3100\n",
      "Processing sequences with past_key_values seq_len = 32\n",
      "Model call completed.\n",
      "Sequence 4 generated token id 1879\n",
      "Processing sequences with past_key_values seq_len = 43\n",
      "Model call completed.\n",
      "Sequence 0 generated token id 24514\n",
      "Sequence 2 generated token id 11\n",
      "Sequence 3 generated token id 4802\n",
      "Processing sequences with past_key_values seq_len = 33\n",
      "Model call completed.\n",
      "Sequence 4 generated token id 374\n",
      "Processing sequences with past_key_values seq_len = 44\n",
      "Model call completed.\n",
      "Sequence 0 generated token id 12645\n",
      "Sequence 2 generated token id 882\n",
      "Sequence 3 generated token id 1119\n",
      "Processing sequences with past_key_values seq_len = 34\n",
      "Model call completed.\n",
      "Sequence 4 generated token id 10423\n",
      "Processing sequences with past_key_values seq_len = 45\n",
      "Model call completed.\n",
      "Sequence 0 generated token id 429\n",
      "Sequence 2 generated token id 11\n",
      "Sequence 3 generated token id 11483\n",
      "Processing sequences with past_key_values seq_len = 35\n",
      "Model call completed.\n",
      "Sequence 4 generated token id 86478\n",
      "Processing sequences with past_key_values seq_len = 46\n",
      "Model call completed.\n",
      "Sequence 0 generated token id 646\n",
      "Sequence 2 generated token id 323\n",
      "Sequence 3 generated token id 4802\n",
      "Processing sequences with past_key_values seq_len = 36\n",
      "Model call completed.\n",
      "Sequence 4 generated token id 11\n",
      "Processing sequences with past_key_values seq_len = 47\n",
      "Model call completed.\n",
      "Sequence 0 generated token id 2736\n",
      "Sequence 2 generated token id 23249\n",
      "Sequence 3 generated token id 9768\n",
      "Processing sequences with past_key_values seq_len = 37\n",
      "Model call completed.\n",
      "Sequence 4 generated token id 892\n",
      "Processing sequences with past_key_values seq_len = 48\n",
      "Model call completed.\n",
      "Sequence 0 generated token id 9079\n",
      "Sequence 2 generated token id 13\n",
      "Sequence 3 generated token id 304\n",
      "Processing sequences with past_key_values seq_len = 38\n",
      "Model call completed.\n",
      "Sequence 4 generated token id 13352\n",
      "Processing sequences with past_key_values seq_len = 49\n",
      "Model call completed.\n",
      "Sequence 0 generated token id 429\n",
      "Sequence 2 generated token id 1084\n",
      "Sequence 3 generated token id 33223\n",
      "Processing sequences with past_key_values seq_len = 39\n",
      "Model call completed.\n",
      "Sequence 4 generated token id 518\n",
      "Processing sequences with past_key_values seq_len = 50\n",
      "Model call completed.\n",
      "Sequence 0 generated token id 11136\n",
      "Sequence 2 generated token id 572\n",
      "Sequence 3 generated token id 13\n",
      "Processing sequences with past_key_values seq_len = 40\n",
      "Model call completed.\n",
      "Sequence 4 generated token id 458\n",
      "Processing sequences with past_key_values seq_len = 51\n",
      "Model call completed.\n",
      "Sequence 0 generated token id 1373\n",
      "Sequence 2 generated token id 7881\n",
      "Sequence 3 generated token id 576\n",
      "Processing sequences with past_key_values seq_len = 41\n",
      "Model call completed.\n",
      "Sequence 4 generated token id 26163\n",
      "Processing sequences with past_key_values seq_len = 52\n",
      "Model call completed.\n",
      "Sequence 0 generated token id 3738\n",
      "Sequence 2 generated token id 553\n",
      "Sequence 3 generated token id 1882\n",
      "Processing sequences with past_key_values seq_len = 42\n",
      "Model call completed.\n",
      "Sequence 4 generated token id 315\n",
      "Processing sequences with past_key_values seq_len = 53\n",
      "Model call completed.\n",
      "Sequence 0 generated token id 11229\n",
      "Sequence 2 generated token id 17513\n",
      "Sequence 3 generated token id 4990\n",
      "Processing sequences with past_key_values seq_len = 43\n",
      "Model call completed.\n",
      "Sequence 4 generated token id 220\n",
      "Processing sequences with past_key_values seq_len = 54\n",
      "Model call completed.\n",
      "Sequence 0 generated token id 11\n",
      "Sequence 2 generated token id 54052\n",
      "Sequence 3 generated token id 1992\n",
      "Processing sequences with past_key_values seq_len = 44\n",
      "Model call completed.\n",
      "Sequence 4 generated token id 23\n",
      "Processing sequences with past_key_values seq_len = 55\n",
      "Model call completed.\n",
      "Sequence 0 generated token id 1741\n",
      "Sequence 2 generated token id 304\n",
      "Sequence 3 generated token id 304\n",
      "Processing sequences with past_key_values seq_len = 45\n",
      "Model call completed.\n",
      "Sequence 4 generated token id 11\n",
      "Processing sequences with past_key_values seq_len = 56\n",
      "Model call completed.\n",
      "Sequence 0 generated token id 438\n",
      "Sequence 2 generated token id 279\n",
      "Sequence 3 generated token id 279\n",
      "Processing sequences with past_key_values seq_len = 46\n",
      "Model call completed.\n",
      "Sequence 4 generated token id 23\n",
      "Processing sequences with past_key_values seq_len = 57\n",
      "Model call completed.\n",
      "Sequence 0 generated token id 9124\n",
      "Sequence 2 generated token id 4124\n",
      "Sequence 3 generated token id 36733\n",
      "Processing sequences with past_key_values seq_len = 47\n",
      "Model call completed.\n",
      "Sequence 4 generated token id 19\n",
      "Processing sequences with past_key_values seq_len = 58\n",
      "Model call completed.\n",
      "Sequence 0 generated token id 20431\n",
      "Sequence 2 generated token id 220\n",
      "Sequence 3 generated token id 91235\n",
      "Processing sequences with past_key_values seq_len = 48\n",
      "Model call completed.\n",
      "Sequence 4 generated token id 23\n",
      "Processing sequences with past_key_values seq_len = 59\n",
      "Model call completed.\n",
      "Sequence 0 generated token id 11\n",
      "Sequence 2 generated token id 17\n",
      "Sequence 3 generated token id 82\n",
      "Processing sequences with past_key_values seq_len = 49\n",
      "Model call completed.\n",
      "Sequence 4 generated token id 20044\n",
      "Processing sequences with past_key_values seq_len = 60\n",
      "Model call completed.\n",
      "Sequence 0 generated token id 8806\n",
      "Sequence 2 generated token id 15\n",
      "Sequence 3 generated token id 315\n",
      "Processing sequences with past_key_values seq_len = 50\n",
      "Model call completed.\n",
      "Sequence 4 generated token id 320\n",
      "Processing sequences with past_key_values seq_len = 61\n",
      "Model call completed.\n",
      "Sequence 0 generated token id 17843\n",
      "Sequence 2 generated token id 339\n",
      "Sequence 3 generated token id 6008\n",
      "Processing sequences with past_key_values seq_len = 51\n",
      "Model call completed.\n",
      "Sequence 4 generated token id 17\n",
      "Processing sequences with past_key_values seq_len = 62\n",
      "Model call completed.\n",
      "Sequence 0 generated token id 11\n",
      "Sequence 2 generated token id 9294\n",
      "Sequence 3 generated token id 7761\n",
      "Processing sequences with past_key_values seq_len = 52\n",
      "Model call completed.\n",
      "Sequence 4 generated token id 24\n",
      "Processing sequences with past_key_values seq_len = 63\n",
      "Model call completed.\n",
      "Sequence 0 generated token id 5480\n",
      "Sequence 2 generated token id 323\n",
      "Sequence 3 generated token id 11\n",
      "Processing sequences with past_key_values seq_len = 53\n",
      "Model call completed.\n",
      "Sequence 4 generated token id 11\n",
      "Processing sequences with past_key_values seq_len = 64\n",
      "Model call completed.\n",
      "Sequence 0 generated token id 27746\n",
      "Sequence 2 generated token id 702\n",
      "Sequence 3 generated token id 892\n",
      "Processing sequences with past_key_values seq_len = 54\n",
      "Model call completed.\n",
      "Sequence 4 generated token id 15\n",
      "Processing sequences with past_key_values seq_len = 65\n",
      "Model call completed.\n",
      "Sequence 0 generated token id 11\n",
      "Sequence 2 generated token id 2474\n",
      "Sequence 3 generated token id 6644\n",
      "Processing sequences with past_key_values seq_len = 55\n",
      "Model call completed.\n",
      "Sequence 4 generated token id 17\n",
      "Processing sequences with past_key_values seq_len = 66\n",
      "Model call completed.\n",
      "Sequence 0 generated token id 323\n",
      "Sequence 2 generated token id 3635\n",
      "Sequence 3 generated token id 36733\n",
      "Processing sequences with past_key_values seq_len = 56\n",
      "Model call completed.\n",
      "Sequence 4 generated token id 24\n",
      "Processing sequences with past_key_values seq_len = 67\n",
      "Model call completed.\n",
      "Sequence 0 generated token id 4128\n",
      "Sequence 2 generated token id 825\n",
      "Sequence 3 generated token id 5127\n",
      "Processing sequences with past_key_values seq_len = 57\n",
      "Model call completed.\n",
      "Sequence 4 generated token id 7541\n",
      "Processing sequences with past_key_values seq_len = 68\n",
      "Model call completed.\n",
      "Sequence 0 generated token id 14468\n",
      "Sequence 2 generated token id 315\n",
      "Sequence 3 generated token id 24705\n",
      "Processing sequences with past_key_values seq_len = 58\n",
      "Model call completed.\n",
      "Sequence 4 generated token id 8\n",
      "Processing sequences with past_key_values seq_len = 69\n",
      "Model call completed.\n",
      "Sequence 0 generated token id 13\n",
      "Sequence 2 generated token id 279\n",
      "Sequence 3 generated token id 11\n",
      "Processing sequences with past_key_values seq_len = 59\n",
      "Model call completed.\n",
      "Sequence 4 generated token id 3403\n",
      "Processing sequences with past_key_values seq_len = 70\n",
      "Model call completed.\n",
      "Sequence 0 generated token id 576\n",
      "Sequence 2 generated token id 1429\n",
      "Sequence 3 generated token id 264\n",
      "Processing sequences with past_key_values seq_len = 60\n",
      "Model call completed.\n",
      "Sequence 4 generated token id 9396\n",
      "Processing sequences with past_key_values seq_len = 71\n",
      "Model call completed.\n",
      "Sequence 0 generated token id 3840\n",
      "Sequence 2 generated token id 2989\n",
      "Sequence 3 generated token id 6176\n",
      "Processing sequences with past_key_values seq_len = 61\n",
      "Model call completed.\n",
      "Sequence 4 generated token id 2188\n",
      "Processing sequences with past_key_values seq_len = 72\n",
      "Model call completed.\n",
      "Sequence 0 generated token id 315\n",
      "Sequence 2 generated token id 323\n",
      "Sequence 3 generated token id 76578\n",
      "Processing sequences with past_key_values seq_len = 62\n",
      "Model call completed.\n",
      "Sequence 4 generated token id 13\n",
      "Processing sequences with past_key_values seq_len = 73\n",
      "Model call completed.\n",
      "Sequence 0 generated token id 15235\n",
      "Sequence 2 generated token id 31449\n",
      "Sequence 3 generated token id 429\n",
      "Processing sequences with past_key_values seq_len = 63\n",
      "Model call completed.\n",
      "Sequence 4 generated token id 1084\n",
      "Processing sequences with past_key_values seq_len = 74\n",
      "Model call completed.\n",
      "Sequence 0 generated token id 374\n",
      "Sequence 2 generated token id 24970\n",
      "Sequence 3 generated token id 90011\n",
      "Processing sequences with past_key_values seq_len = 64\n",
      "Model call completed.\n",
      "Sequence 4 generated token id 374\n",
      "Processing sequences with past_key_values seq_len = 75\n",
      "Model call completed.\n",
      "Sequence 0 generated token id 264\n",
      "Sequence 2 generated token id 304\n",
      "Sequence 3 generated token id 3100\n",
      "Processing sequences with past_key_values seq_len = 65\n",
      "Model call completed.\n",
      "Sequence 4 generated token id 7407\n",
      "Processing sequences with past_key_values seq_len = 76\n",
      "Model call completed.\n",
      "Sequence 0 finished generating.\n",
      "Sequence 2 finished generating.\n",
      "Sequence 3 finished generating.\n",
      "Processing sequences with past_key_values seq_len = 66\n",
      "Model call completed.\n",
      "Sequence 4 generated token id 304\n",
      "Formatted input in working script:\n",
      "<|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "Who wrote 'To Kill a Mockingbird'?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "\n",
      "Added sequence 5 to active sequences\n",
      "Formatted input in working script:\n",
      "<|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "What is the speed of light?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "\n",
      "Added sequence 6 to active sequences\n",
      "Formatted input in working script:\n",
      "<|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "Describe the process of evolution.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "\n",
      "Added sequence 7 to active sequences\n",
      "Calling model for initial sequences...\n",
      "Model call completed.\n",
      "Sequence 5 generated token id 65120\n",
      "Sequence 6 generated token id 198\n",
      "Sequence 7 generated token id 198\n",
      "Processing sequences with past_key_values seq_len = 67\n",
      "Model call completed.\n",
      "Sequence 4 generated token id 279\n",
      "Processing sequences with past_key_values seq_len = 68\n",
      "Model call completed.\n",
      "Sequence 4 generated token id 16171\n",
      "Processing sequences with past_key_values seq_len = 29\n",
      "Model call completed.\n",
      "Sequence 5 generated token id 26835\n",
      "Sequence 6 generated token id 785\n",
      "Sequence 7 generated token id 785\n",
      "Processing sequences with past_key_values seq_len = 69\n",
      "Model call completed.\n",
      "Sequence 4 generated token id 278\n",
      "Processing sequences with past_key_values seq_len = 30\n",
      "Model call completed.\n",
      "Sequence 5 generated token id 264\n",
      "Sequence 6 generated token id 4628\n",
      "Sequence 7 generated token id 1882\n",
      "Processing sequences with past_key_values seq_len = 70\n",
      "Model call completed.\n",
      "Sequence 4 generated token id 524\n",
      "Processing sequences with past_key_values seq_len = 31\n",
      "Model call completed.\n",
      "Sequence 5 generated token id 14563\n",
      "Sequence 6 generated token id 315\n",
      "Sequence 7 generated token id 315\n",
      "Processing sequences with past_key_values seq_len = 71\n",
      "Model call completed.\n",
      "Sequence 4 generated token id 324\n",
      "Processing sequences with past_key_values seq_len = 32\n",
      "Model call completed.\n",
      "Sequence 5 generated token id 287\n",
      "Sequence 6 generated token id 3100\n",
      "Sequence 7 generated token id 15379\n",
      "Processing sequences with past_key_values seq_len = 72\n",
      "Model call completed.\n",
      "Sequence 4 generated token id 75338\n",
      "Processing sequences with past_key_values seq_len = 33\n",
      "Model call completed.\n",
      "Sequence 5 generated token id 22592\n",
      "Sequence 6 generated token id 304\n",
      "Sequence 7 generated token id 374\n",
      "Processing sequences with past_key_values seq_len = 73\n",
      "Model call completed.\n",
      "Sequence 4 generated token id 1186\n",
      "Processing sequences with past_key_values seq_len = 34\n",
      "Model call completed.\n",
      "Sequence 5 generated token id 1\n",
      "Sequence 6 generated token id 264\n",
      "Sequence 7 generated token id 279\n",
      "Processing sequences with past_key_values seq_len = 74\n",
      "Model call completed.\n",
      "Sequence 4 generated token id 30508\n",
      "Processing sequences with past_key_values seq_len = 35\n",
      "Model call completed.\n",
      "Sequence 5 generated token id 572\n",
      "Sequence 6 generated token id 28202\n",
      "Sequence 7 generated token id 52622\n",
      "Processing sequences with past_key_values seq_len = 75\n",
      "Model call completed.\n",
      "Sequence 4 generated token id 315\n",
      "Processing sequences with past_key_values seq_len = 36\n",
      "Model call completed.\n",
      "Sequence 5 generated token id 5326\n",
      "Sequence 6 generated token id 374\n",
      "Sequence 7 generated token id 2297\n",
      "Processing sequences with past_key_values seq_len = 76\n",
      "Model call completed.\n",
      "Sequence 4 finished generating.\n",
      "Processing sequences with past_key_values seq_len = 37\n",
      "Model call completed.\n",
      "Sequence 5 generated token id 553\n",
      "Sequence 6 generated token id 13187\n",
      "Sequence 7 generated token id 304\n",
      "Formatted input in working script:\n",
      "<|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "What is quantum computing?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "\n",
      "Added sequence 8 to active sequences\n",
      "Calling model for initial sequences...\n",
      "Model call completed.\n",
      "Sequence 8 generated token id 44220\n",
      "Processing sequences with past_key_values seq_len = 38\n",
      "Model call completed.\n",
      "Sequence 5 generated token id 32007\n",
      "Sequence 6 generated token id 220\n",
      "Sequence 7 generated token id 279\n",
      "Processing sequences with past_key_values seq_len = 39\n",
      "Model call completed.\n",
      "Sequence 5 generated token id 12066\n",
      "Sequence 6 generated token id 17\n",
      "Sequence 7 generated token id 18929\n",
      "Processing sequences with past_key_values seq_len = 24\n",
      "Model call completed.\n",
      "Sequence 8 generated token id 372\n",
      "Processing sequences with past_key_values seq_len = 40\n",
      "Model call completed.\n",
      "Sequence 5 generated token id 13\n",
      "Sequence 6 generated token id 24\n",
      "Sequence 7 generated token id 26551\n",
      "Processing sequences with past_key_values seq_len = 25\n",
      "Model call completed.\n",
      "Sequence 8 generated token id 24231\n",
      "Processing sequences with past_key_values seq_len = 41\n",
      "Model call completed.\n",
      "Sequence 5 finished generating.\n",
      "Sequence 6 generated token id 24\n",
      "Sequence 7 generated token id 315\n",
      "Processing sequences with past_key_values seq_len = 26\n",
      "Model call completed.\n",
      "Sequence 8 generated token id 374\n",
      "Formatted input in working script:\n",
      "<|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "Who was Albert Einstein?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "\n",
      "Added sequence 9 to active sequences\n",
      "Calling model for initial sequences...\n",
      "Model call completed.\n",
      "Sequence 9 generated token id 66622\n",
      "Processing sequences with past_key_values seq_len = 42\n",
      "Model call completed.\n",
      "Sequence 6 generated token id 11\n",
      "Sequence 7 generated token id 264\n",
      "Processing sequences with past_key_values seq_len = 27\n",
      "Model call completed.\n",
      "Sequence 8 generated token id 264\n",
      "Processing sequences with past_key_values seq_len = 43\n",
      "Model call completed.\n",
      "Sequence 6 generated token id 22\n",
      "Sequence 7 generated token id 7042\n",
      "Processing sequences with past_key_values seq_len = 28\n",
      "Model call completed.\n",
      "Sequence 8 generated token id 943\n",
      "Processing sequences with past_key_values seq_len = 24\n",
      "Model call completed.\n",
      "Sequence 9 generated token id 54052\n",
      "Processing sequences with past_key_values seq_len = 44\n",
      "Model call completed.\n",
      "Sequence 6 generated token id 24\n",
      "Sequence 7 generated token id 916\n",
      "Processing sequences with past_key_values seq_len = 29\n",
      "Model call completed.\n",
      "Sequence 8 generated token id 315\n",
      "Processing sequences with past_key_values seq_len = 25\n",
      "Model call completed.\n",
      "Sequence 9 generated token id 572\n",
      "Processing sequences with past_key_values seq_len = 45\n",
      "Model call completed.\n",
      "Sequence 6 generated token id 17\n",
      "Sequence 7 generated token id 882\n",
      "Processing sequences with past_key_values seq_len = 30\n",
      "Model call completed.\n",
      "Sequence 8 generated token id 24231\n",
      "Processing sequences with past_key_values seq_len = 26\n",
      "Model call completed.\n",
      "Sequence 9 generated token id 264\n",
      "Processing sequences with past_key_values seq_len = 46\n",
      "Model call completed.\n",
      "Sequence 6 generated token id 11\n",
      "Sequence 7 generated token id 13\n",
      "Processing sequences with past_key_values seq_len = 31\n",
      "Model call completed.\n",
      "Sequence 8 generated token id 429\n",
      "Processing sequences with past_key_values seq_len = 27\n",
      "Model call completed.\n",
      "Sequence 9 generated token id 5938\n",
      "Processing sequences with past_key_values seq_len = 47\n",
      "Model call completed.\n",
      "Sequence 6 generated token id 19\n",
      "Sequence 7 generated token id 1096\n",
      "Processing sequences with past_key_values seq_len = 32\n",
      "Model call completed.\n",
      "Sequence 8 generated token id 5711\n",
      "Processing sequences with past_key_values seq_len = 28\n",
      "Model call completed.\n",
      "Sequence 9 generated token id 39160\n",
      "Processing sequences with past_key_values seq_len = 48\n",
      "Model call completed.\n",
      "Sequence 6 generated token id 20\n",
      "Sequence 7 generated token id 2297\n",
      "Processing sequences with past_key_values seq_len = 33\n",
      "Model call completed.\n",
      "Sequence 8 generated token id 30128\n",
      "Processing sequences with past_key_values seq_len = 29\n",
      "Model call completed.\n",
      "Sequence 9 generated token id 31787\n",
      "Processing sequences with past_key_values seq_len = 49\n",
      "Model call completed.\n",
      "Sequence 6 generated token id 23\n",
      "Sequence 7 generated token id 13666\n",
      "Processing sequences with past_key_values seq_len = 34\n",
      "Model call completed.\n",
      "Sequence 8 generated token id 1448\n",
      "Processing sequences with past_key_values seq_len = 30\n",
      "Model call completed.\n",
      "Sequence 9 generated token id 82223\n",
      "Processing sequences with past_key_values seq_len = 50\n",
      "Model call completed.\n",
      "Sequence 6 generated token id 20044\n",
      "Sequence 7 generated token id 1526\n",
      "Processing sequences with past_key_values seq_len = 35\n",
      "Model call completed.\n",
      "Sequence 8 generated token id 4737\n",
      "Processing sequences with past_key_values seq_len = 31\n",
      "Model call completed.\n",
      "Sequence 9 generated token id 879\n",
      "Processing sequences with past_key_values seq_len = 51\n",
      "Model call completed.\n",
      "Sequence 6 generated token id 817\n",
      "Sequence 7 generated token id 264\n",
      "Processing sequences with past_key_values seq_len = 36\n",
      "Model call completed.\n",
      "Sequence 8 generated token id 44883\n",
      "Processing sequences with past_key_values seq_len = 32\n",
      "Model call completed.\n",
      "Sequence 9 generated token id 374\n",
      "Processing sequences with past_key_values seq_len = 52\n",
      "Model call completed.\n",
      "Sequence 6 generated token id 2086\n",
      "Sequence 7 generated token id 4013\n",
      "Processing sequences with past_key_values seq_len = 37\n",
      "Model call completed.\n",
      "Sequence 8 generated token id 43147\n",
      "Processing sequences with past_key_values seq_len = 33\n",
      "Model call completed.\n",
      "Sequence 9 generated token id 13570\n",
      "Processing sequences with past_key_values seq_len = 53\n",
      "Model call completed.\n",
      "Sequence 6 generated token id 320\n",
      "Sequence 7 generated token id 315\n",
      "Processing sequences with past_key_values seq_len = 38\n",
      "Model call completed.\n",
      "Sequence 8 generated token id 11\n",
      "Processing sequences with past_key_values seq_len = 34\n",
      "Model call completed.\n",
      "Sequence 9 generated token id 26361\n",
      "Processing sequences with past_key_values seq_len = 54\n",
      "Model call completed.\n",
      "Sequence 6 generated token id 76\n",
      "Sequence 7 generated token id 7354\n",
      "Processing sequences with past_key_values seq_len = 39\n",
      "Model call completed.\n",
      "Sequence 8 generated token id 1741\n",
      "Processing sequences with past_key_values seq_len = 35\n",
      "Model call completed.\n",
      "Sequence 9 generated token id 438\n",
      "Processing sequences with past_key_values seq_len = 55\n",
      "Model call completed.\n",
      "Sequence 6 generated token id 2687\n",
      "Sequence 7 generated token id 11\n",
      "Processing sequences with past_key_values seq_len = 40\n",
      "Model call completed.\n",
      "Sequence 8 generated token id 438\n",
      "Processing sequences with past_key_values seq_len = 36\n",
      "Model call completed.\n",
      "Sequence 9 generated token id 825\n",
      "Processing sequences with past_key_values seq_len = 56\n",
      "Model call completed.\n",
      "Sequence 6 generated token id 568\n",
      "Sequence 7 generated token id 2670\n",
      "Processing sequences with past_key_values seq_len = 41\n",
      "Model call completed.\n",
      "Sequence 8 generated token id 2256\n",
      "Processing sequences with past_key_values seq_len = 37\n",
      "Model call completed.\n",
      "Sequence 9 generated token id 315\n",
      "Processing sequences with past_key_values seq_len = 57\n",
      "Model call completed.\n",
      "Sequence 6 finished generating.\n",
      "Sequence 7 generated token id 26374\n",
      "Processing sequences with past_key_values seq_len = 42\n",
      "Model call completed.\n",
      "Sequence 8 generated token id 3487\n",
      "Processing sequences with past_key_values seq_len = 38\n",
      "Model call completed.\n",
      "Sequence 9 generated token id 279\n",
      "Processing sequences with past_key_values seq_len = 58\n",
      "Model call completed.\n",
      "Sequence 7 generated token id 11\n",
      "Processing sequences with past_key_values seq_len = 43\n",
      "Model call completed.\n",
      "Sequence 8 generated token id 323\n",
      "Processing sequences with past_key_values seq_len = 39\n",
      "Model call completed.\n",
      "Sequence 9 generated token id 1429\n",
      "Processing sequences with past_key_values seq_len = 59\n",
      "Model call completed.\n",
      "Sequence 7 generated token id 18929\n",
      "Processing sequences with past_key_values seq_len = 44\n",
      "Model call completed.\n",
      "Sequence 8 generated token id 1197\n",
      "Processing sequences with past_key_values seq_len = 40\n",
      "Model call completed.\n",
      "Sequence 9 generated token id 31449\n",
      "Processing sequences with past_key_values seq_len = 60\n",
      "Model call completed.\n",
      "Sequence 7 generated token id 33638\n",
      "Processing sequences with past_key_values seq_len = 45\n",
      "Model call completed.\n",
      "Sequence 8 generated token id 524\n",
      "Processing sequences with past_key_values seq_len = 41\n",
      "Model call completed.\n",
      "Sequence 9 generated token id 13923\n",
      "Processing sequences with past_key_values seq_len = 61\n",
      "Model call completed.\n",
      "Sequence 7 generated token id 11\n",
      "Processing sequences with past_key_values seq_len = 46\n",
      "Model call completed.\n",
      "Sequence 8 generated token id 986\n",
      "Processing sequences with past_key_values seq_len = 42\n",
      "Model call completed.\n",
      "Sequence 9 generated token id 315\n",
      "Processing sequences with past_key_values seq_len = 62\n",
      "Model call completed.\n",
      "Sequence 7 generated token id 5810\n",
      "Processing sequences with past_key_values seq_len = 47\n",
      "Model call completed.\n",
      "Sequence 8 generated token id 11\n",
      "Processing sequences with past_key_values seq_len = 43\n",
      "Model call completed.\n",
      "Sequence 9 generated token id 279\n",
      "Processing sequences with past_key_values seq_len = 63\n",
      "Model call completed.\n",
      "Sequence 7 generated token id 6589\n",
      "Processing sequences with past_key_values seq_len = 48\n",
      "Model call completed.\n",
      "Sequence 8 generated token id 311\n",
      "Processing sequences with past_key_values seq_len = 44\n",
      "Model call completed.\n",
      "Sequence 9 generated token id 220\n",
      "Processing sequences with past_key_values seq_len = 64\n",
      "Model call completed.\n",
      "Sequence 7 generated token id 11\n",
      "Processing sequences with past_key_values seq_len = 49\n",
      "Model call completed.\n",
      "Sequence 8 generated token id 2736\n",
      "Processing sequences with past_key_values seq_len = 45\n",
      "Model call completed.\n",
      "Sequence 9 generated token id 17\n",
      "Processing sequences with past_key_values seq_len = 65\n",
      "Model call completed.\n",
      "Sequence 7 generated token id 323\n",
      "Processing sequences with past_key_values seq_len = 50\n",
      "Model call completed.\n",
      "Sequence 8 generated token id 7525\n",
      "Processing sequences with past_key_values seq_len = 46\n",
      "Model call completed.\n",
      "Sequence 9 generated token id 15\n",
      "Processing sequences with past_key_values seq_len = 66\n",
      "Model call completed.\n",
      "Sequence 7 generated token id 18929\n",
      "Processing sequences with past_key_values seq_len = 51\n",
      "Model call completed.\n",
      "Sequence 8 generated token id 389\n",
      "Processing sequences with past_key_values seq_len = 47\n",
      "Model call completed.\n",
      "Sequence 9 generated token id 339\n",
      "Processing sequences with past_key_values seq_len = 67\n",
      "Model call completed.\n",
      "Sequence 7 generated token id 11906\n",
      "Processing sequences with past_key_values seq_len = 52\n",
      "Model call completed.\n",
      "Sequence 8 generated token id 821\n",
      "Processing sequences with past_key_values seq_len = 48\n",
      "Model call completed.\n",
      "Sequence 9 generated token id 9294\n",
      "Processing sequences with past_key_values seq_len = 68\n",
      "Model call completed.\n",
      "Sequence 7 generated token id 13\n",
      "Processing sequences with past_key_values seq_len = 53\n",
      "Model call completed.\n",
      "Sequence 8 generated token id 13\n",
      "Processing sequences with past_key_values seq_len = 49\n",
      "Model call completed.\n",
      "Sequence 9 generated token id 13\n",
      "Processing sequences with past_key_values seq_len = 69\n",
      "Model call completed.\n",
      "Sequence 7 generated token id 67203\n",
      "Processing sequences with past_key_values seq_len = 54\n",
      "Model call completed.\n",
      "Sequence 8 generated token id 26048\n",
      "Processing sequences with past_key_values seq_len = 50\n",
      "Model call completed.\n",
      "Sequence 9 generated token id 1260\n",
      "Processing sequences with past_key_values seq_len = 70\n",
      "Model call completed.\n",
      "Sequence 7 generated token id 374\n",
      "Processing sequences with past_key_values seq_len = 55\n",
      "Model call completed.\n",
      "Sequence 8 generated token id 28824\n",
      "Processing sequences with past_key_values seq_len = 51\n",
      "Model call completed.\n",
      "Sequence 9 generated token id 374\n",
      "Processing sequences with past_key_values seq_len = 71\n",
      "Model call completed.\n",
      "Sequence 7 generated token id 279\n",
      "Processing sequences with past_key_values seq_len = 56\n",
      "Model call completed.\n",
      "Sequence 8 generated token id 18495\n",
      "Processing sequences with past_key_values seq_len = 52\n",
      "Model call completed.\n",
      "Sequence 9 generated token id 1850\n",
      "Processing sequences with past_key_values seq_len = 72\n",
      "Model call completed.\n",
      "Sequence 7 generated token id 4194\n",
      "Processing sequences with past_key_values seq_len = 57\n",
      "Model call completed.\n",
      "Sequence 8 generated token id 11\n",
      "Processing sequences with past_key_values seq_len = 53\n",
      "Model call completed.\n",
      "Sequence 9 generated token id 3881\n",
      "Processing sequences with past_key_values seq_len = 73\n",
      "Model call completed.\n",
      "Sequence 7 generated token id 2297\n",
      "Processing sequences with past_key_values seq_len = 58\n",
      "Model call completed.\n",
      "Sequence 8 generated token id 892\n",
      "Processing sequences with past_key_values seq_len = 54\n",
      "Model call completed.\n",
      "Sequence 9 generated token id 369\n",
      "Processing sequences with past_key_values seq_len = 74\n",
      "Model call completed.\n",
      "Sequence 7 generated token id 304\n",
      "Processing sequences with past_key_values seq_len = 59\n",
      "Model call completed.\n",
      "Sequence 8 generated token id 990\n",
      "Processing sequences with past_key_values seq_len = 55\n",
      "Model call completed.\n",
      "Sequence 9 generated token id 806\n",
      "Processing sequences with past_key_values seq_len = 75\n",
      "Model call completed.\n",
      "Sequence 7 generated token id 279\n",
      "Processing sequences with past_key_values seq_len = 60\n",
      "Model call completed.\n",
      "Sequence 8 generated token id 9472\n",
      "Processing sequences with past_key_values seq_len = 56\n",
      "Model call completed.\n",
      "Sequence 9 generated token id 10126\n",
      "Processing sequences with past_key_values seq_len = 76\n",
      "Model call completed.\n",
      "Sequence 7 generated token id 15552\n",
      "Processing sequences with past_key_values seq_len = 61\n",
      "Model call completed.\n",
      "Sequence 8 generated token id 311\n",
      "Processing sequences with past_key_values seq_len = 57\n",
      "Model call completed.\n",
      "Sequence 9 generated token id 315\n",
      "Processing sequences with past_key_values seq_len = 77\n",
      "Model call completed.\n",
      "Sequence 7 finished generating.\n",
      "Processing sequences with past_key_values seq_len = 62\n",
      "Model call completed.\n",
      "Sequence 8 generated token id 4009\n",
      "Processing sequences with past_key_values seq_len = 58\n",
      "Model call completed.\n",
      "Sequence 9 generated token id 1351\n",
      "Processing sequences with past_key_values seq_len = 63\n",
      "Model call completed.\n",
      "Sequence 8 generated token id 323\n",
      "Processing sequences with past_key_values seq_len = 59\n",
      "Model call completed.\n",
      "Sequence 9 generated token id 43415\n",
      "Processing sequences with past_key_values seq_len = 64\n",
      "Model call completed.\n",
      "Sequence 8 generated token id 1882\n",
      "Processing sequences with past_key_values seq_len = 60\n",
      "Model call completed.\n",
      "Sequence 9 generated token id 11\n",
      "Processing sequences with past_key_values seq_len = 65\n",
      "Model call completed.\n",
      "Sequence 8 generated token id 1995\n",
      "Processing sequences with past_key_values seq_len = 61\n",
      "Model call completed.\n",
      "Sequence 9 generated token id 892\n",
      "Processing sequences with past_key_values seq_len = 66\n",
      "Model call completed.\n",
      "Sequence 8 generated token id 11\n",
      "Processing sequences with past_key_values seq_len = 62\n",
      "Model call completed.\n",
      "Sequence 9 generated token id 13791\n",
      "Processing sequences with past_key_values seq_len = 67\n",
      "Model call completed.\n",
      "Sequence 8 generated token id 30128\n",
      "Processing sequences with past_key_values seq_len = 63\n",
      "Model call completed.\n",
      "Sequence 9 generated token id 1506\n",
      "Processing sequences with past_key_values seq_len = 68\n",
      "Model call completed.\n",
      "Sequence 8 generated token id 18495\n",
      "Processing sequences with past_key_values seq_len = 64\n",
      "Model call completed.\n",
      "Sequence 9 generated token id 1039\n",
      "Processing sequences with past_key_values seq_len = 69\n",
      "Model call completed.\n",
      "Sequence 8 generated token id 990\n",
      "Processing sequences with past_key_values seq_len = 65\n",
      "Model call completed.\n",
      "Sequence 9 generated token id 8660\n",
      "Processing sequences with past_key_values seq_len = 70\n",
      "Model call completed.\n",
      "Sequence 8 generated token id 30128\n",
      "Processing sequences with past_key_values seq_len = 66\n",
      "Model call completed.\n",
      "Sequence 9 generated token id 315\n",
      "Processing sequences with past_key_values seq_len = 71\n",
      "Model call completed.\n",
      "Sequence 8 generated token id 9472\n",
      "Processing sequences with past_key_values seq_len = 67\n",
      "Model call completed.\n",
      "Sequence 9 generated token id 3550\n",
      "Processing sequences with past_key_values seq_len = 72\n",
      "Model call completed.\n",
      "Sequence 8 finished generating.\n",
      "Processing sequences with past_key_values seq_len = 68\n",
      "Model call completed.\n",
      "Sequence 9 generated token id 11\n",
      "Processing sequences with past_key_values seq_len = 69\n",
      "Model call completed.\n",
      "Sequence 9 generated token id 882\n",
      "Processing sequences with past_key_values seq_len = 70\n",
      "Model call completed.\n",
      "Sequence 9 generated token id 11\n",
      "Processing sequences with past_key_values seq_len = 71\n",
      "Model call completed.\n",
      "Sequence 9 generated token id 323\n",
      "Processing sequences with past_key_values seq_len = 72\n",
      "Model call completed.\n",
      "Sequence 9 finished generating.\n",
      "\n",
      "Generated text 1:\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "What is the capital city of France?\n",
      "assistant\n",
      "\n",
      "The capital city of France is Paris.\n",
      "\n",
      "\n",
      "Generated text 0:\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "Tell me about the history of artificial intelligence.\n",
      "assistant\n",
      "Artificial intelligence (AI) is a field of computer science that aims to create intelligent machines that can perform tasks that typically require human intelligence, such as visual perception, speech recognition, decision-making, and language translation. The history of AI is a long\n",
      "\n",
      "\n",
      "Generated text 2:\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "Explain the theory of relativity.\n",
      "assistant\n",
      "\n",
      "The theory of relativity is a scientific theory that describes the relationship between space, time, and gravity. It was developed by Albert Einstein in the early 20th century and has since become one of the most important and influential theories in physics\n",
      "\n",
      "\n",
      "Generated text 3:\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "How does the process of photosynthesis work?\n",
      "assistant\n",
      "Photosynthesis is the process by which plants, algae, and some bacteria convert light energy into chemical energy stored in glucose. The process takes place in the chloroplasts of plant cells, which contain chlorophyll, a green pigment that absorbs light energy\n",
      "\n",
      "\n",
      "Generated text 4:\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "What is the tallest mountain in the world?\n",
      "assistant\n",
      "The tallest mountain in the world is Mount Everest, which stands at an elevation of 8,848 meters (29,029 feet) above sea level. It is located in the Mahalangur Himal sub-range of the\n",
      "\n",
      "\n",
      "Generated text 5:\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "Who wrote 'To Kill a Mockingbird'?\n",
      "assistant\n",
      "\"To Kill a Mockingbird\" was written by Harper Lee.\n",
      "\n",
      "\n",
      "Generated text 6:\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "What is the speed of light?\n",
      "assistant\n",
      "\n",
      "The speed of light in a vacuum is approximately 299,792,458 meters per second (m/s).\n",
      "\n",
      "\n",
      "Generated text 7:\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "Describe the process of evolution.\n",
      "assistant\n",
      "\n",
      "The process of evolution is the gradual change in the genetic makeup of a population over time. This change occurs through a series of steps, including mutation, genetic drift, natural selection, and genetic migration. Mutation is the random change in the DNA sequence\n",
      "\n",
      "\n",
      "Generated text 8:\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "What is quantum computing?\n",
      "assistant\n",
      "Quantum computing is a type of computing that uses quantum-mechanical phenomena, such as superposition and entanglement, to perform operations on data. Unlike classical computers, which use bits to represent and process information, quantum computers use quantum bits,\n",
      "\n",
      "\n",
      "Generated text 9:\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "Who was Albert Einstein?\n",
      "assistant\n",
      "Albert Einstein was a German-born theoretical physicist who is widely regarded as one of the most influential scientists of the 20th century. He is best known for his theory of relativity, which revolutionized our understanding of space, time, and gravity\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model_name = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Ensure pad_token is set\n",
    "\n",
    "print(\"Special tokens map:\", tokenizer.special_tokens_map)\n",
    "print(\"All special tokens:\", tokenizer.all_special_tokens)\n",
    "print(\"All special token IDs:\", tokenizer.all_special_ids)\n",
    "\n",
    "# Get the model's default dtype\n",
    "default_dtype = next(model.parameters()).dtype\n",
    "\n",
    "# All prompts\n",
    "pending_prompts = [\n",
    "    \"Tell me about the history of artificial intelligence.\",\n",
    "    \"What is the capital city of France?\",\n",
    "    \"Explain the theory of relativity.\",\n",
    "    \"How does the process of photosynthesis work?\",\n",
    "    \"What is the tallest mountain in the world?\",\n",
    "    \"Who wrote 'To Kill a Mockingbird'?\",\n",
    "    \"What is the speed of light?\",\n",
    "    \"Describe the process of evolution.\",\n",
    "    \"What is quantum computing?\",\n",
    "    \"Who was Albert Einstein?\",\n",
    "]\n",
    "\n",
    "max_new_tokens = 50  # Maximum tokens to generate per sequence\n",
    "max_batch_size = 4   # Maximum number of sequences in a batch\n",
    "eos_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# Initialize lists\n",
    "active_sequences = []\n",
    "finished_sequences = []\n",
    "sequence_id = 0  # Unique identifier for each sequence\n",
    "\n",
    "# Get model configurations\n",
    "num_layers = model.config.num_hidden_layers\n",
    "# Adjusted for Grouped Query Attention (GQA)\n",
    "if hasattr(model.config, \"num_key_value_heads\"):\n",
    "    num_kv_heads = model.config.num_key_value_heads\n",
    "elif hasattr(model.config, \"num_key_value_groups\"):\n",
    "    num_kv_heads = model.config.num_key_value_groups\n",
    "else:\n",
    "    # Default to num_attention_heads if no GQA is used\n",
    "    num_kv_heads = model.config.num_attention_heads\n",
    "\n",
    "# Main loop\n",
    "while pending_prompts or active_sequences:\n",
    "    # Fill up the batch with new prompts if we have space\n",
    "    while len(active_sequences) < max_batch_size and pending_prompts:\n",
    "        prompt = pending_prompts.pop(0)\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "        text = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "        model_input = tokenizer(text, return_tensors=\"pt\")\n",
    "        input_ids = model_input[\"input_ids\"].to(model.device)  # Shape: [1, seq_len]\n",
    "        attention_mask = model_input[\"attention_mask\"].to(model.device)\n",
    "        # Initialize position_ids\n",
    "        position_ids = (attention_mask.cumsum(dim=1) - 1).clamp(min=0)\n",
    "\n",
    "        # Initialize past_key_values as None for the sequence\n",
    "        sequence = {\n",
    "            \"id\": sequence_id,\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"position_ids\": position_ids,\n",
    "            \"generated_ids\": input_ids.clone(),\n",
    "            \"past_key_values\": None,  # Initialize as None\n",
    "            \"finished\": False,\n",
    "            \"max_length\": input_ids.shape[1] + max_new_tokens,\n",
    "        }\n",
    "        active_sequences.append(sequence)\n",
    "        sequence_id += 1\n",
    "        print(f\"Added sequence {sequence['id']} to active sequences\")\n",
    "\n",
    "    if not active_sequences:\n",
    "        break  # No active sequences left to process\n",
    "\n",
    "    # Separate sequences into initial and subsequent sequences\n",
    "    initial_sequences = [seq for seq in active_sequences if seq[\"past_key_values\"] is None]\n",
    "    subsequent_sequences = [seq for seq in active_sequences if seq[\"past_key_values\"] is not None]\n",
    "\n",
    "    # Process initial sequences\n",
    "    if initial_sequences:\n",
    "        batch_input_ids = [seq[\"input_ids\"].squeeze(0) for seq in initial_sequences]  # Remove batch dimension\n",
    "        batch_attention_mask = [seq[\"attention_mask\"].squeeze(0) for seq in initial_sequences]\n",
    "        batch_position_ids = [seq[\"position_ids\"].squeeze(0) for seq in initial_sequences]\n",
    "\n",
    "        # Pad sequences to the same length\n",
    "        batch_input_ids = torch.nn.utils.rnn.pad_sequence(batch_input_ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "        batch_attention_mask = torch.nn.utils.rnn.pad_sequence(batch_attention_mask, batch_first=True, padding_value=0)\n",
    "        batch_position_ids = torch.nn.utils.rnn.pad_sequence(batch_position_ids, batch_first=True, padding_value=0)\n",
    "\n",
    "        # Prepare model inputs\n",
    "        model_inputs = {\n",
    "            \"input_ids\": batch_input_ids,\n",
    "            \"attention_mask\": batch_attention_mask,\n",
    "            \"position_ids\": batch_position_ids,\n",
    "            \"use_cache\": True,\n",
    "        }\n",
    "\n",
    "        # Forward pass\n",
    "        print(f\"Calling model for initial sequences...\")\n",
    "        outputs = model(**model_inputs)\n",
    "        print(\"Model call completed.\")\n",
    "\n",
    "        logits = outputs.logits  # Shape: (batch_size, seq_length, vocab_size)\n",
    "        new_past_key_values = outputs.past_key_values  # List of tuples per layer\n",
    "\n",
    "        # Update each sequence\n",
    "        for idx, seq in enumerate(initial_sequences):\n",
    "            # Extract the key and value tensors for this sequence\n",
    "            seq_past_key_values = []\n",
    "            for layer_idx in range(num_layers):\n",
    "                key = new_past_key_values[layer_idx][0][idx:idx+1]\n",
    "                value = new_past_key_values[layer_idx][1][idx:idx+1]\n",
    "                seq_past_key_values.append((key, value))\n",
    "            seq[\"past_key_values\"] = seq_past_key_values\n",
    "\n",
    "            # Get next token logits (last token)\n",
    "            next_token_logits = logits[idx, -1, :]\n",
    "\n",
    "            # Apply greedy decoding\n",
    "            next_token = torch.argmax(next_token_logits, dim=-1, keepdim=True)  # Shape: [1]\n",
    "            next_token = next_token.to(seq[\"generated_ids\"].device)\n",
    "\n",
    "            # Update generated_ids\n",
    "            seq[\"generated_ids\"] = torch.cat([seq[\"generated_ids\"], next_token.unsqueeze(0)], dim=1)\n",
    "            # Update position_ids\n",
    "            seq[\"position_ids\"] = torch.cat([seq[\"position_ids\"], seq[\"position_ids\"][:, -1:] + 1], dim=1)\n",
    "\n",
    "            # Check for EOS token or max length\n",
    "            if next_token.item() == eos_token_id or seq[\"generated_ids\"].shape[1] >= seq[\"max_length\"]:\n",
    "                seq[\"finished\"] = True\n",
    "                print(f\"Sequence {seq['id']} finished generating.\")\n",
    "            else:\n",
    "                print(f\"Sequence {seq['id']} generated token id {next_token.item()}\")\n",
    "\n",
    "    # Process subsequent sequences\n",
    "    if subsequent_sequences:\n",
    "        # Group sequences by past_key_values seq_len\n",
    "        seq_len_to_sequences = defaultdict(list)\n",
    "        for seq in subsequent_sequences:\n",
    "            seq_len = seq[\"past_key_values\"][0][0].shape[2]  # seq_len dimension\n",
    "            seq_len_to_sequences[seq_len].append(seq)\n",
    "\n",
    "        # Process each group separately\n",
    "        for seq_len, sequences in seq_len_to_sequences.items():\n",
    "            batch_input_ids = []\n",
    "            batch_attention_mask = []\n",
    "            batch_position_ids = []\n",
    "            batch_past_key_values = []\n",
    "            next_position_ids_per_sequence = []  # Store per-sequence next_position_id\n",
    "\n",
    "            # Collect inputs and past_key_values\n",
    "            for idx, seq in enumerate(sequences):\n",
    "                # Collect past_key_values for each layer\n",
    "                for layer_idx in range(num_layers):\n",
    "                    past_key, past_value = seq[\"past_key_values\"][layer_idx]\n",
    "                    if idx == 0:\n",
    "                        # Initialize lists for this layer\n",
    "                        batch_past_key_values.append([[], []])\n",
    "                    batch_past_key_values[layer_idx][0].append(past_key)\n",
    "                    batch_past_key_values[layer_idx][1].append(past_value)\n",
    "\n",
    "                # Prepare input_ids, attention_mask, position_ids\n",
    "                next_input_id = seq[\"generated_ids\"][:, -1:]  # Shape: [1, 1]\n",
    "                batch_input_ids.append(next_input_id)\n",
    "\n",
    "                attention_mask = torch.ones_like(next_input_id, dtype=seq[\"attention_mask\"].dtype)\n",
    "                batch_attention_mask.append(attention_mask)\n",
    "\n",
    "                next_position_id = seq[\"position_ids\"][:, -1:] + 1  # Shape: [1, 1]\n",
    "                batch_position_ids.append(next_position_id)\n",
    "                # Store per-sequence next_position_id for later use\n",
    "                next_position_ids_per_sequence.append(next_position_id)\n",
    "\n",
    "            # Stack past_key_values for each layer\n",
    "            for layer_idx in range(num_layers):\n",
    "                keys = torch.cat(batch_past_key_values[layer_idx][0], dim=0)\n",
    "                values = torch.cat(batch_past_key_values[layer_idx][1], dim=0)\n",
    "                batch_past_key_values[layer_idx] = (keys, values)\n",
    "\n",
    "            # Concatenate input tensors along batch dimension\n",
    "            batch_input_ids = torch.cat(batch_input_ids, dim=0)\n",
    "            batch_attention_mask = torch.cat(batch_attention_mask, dim=0)\n",
    "            batch_position_ids = torch.cat(batch_position_ids, dim=0)\n",
    "\n",
    "            # Prepare model inputs\n",
    "            model_inputs = {\n",
    "                \"input_ids\": batch_input_ids,\n",
    "                \"attention_mask\": batch_attention_mask,\n",
    "                \"position_ids\": batch_position_ids,\n",
    "                \"past_key_values\": batch_past_key_values,\n",
    "                \"use_cache\": True,\n",
    "            }\n",
    "\n",
    "            # Forward pass\n",
    "            print(f\"Processing sequences with past_key_values seq_len = {seq_len}\")\n",
    "            outputs = model(**model_inputs)\n",
    "            print(\"Model call completed.\")\n",
    "\n",
    "            logits = outputs.logits  # Shape: (batch_size, seq_length, vocab_size)\n",
    "            new_past_key_values = outputs.past_key_values  # List of tuples per layer\n",
    "\n",
    "            # Update each sequence in the group\n",
    "            for idx, seq in enumerate(sequences):\n",
    "                # Extract the key and value tensors for this sequence\n",
    "                seq_past_key_values = []\n",
    "                for layer_idx in range(num_layers):\n",
    "                    key = new_past_key_values[layer_idx][0][idx:idx+1]\n",
    "                    value = new_past_key_values[layer_idx][1][idx:idx+1]\n",
    "                    seq_past_key_values.append((key, value))\n",
    "                seq[\"past_key_values\"] = seq_past_key_values\n",
    "\n",
    "                # Get next token logits (last token)\n",
    "                next_token_logits = logits[idx, -1, :]\n",
    "\n",
    "                # Apply any decoding strategy here (e.g., greedy)\n",
    "                next_token = torch.argmax(next_token_logits, dim=-1, keepdim=True)  # Shape: [1]\n",
    "                next_token = next_token.to(seq[\"generated_ids\"].device)\n",
    "\n",
    "                # Update generated_ids\n",
    "                seq[\"generated_ids\"] = torch.cat([seq[\"generated_ids\"], next_token.unsqueeze(0)], dim=1)\n",
    "                # Update position_ids using the stored next_position_id\n",
    "                seq[\"position_ids\"] = torch.cat([seq[\"position_ids\"], next_position_ids_per_sequence[idx]], dim=1)\n",
    "\n",
    "                # Check for EOS token or max length\n",
    "                if next_token.item() == eos_token_id or seq[\"generated_ids\"].shape[1] >= seq[\"max_length\"]:\n",
    "                    seq[\"finished\"] = True\n",
    "                    print(f\"Sequence {seq['id']} finished generating.\")\n",
    "                else:\n",
    "                    print(f\"Sequence {seq['id']} generated token id {next_token.item()}\")\n",
    "\n",
    "    # Remove finished sequences and add to finished_sequences\n",
    "    new_active_sequences = []\n",
    "    for seq in active_sequences:\n",
    "        if seq[\"finished\"]:\n",
    "            finished_sequences.append(seq)\n",
    "        else:\n",
    "            new_active_sequences.append(seq)\n",
    "    active_sequences = new_active_sequences\n",
    "\n",
    "    # Refill the batch after processing\n",
    "    while len(active_sequences) < max_batch_size and pending_prompts:\n",
    "        prompt = pending_prompts.pop(0)\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "        text = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "        print(f\"Formatted input in working script:\\n{text}\\n\")\n",
    "        model_input = tokenizer(text, return_tensors=\"pt\")\n",
    "        input_ids = model_input[\"input_ids\"].to(model.device)\n",
    "        attention_mask = model_input[\"attention_mask\"].to(model.device)\n",
    "        # Initialize position_ids\n",
    "        position_ids = (attention_mask.cumsum(dim=1) - 1).clamp(min=0)\n",
    "\n",
    "        # Initialize past_key_values as None for the sequence\n",
    "        sequence = {\n",
    "            \"id\": sequence_id,\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"position_ids\": position_ids,\n",
    "            \"generated_ids\": input_ids.clone(),\n",
    "            \"past_key_values\": None,  # Initialize as None\n",
    "            \"finished\": False,\n",
    "            \"max_length\": input_ids.shape[1] + max_new_tokens,\n",
    "        }\n",
    "        active_sequences.append(sequence)\n",
    "        sequence_id += 1\n",
    "        print(f\"Added sequence {sequence['id']} to active sequences\")\n",
    "\n",
    "# Decode generated sequences\n",
    "for seq in finished_sequences:\n",
    "    generated_ids = seq[\"generated_ids\"]\n",
    "    generated_text = tokenizer.decode(generated_ids.squeeze(0), skip_special_tokens=True)\n",
    "    print(f\"\\nGenerated text {seq['id']}:\\n{generated_text}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
