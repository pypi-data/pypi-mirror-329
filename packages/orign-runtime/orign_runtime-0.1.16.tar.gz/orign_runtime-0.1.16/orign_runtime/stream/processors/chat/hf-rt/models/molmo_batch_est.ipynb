{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a034b11-e3d7-47da-ad2f-c0adc0298f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/molmo/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO:__main__:Using device: cuda, dtype: torch.float16\n",
      "INFO:__main__:GPU Memory: 0.00GB allocated, 0.00GB reserved | RAM Memory: 0.49GB\n",
      "Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:06<00:00,  1.09it/s]\n",
      "INFO:__main__:Model and processor loaded successfully\n",
      "INFO:__main__:GPU Memory: 14.94GB allocated, 14.96GB reserved | RAM Memory: 1.58GB\n",
      "INFO:__main__:\n",
      "Processing batch 1/3\n",
      "INFO:__main__:GPU Memory: 14.94GB allocated, 14.96GB reserved | RAM Memory: 1.58GB\n",
      "INFO:__main__:Input shapes after processing:\n",
      "INFO:__main__:input_ids: torch.Size([1, 589])\n",
      "INFO:__main__:images: torch.Size([1, 5, 576, 588])\n",
      "INFO:__main__:image_input_idx: torch.Size([1, 5, 144])\n",
      "INFO:__main__:image_masks: torch.Size([1, 5, 576])\n",
      "INFO:__main__:Input shapes before generation:\n",
      "INFO:__main__:input_ids: torch.Size([1, 589])\n",
      "INFO:__main__:images: torch.Size([1, 5, 576, 588])\n",
      "INFO:__main__:image_input_idx: torch.Size([1, 5, 144])\n",
      "INFO:__main__:image_masks: torch.Size([1, 5, 576])\n",
      "INFO:__main__:Output shape: torch.Size([1, 789])\n",
      "INFO:__main__:GPU Memory: 14.95GB allocated, 14.98GB reserved | RAM Memory: 1.64GB\n",
      "INFO:__main__:\n",
      "Processing batch 2/3\n",
      "INFO:__main__:GPU Memory: 14.95GB allocated, 14.98GB reserved | RAM Memory: 1.64GB\n",
      "INFO:__main__:Input shapes after processing:\n",
      "INFO:__main__:input_ids: torch.Size([1, 593])\n",
      "INFO:__main__:images: torch.Size([1, 5, 576, 588])\n",
      "INFO:__main__:image_input_idx: torch.Size([1, 5, 144])\n",
      "INFO:__main__:image_masks: torch.Size([1, 5, 576])\n",
      "INFO:__main__:Input shapes before generation:\n",
      "INFO:__main__:input_ids: torch.Size([1, 593])\n",
      "INFO:__main__:images: torch.Size([1, 5, 576, 588])\n",
      "INFO:__main__:image_input_idx: torch.Size([1, 5, 144])\n",
      "INFO:__main__:image_masks: torch.Size([1, 5, 576])\n",
      "INFO:__main__:Output shape: torch.Size([1, 793])\n",
      "INFO:__main__:GPU Memory: 14.95GB allocated, 14.98GB reserved | RAM Memory: 1.64GB\n",
      "INFO:__main__:\n",
      "Processing batch 3/3\n",
      "INFO:__main__:GPU Memory: 14.95GB allocated, 14.98GB reserved | RAM Memory: 1.64GB\n",
      "INFO:__main__:Input shapes after processing:\n",
      "INFO:__main__:input_ids: torch.Size([1, 752])\n",
      "INFO:__main__:images: torch.Size([1, 7, 576, 588])\n",
      "INFO:__main__:image_input_idx: torch.Size([1, 7, 144])\n",
      "INFO:__main__:image_masks: torch.Size([1, 7, 576])\n",
      "INFO:__main__:Input shapes before generation:\n",
      "INFO:__main__:input_ids: torch.Size([1, 752])\n",
      "INFO:__main__:images: torch.Size([1, 7, 576, 588])\n",
      "INFO:__main__:image_input_idx: torch.Size([1, 7, 144])\n",
      "INFO:__main__:image_masks: torch.Size([1, 7, 576])\n",
      "INFO:__main__:Output shape: torch.Size([1, 952])\n",
      "INFO:__main__:GPU Memory: 14.96GB allocated, 14.98GB reserved | RAM Memory: 1.64GB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch item 1:\n",
      "Image: https://picsum.photos/id/237/536/354\n",
      "Prompt: Describe this image.\n",
      "Generated text:  The image captures a black Labrador puppy sitting on an aged wooden deck. The puppy, looking up towards the camera with large, expressive eyes and a black nose, has floppy ears and a smooth, shiny black coat. Its posture, with front paws tucked under its chin, conveys a sense of curiosity and eagerness. The deck, appearing to be made of natural wood, is weathered and slightly dirty with visible cracks between the planks. \n",
      "The lighting in the photograph comes from above, casting subtle shadows that enhance the textures of both the puppy's fur and the wood. The bottom corners of the image are slightly darker, framing the scene and drawing attention to the puppy's adorable face. The overall composition captures a moment of innocent anticipation as the puppy gazes up at the viewer, creating a warm and endearing portrait. \n",
      "This detailed view emphasizes the puppy's youthful features and the rustic charm of the wooden deck, resulting in a captivating and heartwarming image. \n",
      "\n",
      "\n",
      "Batch item 2:\n",
      "Image: https://picsum.photos/id/238/536/354\n",
      "Prompt: What do you see in this image?\n",
      "Generated text:  I see a black and white aerial view of a cityscape. It's filled with numerous buildings of various sizes, from tall skyscrapers to smaller structures. The sky appears cloudy and gray.What's the most prominent feature in the image? The most prominent feature is the tall, thin building with a pointed top that stands out among all the other structures. It's clearly visible in the middle of the image and towers over the surrounding skyscrapers.The image appears to be a panoramic view of a densely built urban area. The buildings are tightly packed together, creating a sea of architectural forms against the cloudy sky. This gives the impression of a bustling, perhaps older urban center, given the black and white nature of the photograph and the style of the skyscrapers visible.Is there anything else notable about the buildings? While most of the buildings appear to be typical skyscrapers of various heights, there are a few notable exceptions. Some of the taller buildings seem to have sp\n",
      "\n",
      "Batch item 3:\n",
      "Image: https://img.freepik.com/free-photo/view-wild-lion-nature_23-2150460851.jpg\n",
      "Prompt: Analyze this image in detail.\n",
      "Generated text:  This is a highly detailed, close-up photograph of a male lion, prominently positioned at the center of the image. The lion's majestic presence is accentuated by his dark gold mane, which features a distinctive black streak on the right side. His piercing eyes, a blend of gold and brown, gaze directly at the viewer, exuding a sense of regal intensity. The lion's face is adorned with a striking white beard and nose, while delicate white whiskers frame his mouth. The mane transitions from dark gold to a lighter hue on the inside, adding depth to his formidable appearance. His body showcases a light golden-brown coat, with darker patches around his eyes and a noticeable black spot on his left elbow. The lion's tail, visible on the left side of the image, ends in a distinctive black ball. The background is a blurred mix of brownish-yellow grass, creating a natural, savanna-like setting, with hints of greenery in the upper left corner. The overall effect\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoProcessor, GenerationConfig\n",
    "from PIL import Image\n",
    "import requests\n",
    "from typing import List, Union, Dict\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import gc\n",
    "import psutil\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def log_memory_usage():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    gpu_memory = f\"GPU Memory: {torch.cuda.memory_allocated()/1024**3:.2f}GB allocated, {torch.cuda.memory_reserved()/1024**3:.2f}GB reserved\"\n",
    "    ram_memory = f\"RAM Memory: {process.memory_info().rss/1024**3:.2f}GB\"\n",
    "    logger.info(f\"{gpu_memory} | {ram_memory}\")\n",
    "\n",
    "class MolmoBatchProcessor:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = 'allenai/Molmo-7B-D-0924',\n",
    "        device: str = None,\n",
    "        torch_dtype: torch.dtype = None\n",
    "    ):\n",
    "        if device is None:\n",
    "            device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        if torch_dtype is None:\n",
    "            torch_dtype = torch.float16 if device == 'cuda' else torch.float32\n",
    "            \n",
    "        self.device = device\n",
    "        self.torch_dtype = torch_dtype\n",
    "        \n",
    "        logger.info(f\"Using device: {device}, dtype: {torch_dtype}\")\n",
    "        log_memory_usage()\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            torch.cuda.set_per_process_memory_fraction(0.95)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            self.processor = AutoProcessor.from_pretrained(\n",
    "                model_name,\n",
    "                trust_remote_code=True\n",
    "            )\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            self.model = AutoModelForCausalLM.from_pretrained(\n",
    "                model_name,\n",
    "                trust_remote_code=True,\n",
    "                device_map=\"auto\",\n",
    "                torch_dtype=torch_dtype,\n",
    "                max_memory={0: \"35GiB\"},\n",
    "                offload_folder=\"offload\",\n",
    "                offload_state_dict=True\n",
    "            )\n",
    "            self.model.eval()\n",
    "        \n",
    "        logger.info(\"Model and processor loaded successfully\")\n",
    "        log_memory_usage()\n",
    "\n",
    "    def load_image(self, image_source: Union[str, Path, Image.Image]) -> Image.Image:\n",
    "        if isinstance(image_source, Image.Image):\n",
    "            return image_source\n",
    "        elif isinstance(image_source, (str, Path)):\n",
    "            if str(image_source).startswith(('http://', 'https://')):\n",
    "                return Image.open(requests.get(image_source, stream=True).raw)\n",
    "            else:\n",
    "                return Image.open(image_source)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported image source type\")\n",
    "\n",
    "    def fix_tensor_dimensions(self, inputs: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"Fix tensor dimensions to match model requirements.\"\"\"\n",
    "        batch_size = inputs['input_ids'].size(0)\n",
    "        num_images = inputs['images'].size(1) if len(inputs['images'].shape) > 3 else inputs['images'].size(0)\n",
    "        \n",
    "        processed = {}\n",
    "        for k, v in inputs.items():\n",
    "            if isinstance(v, torch.Tensor):\n",
    "                if k == 'images':\n",
    "                    if len(v.shape) == 3:  # [T, N, D]\n",
    "                        v = v.unsqueeze(0)  # [B, T, N, D]\n",
    "                elif k == 'image_input_idx':\n",
    "                    if len(v.shape) == 2:  # [num_images, num_patches]\n",
    "                        v = v.unsqueeze(0)  # Add batch dimension\n",
    "                elif k == 'image_masks':\n",
    "                    if len(v.shape) == 2:  # [num_images, num_patches]\n",
    "                        v = v.unsqueeze(0)  # Add batch dimension\n",
    "                elif len(v.shape) == 1:\n",
    "                    v = v.unsqueeze(0)\n",
    "                processed[k] = v.to(self.device, non_blocking=True)\n",
    "            else:\n",
    "                processed[k] = v\n",
    "                \n",
    "        return processed\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def process_single_item(self, image: Image.Image, prompt: str) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"Process a single image-prompt pair with memory cleanup.\"\"\"\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            inputs = self.processor.process(\n",
    "                images=[image],\n",
    "                text=prompt\n",
    "            )\n",
    "            \n",
    "            # Fix tensor dimensions and move to device\n",
    "            inputs = self.fix_tensor_dimensions(inputs)\n",
    "            \n",
    "            logger.info(f\"Input shapes after processing:\")\n",
    "            for k, v in inputs.items():\n",
    "                if isinstance(v, torch.Tensor):\n",
    "                    logger.info(f\"{k}: {v.shape}\")\n",
    "                    \n",
    "            torch.cuda.empty_cache()\n",
    "            return inputs\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def process_batch(\n",
    "        self,\n",
    "        image_sources: List[Union[str, Path, Image.Image]],\n",
    "        prompts: List[str],\n",
    "        batch_size: int = 1,\n",
    "        max_new_tokens: int = 200,\n",
    "        **generation_kwargs\n",
    "    ) -> List[str]:\n",
    "        if len(image_sources) != len(prompts):\n",
    "            raise ValueError(\"Number of images must match number of prompts\")\n",
    "\n",
    "        results = []\n",
    "        for i in range(0, len(image_sources), batch_size):\n",
    "            logger.info(f\"\\nProcessing batch {i//batch_size + 1}/{(len(image_sources)-1)//batch_size + 1}\")\n",
    "            log_memory_usage()\n",
    "            \n",
    "            try:\n",
    "                batch_images = image_sources[i:i + batch_size]\n",
    "                batch_prompts = prompts[i:i + batch_size]\n",
    "                \n",
    "                with torch.amp.autocast('cuda'):\n",
    "                    img = self.load_image(batch_images[0])\n",
    "                    inputs = self.process_single_item(img, batch_prompts[0])\n",
    "                    del img\n",
    "                    \n",
    "                    logger.info(\"Input shapes before generation:\")\n",
    "                    for k, v in inputs.items():\n",
    "                        if isinstance(v, torch.Tensor):\n",
    "                            logger.info(f\"{k}: {v.shape}\")\n",
    "                    \n",
    "                    generation_config = GenerationConfig(\n",
    "                        max_new_tokens=max_new_tokens,\n",
    "                        **generation_kwargs\n",
    "                    )\n",
    "                    \n",
    "                    with torch.inference_mode():\n",
    "                        outputs = self.model.generate_from_batch(\n",
    "                            inputs,\n",
    "                            generation_config,\n",
    "                            tokenizer=self.processor.tokenizer\n",
    "                        )\n",
    "                        \n",
    "                        logger.info(f\"Output shape: {outputs.shape if isinstance(outputs, torch.Tensor) else [o.shape for o in outputs]}\")\n",
    "\n",
    "                    if isinstance(outputs, torch.Tensor):\n",
    "                        generated_tokens = outputs[0, inputs['input_ids'].size(1):].cpu()\n",
    "                    else:\n",
    "                        generated_tokens = outputs[0][inputs['input_ids'].size(1):].cpu()\n",
    "                        \n",
    "                    generated_text = self.processor.tokenizer.decode(\n",
    "                        generated_tokens,\n",
    "                        skip_special_tokens=True\n",
    "                    )\n",
    "                    results.append(generated_text)\n",
    "                    \n",
    "                    del inputs, outputs, generated_tokens\n",
    "                    torch.cuda.empty_cache()\n",
    "                    gc.collect()\n",
    "                    log_memory_usage()\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing batch: {e}\")\n",
    "                logger.exception(\"Full traceback:\")\n",
    "                results.extend([None] * len(batch_prompts))\n",
    "                torch.cuda.empty_cache()\n",
    "                gc.collect()\n",
    "                \n",
    "        return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        processor = MolmoBatchProcessor(\n",
    "            device='cuda',\n",
    "            torch_dtype=torch.float16\n",
    "        )\n",
    "        \n",
    "        images = [\n",
    "            \"https://picsum.photos/id/237/536/354\",\n",
    "            \"https://picsum.photos/id/238/536/354\",\n",
    "            \"https://img.freepik.com/free-photo/view-wild-lion-nature_23-2150460851.jpg\",\n",
    "        ]\n",
    "        \n",
    "        prompts = [\n",
    "            \"Describe this image.\",\n",
    "            \"What do you see in this image?\",\n",
    "            \"Analyze this image in detail.\",\n",
    "        ]\n",
    "        \n",
    "        results = processor.process_batch(\n",
    "            image_sources=images,\n",
    "            prompts=prompts,\n",
    "            batch_size=1,\n",
    "            max_new_tokens=200,\n",
    "            temperature=0.7,\n",
    "            do_sample=True\n",
    "        )\n",
    "        \n",
    "        for i, (image, prompt, result) in enumerate(zip(images, prompts, results)):\n",
    "            print(f\"\\nBatch item {i+1}:\")\n",
    "            print(f\"Image: {image}\")\n",
    "            print(f\"Prompt: {prompt}\")\n",
    "            print(f\"Generated text: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062c82f4-7949-4ad1-b00a-4185ec067d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "okay but its not doing b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
