{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "454411c9-3c25-429b-aed9-126e708e4678",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.cache/pypoetry/virtualenvs/orign-Sz0VPFy2-py3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-10-26 20:38:29,175\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 10-26 20:38:29 config.py:1664] Downcasting torch.float32 to torch.float16.\n",
      "INFO 10-26 20:38:33 llm_engine.py:237] Initializing an LLM engine (v0.6.3.post1) with config: model='allenai/Molmo-7B-D-0924', speculative_config=None, tokenizer='allenai/Molmo-7B-D-0924', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=allenai/Molmo-7B-D-0924, num_scheduler_steps=1, chunked_prefill_enabled=False multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=True, use_cached_outputs=False, mm_processor_kwargs=None)\n",
      "INFO 10-26 20:38:34 model_runner.py:1056] Starting to load model allenai/Molmo-7B-D-0924...\n",
      "WARNING 10-26 20:38:34 utils.py:513] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.\n",
      "WARNING 10-26 20:38:34 utils.py:513] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.\n",
      "WARNING 10-26 20:38:34 utils.py:513] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.\n",
      "WARNING 10-26 20:38:34 utils.py:513] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.\n",
      "WARNING 10-26 20:38:34 utils.py:513] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.\n",
      "WARNING 10-26 20:38:34 utils.py:513] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.\n",
      "WARNING 10-26 20:38:34 utils.py:513] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.\n",
      "WARNING 10-26 20:38:34 utils.py:513] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.\n",
      "WARNING 10-26 20:38:34 utils.py:513] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.\n",
      "WARNING 10-26 20:38:34 utils.py:513] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.\n",
      "WARNING 10-26 20:38:34 utils.py:513] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.\n",
      "WARNING 10-26 20:38:34 utils.py:513] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.\n",
      "WARNING 10-26 20:38:34 utils.py:513] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.\n",
      "WARNING 10-26 20:38:34 utils.py:513] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.\n",
      "WARNING 10-26 20:38:34 utils.py:513] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.\n",
      "WARNING 10-26 20:38:34 utils.py:513] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.\n",
      "WARNING 10-26 20:38:34 utils.py:513] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.\n",
      "WARNING 10-26 20:38:34 utils.py:513] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.\n",
      "WARNING 10-26 20:38:34 utils.py:513] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.\n",
      "WARNING 10-26 20:38:34 utils.py:513] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.\n",
      "WARNING 10-26 20:38:34 utils.py:513] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.\n",
      "WARNING 10-26 20:38:34 utils.py:513] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.\n",
      "WARNING 10-26 20:38:34 utils.py:513] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.\n",
      "WARNING 10-26 20:38:34 utils.py:513] Current `vllm-flash-attn` has a bug inside vision module, so we use xformers backend instead. You can run `pip install flash-attn` to use flash-attention backend.\n",
      "INFO 10-26 20:38:34 weight_utils.py:243] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/7 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards:  14% Completed | 1/7 [00:00<00:02,  2.21it/s]\n",
      "Loading safetensors checkpoint shards:  29% Completed | 2/7 [00:01<00:04,  1.21it/s]\n",
      "Loading safetensors checkpoint shards:  43% Completed | 3/7 [00:02<00:04,  1.06s/it]\n",
      "Loading safetensors checkpoint shards:  57% Completed | 4/7 [00:04<00:03,  1.17s/it]\n",
      "Loading safetensors checkpoint shards:  71% Completed | 5/7 [00:05<00:02,  1.26s/it]\n",
      "Loading safetensors checkpoint shards:  86% Completed | 6/7 [00:06<00:01,  1.12s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 7/7 [00:07<00:00,  1.13s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 7/7 [00:07<00:00,  1.09s/it]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 10-26 20:38:43 model_runner.py:1067] Loading model weights took 14.9975 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.cache/pypoetry/virtualenvs/orign-Sz0VPFy2-py3.12/lib/python3.12/site-packages/xformers/ops/fmha/flash.py:211: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
      "  @torch.library.impl_abstract(\"xformers_flash::flash_fwd\")\n",
      "/home/ubuntu/.cache/pypoetry/virtualenvs/orign-Sz0VPFy2-py3.12/lib/python3.12/site-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
      "  @torch.library.impl_abstract(\"xformers_flash::flash_bwd\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 10-26 20:38:56 gpu_executor.py:122] # GPU blocks: 26351, # CPU blocks: 4681\n",
      "INFO 10-26 20:38:56 gpu_executor.py:126] Maximum concurrency for 4096 tokens per request: 102.93x\n",
      "INFO 10-26 20:39:00 model_runner.py:1395] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 10-26 20:39:00 model_runner.py:1399] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 10-26 20:39:11 model_runner.py:1523] Graph capturing finished in 11 secs.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "from PIL import Image\n",
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "llm = LLM(model=\"allenai/Molmo-7B-D-0924\", trust_remote_code=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8de52106-94d1-4141-bdf9-486ed9ccfb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.14s/it, est. speed input: 10.52 toks/s, output: 313.80 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output:  RequestOutput(request_id=3, prompt='Whats the content of this image?', prompt_token_ids=tensor([151643,   2657,     25,  29756,    279,   2213,    315,    419,   2168,\n",
      "            30,  21388,     25], dtype=torch.int32), encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' The image contains text in a decorative font. It displays the letter \"A\" repeated twice. The text appears to be in a stylized or ornate typeface, which gives it a visually ornamental quality. The repetition of the letter \"A\" creates an interesting visual pattern or design element.', token_ids=(576, 2168, 5610, 1467, 304, 264, 45436, 3301, 13, 1084, 18689, 279, 6524, 330, 32, 1, 11504, 10917, 13, 576, 1467, 7952, 311, 387, 304, 264, 48204, 1506, 476, 39445, 349, 943, 1564, 11, 892, 6696, 432, 264, 42295, 39445, 43086, 4271, 13, 576, 53415, 315, 279, 6524, 330, 32, 1, 11450, 458, 7040, 9124, 5383, 476, 2884, 2392, 13, 151643), cumulative_logprob=None, logprobs=None, finish_reason=stop, stop_reason=None), CompletionOutput(index=1, text=\" The image shows a screenshot of a smartphone's control center. At the top, there's a search bar with a magnifying glass icon for quickly searching through settings and apps.\\n\\nBelow the search bar, various sections of the control center are visible:\\n\\n1. Weather information:\\n   - Temperature: 26°C (79°F)\\n   - Weather condition: Cloudy with a wind speed of 10 km/h\\n   - Time: 2:50 PM\\n\\n2. Network &\", token_ids=(576, 2168, 4933, 264, 36190, 315, 264, 21511, 594, 2524, 4126, 13, 2411, 279, 1909, 11, 1052, 594, 264, 2711, 3619, 448, 264, 8455, 7766, 8991, 4603, 369, 6157, 15039, 1526, 5003, 323, 10500, 382, 38214, 279, 2711, 3619, 11, 5257, 14158, 315, 279, 2524, 4126, 525, 9434, 1447, 16, 13, 22629, 1995, 510, 256, 481, 37022, 25, 220, 17, 21, 30937, 320, 22, 24, 58472, 340, 256, 481, 22629, 2971, 25, 14817, 88, 448, 264, 9956, 4628, 315, 220, 16, 15, 13136, 7530, 198, 256, 481, 4120, 25, 220, 17, 25, 20, 15, 5851, 271, 17, 13, 8141, 609), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None), CompletionOutput(index=2, text=' The image displays a leaflet for chickenpox prevention. The title at the top reads \"CHICKENPOX.\"\\n\\nBelow the title, there\\'s a simple graphic of a chickenpox virus. The virus is depicted as a large, spiky structure, which is characteristic of the viral particles that cause chickenpox.\\n\\nThe leaflet\\'s design is minimalistic, using primarily black and white colors. It\\'s divided into sections that likely provide essential information about chickenpox, its prevention', token_ids=(576, 2168, 18689, 264, 15933, 1149, 369, 16158, 79, 5131, 26248, 13, 576, 2265, 518, 279, 1909, 15804, 330, 2149, 10685, 953, 2045, 55, 2217, 38214, 279, 2265, 11, 1052, 594, 264, 4285, 20514, 315, 264, 16158, 79, 5131, 16770, 13, 576, 16770, 374, 43794, 438, 264, 3460, 11, 978, 1579, 88, 5944, 11, 892, 374, 28583, 315, 279, 28862, 18730, 429, 5240, 16158, 79, 5131, 382, 785, 15933, 1149, 594, 2884, 374, 17377, 4532, 11, 1667, 15503, 3691, 323, 4158, 7987, 13, 1084, 594, 17779, 1119, 14158, 429, 4363, 3410, 7565, 1995, 911, 16158, 79, 5131, 11, 1181, 26248), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None), CompletionOutput(index=3, text=' The image displays a chart illustrating two popular machine learning models: support vector machines (SVMs) and artificial neural networks. It\\'s titled \"The Final Battle: SVM vs Neural Network.\"\\n\\nSVMs are characterized by their separation of data into different clusters, representing the model\\'s decision boundaries. These models are based on vector cartography and use algorithms like Platt\\'s scaling for classification tasks.\\n\\nArtificial neural networks are depicted as a series of interconnected nodes, symbolizing the complex structure of these models.', token_ids=(576, 2168, 18689, 264, 9487, 92912, 1378, 5411, 5662, 6832, 4119, 25, 1824, 4621, 12645, 320, 50, 11187, 82, 8, 323, 20443, 29728, 14155, 13, 1084, 594, 24849, 330, 785, 13023, 16115, 25, 90009, 6165, 60477, 8141, 2217, 50, 11187, 82, 525, 31871, 553, 862, 24737, 315, 821, 1119, 2155, 26968, 11, 14064, 279, 1614, 594, 5480, 22711, 13, 4220, 4119, 525, 3118, 389, 4621, 7406, 5696, 323, 990, 25185, 1075, 94678, 594, 26943, 369, 23850, 9079, 382, 9286, 16488, 29728, 14155, 525, 43794, 438, 264, 4013, 315, 82316, 7798, 11, 7735, 4849, 279, 6351, 5944, 315, 1493, 4119, 13), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1729975206.9357355, last_token_time=1729975206.9357355, first_scheduled_time=1729975206.942941, first_token_time=1729975207.0506094, time_in_queue=0.007205486297607422, finished_time=1729975209.2237768, scheduler_time=0.009641874261433259, model_forward_time=None, model_execute_time=None), lora_request=None) ----\n",
      "\n",
      " The image contains text in a decorative font. It displays the letter \"A\" repeated twice. The text appears to be in a stylized or ornate typeface, which gives it a visually ornamental quality. The repetition of the letter \"A\" creates an interesting visual pattern or design element.\n",
      "output:  RequestOutput(request_id=4, prompt='Whats the color of this image?', prompt_token_ids=tensor([151643,   2657,     25,  29756,    279,   1894,    315,    419,   2168,\n",
      "            30,  21388,     25], dtype=torch.int32), encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\" The color of this image is primarily green. The central figure is a green robot standing against a green background. There are also darker green elements visible, such as the robot's ears. The robot's left arm and hands feature dark green rectangular pieces, adding depth and detail to the green color scheme. This monochromatic design creates a cohesive and visually striking green palette throughout the image.\", token_ids=(576, 1894, 315, 419, 2168, 374, 15503, 6176, 13, 576, 8622, 7071, 374, 264, 6176, 12305, 11259, 2348, 264, 6176, 4004, 13, 2619, 525, 1083, 39030, 6176, 5424, 9434, 11, 1741, 438, 279, 12305, 594, 24230, 13, 576, 12305, 594, 2115, 6773, 323, 6078, 4565, 6319, 6176, 51424, 9666, 11, 7842, 7990, 323, 7716, 311, 279, 6176, 1894, 12859, 13, 1096, 1615, 4953, 98766, 2884, 11450, 264, 86416, 323, 42295, 21239, 6176, 26308, 6814, 279, 2168, 13, 151643), cumulative_logprob=None, logprobs=None, finish_reason=stop, stop_reason=None), CompletionOutput(index=1, text=' The color palette of this image consists primarily of green, gray, and black. The background is a rich, deep green with hues that shift to a greenish-gray towards the edges, creating a subtle gradient effect. The central element, which appears to be a bush or shrub, is rendered in black. This use of solid black gives the plant form a striking contrast against the varied green tones of the background. The combination of these colors - the predominant green background, the grayish-green edges,', token_ids=(576, 1894, 26308, 315, 419, 2168, 17167, 15503, 315, 6176, 11, 17545, 11, 323, 3691, 13, 576, 4004, 374, 264, 9080, 11, 5538, 6176, 448, 81657, 429, 6407, 311, 264, 6176, 812, 21840, 6974, 279, 12822, 11, 6825, 264, 26447, 20169, 2456, 13, 576, 8622, 2392, 11, 892, 7952, 311, 387, 264, 29673, 476, 14035, 392, 11, 374, 22383, 304, 3691, 13, 1096, 990, 315, 6437, 3691, 6696, 279, 6008, 1352, 264, 21239, 12872, 2348, 279, 27730, 6176, 41976, 315, 279, 4004, 13, 576, 10601, 315, 1493, 7987, 481, 279, 95431, 6176, 4004, 11, 279, 17545, 812, 38268, 12822, 11), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None), CompletionOutput(index=2, text=\" The color palette of this image features several key hues. The predominant colors are various shades of blue, ranging from deep navy to lighter sky blue tones. These create a serene and expansive atmosphere, likely representing the ocean and sky.\\n\\nWhite is also a significant color in the image, present in clouds scattered across the sky and possibly in waves or foam on the water's surface. This provides a striking contrast to the blue tones and adds depth to the scene.\\n\\nAdditionally, there are beige and yellow tones visible.\", token_ids=(576, 1894, 26308, 315, 419, 2168, 4419, 3807, 1376, 81657, 13, 576, 95431, 7987, 525, 5257, 36099, 315, 6303, 11, 23994, 504, 5538, 44774, 311, 29573, 12884, 6303, 41976, 13, 4220, 1855, 264, 94763, 323, 60738, 16566, 11, 4363, 14064, 279, 17951, 323, 12884, 382, 14075, 374, 1083, 264, 5089, 1894, 304, 279, 2168, 11, 3042, 304, 29514, 36967, 3941, 279, 12884, 323, 10767, 304, 16876, 476, 31083, 389, 279, 3015, 594, 7329, 13, 1096, 5707, 264, 21239, 12872, 311, 279, 6303, 41976, 323, 11367, 7990, 311, 279, 6109, 382, 49574, 11, 1052, 525, 78265, 323, 13753, 41976, 9434, 13), cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None), CompletionOutput(index=3, text=' This image contains a mix of colors, primarily showcasing a painting with vibrant hues. The colors present include red, yellow, green, blue, and pink, which create a lively and artistic composition. There are also elements in white, brown, gray, and black that provide contrast and depth to the overall scene. The combination of these colors results in a visually engaging and dynamic image.', token_ids=(1096, 2168, 5610, 264, 6514, 315, 7987, 11, 15503, 66808, 264, 18824, 448, 32976, 81657, 13, 576, 7987, 3042, 2924, 2518, 11, 13753, 11, 6176, 11, 6303, 11, 323, 18217, 11, 892, 1855, 264, 48177, 323, 31592, 18037, 13, 2619, 525, 1083, 5424, 304, 4158, 11, 13876, 11, 17545, 11, 323, 3691, 429, 3410, 12872, 323, 7990, 311, 279, 8084, 6109, 13, 576, 10601, 315, 1493, 7987, 3059, 304, 264, 42295, 22570, 323, 8741, 2168, 13, 151643), cumulative_logprob=None, logprobs=None, finish_reason=stop, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1729975206.9389157, last_token_time=1729975206.9389157, first_scheduled_time=1729975206.942941, first_token_time=1729975207.0506094, time_in_queue=0.00402522087097168, finished_time=1729975209.2237957, scheduler_time=0.009641874261433259, model_forward_time=None, model_execute_time=None), lora_request=None) ----\n",
      "\n",
      " The color of this image is primarily green. The central figure is a green robot standing against a green background. There are also darker green elements visible, such as the robot's ears. The robot's left arm and hands feature dark green rectangular pieces, adding depth and detail to the green color scheme. This monochromatic design creates a cohesive and visually striking green palette throughout the image.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def open_image_from_url(url: str) -> Image.Image:\n",
    "    \"\"\"\n",
    "    Opens an image from a given URL.\n",
    "\n",
    "    Parameters:\n",
    "    url (str): The URL of the image.\n",
    "\n",
    "    Returns:\n",
    "    Image.Image: The opened PIL Image object.\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # Check if the request was successful\n",
    "    return Image.open(BytesIO(response.content))\n",
    "\n",
    "\n",
    "image_1 = open_image_from_url(\"https://picsum.photos/id/237/536/354\",)\n",
    "image_2 = open_image_from_url(\"https://picsum.photos/id/238/536/354\")\n",
    "\n",
    "outputs = llm.generate(\n",
    "    prompts=[\n",
    "        {\n",
    "            \"prompt\": \"Whats the content of this image?\",\n",
    "            \"multi_modal_data\": {\"image_0\": image_1},\n",
    "        },\n",
    "        {\n",
    "            \"prompt\": \"Whats the color of this image?\",\n",
    "            \"multi_modal_data\": {\"image_1\": image_2},\n",
    "        },\n",
    "        {\n",
    "            \"prompt\": \"Whats the color of this image?\",\n",
    "            \"multi_modal_data\": {\"image_1\": [image_1, image_2]},\n",
    "        }\n",
    "    ],\n",
    "    sampling_params=SamplingParams(max_tokens=100, n=4),\n",
    ")\n",
    "\n",
    "for o in outputs:\n",
    "    print(\"output: \", o, \"----\\n\")\n",
    "    generated_text = o.outputs[0].text\n",
    "    print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0484d369-1508-442a-843c-16ced7f620e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
