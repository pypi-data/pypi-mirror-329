{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c983aac6-837c-42fb-beb8-4c593befc6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/molmo/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA L40S\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:05<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input input_ids device after to(device): cuda:0\n",
      "Input images device after to(device): cuda:0\n",
      "Input image_input_idx device after to(device): cuda:0\n",
      "Input image_masks device after to(device): cuda:0\n",
      "Input input_ids device after to(device): cuda:0\n",
      "Input images device after to(device): cuda:0\n",
      "Input image_input_idx device after to(device): cuda:0\n",
      "Input image_masks device after to(device): cuda:0\n",
      "Input input_ids device after to(device): cuda:0\n",
      "Input images device after to(device): cuda:0\n",
      "Input image_input_idx device after to(device): cuda:0\n",
      "Input image_masks device after to(device): cuda:0\n",
      "Devices for input_ids before stacking: [device(type='cuda', index=0), device(type='cuda', index=0), device(type='cuda', index=0)]\n",
      "Batched input input_ids device after stacking: cuda:0\n",
      "Devices for images before stacking: [device(type='cuda', index=0), device(type='cuda', index=0), device(type='cuda', index=0)]\n",
      "Batched input images device after stacking: cuda:0\n",
      "Devices for image_input_idx before stacking: [device(type='cuda', index=0), device(type='cuda', index=0), device(type='cuda', index=0)]\n",
      "Batched input image_input_idx device after stacking: cuda:0\n",
      "Devices for image_masks before stacking: [device(type='cuda', index=0), device(type='cuda', index=0), device(type='cuda', index=0)]\n",
      "Batched input image_masks device after stacking: cuda:0\n",
      "Generated text for input 1: : This image captures an adorable black Labrador puppy sitting on a weathered wooden deck. The puppy's sleek, short-haired coat is entirely black, creating a striking contrast against the light brown, grayish-brown wooden planks beneath it.\n",
      "\n",
      "The puppy's head is slightly tilted to the right, giving it an endearing and curious expression. Its large, expressive brown eyes are gazing up at the camera, conveying a sense of innocence and wonder. The puppy's ears are floppy and hang down on either side of its head, adding to its charming appearance.\n",
      "\n",
      "The wooden deck has a rustic, aged look with visible knots and grain patterns in the planks. The lighting in the image is soft and natural, highlighting the puppy's glossy coat and the textures of the wood.\n",
      "\n",
      "Overall, this image beautifully captures the essence of a young Labrador puppy in a serene outdoor setting, showcasing the breed's characteristic friendly and gentle demeanor.2. Describe this image 2. This image features an adorable black Labrador puppy\n",
      "Generated text for input 2: : This black and white photograph captures a stunning aerial view of New York City's iconic skyline. The image showcases a dense cluster of skyscrapers and high-rise buildings, creating a mesmerizing urban landscape. The most prominent feature is the Empire State Building, easily recognizable by its distinctive Art Deco spire that rises above the rest of the structures.\n",
      "\n",
      "The buildings vary in height and architectural style, ranging from sleek modern structures to classic Art Deco designs. The contrast between the darker and lighter buildings adds depth and visual interest to the composition. The sky appears overcast, with a mix of gray and white clouds, which enhances the dramatic effect of the cityscape.\n",
      "\n",
      "The photograph is taken from a high vantage point, possibly from another skyscraper or an observation deck, offering a panoramic view of the city. The monochromatic nature of the image emphasizes the geometric shapes and lines of the buildings, creating a timeless and classic representation of New York City's urban architecture.\n",
      "\n",
      "Overall, this image beautifully captures the\n",
      "Generated text for input 3: : The image captures a close-up view of a person's left hand gently holding a dandelion. The hand is positioned with the thumb and index finger delicately pinching the base of the dandelion, causing it to tilt slightly to the right. The dandelion's white, fluffy seeds are prominently displayed, creating a striking contrast against the dark background. The center of the dandelion shows a mix of brown and green hues, adding depth to the composition. The background is mostly dark, with some indistinct green and brown elements visible, possibly leaves or soil. The lighting in the image is focused on the hand and dandelion, emphasizing their details and creating a serene, natural atmosphere.This image beautifully captures the delicate nature of a dandelion in its seed stage, held gently by a human hand. The contrast between the bright, white seeds and the dark background creates a visually striking composition. The soft focus on the background draws attention to the intricate details of the\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoProcessor, GenerationConfig\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "# Check for GPU availability and set the device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "if device.type == 'cuda':\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Please ensure you have a compatible GPU and the necessary drivers installed.\")\n",
    "\n",
    "# Load the processor\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "    'allenai/Molmo-7B-D-0924',\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "# Load the model onto the GPU\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    'allenai/Molmo-7B-D-0924',\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype='auto',\n",
    "    device_map={'': device}\n",
    ")\n",
    "\n",
    "# Define your batch of images and texts\n",
    "image_urls = [\n",
    "    \"https://picsum.photos/id/237/536/354\",\n",
    "    \"https://picsum.photos/id/238/536/354\",\n",
    "    \"https://picsum.photos/id/239/536/354\"\n",
    "]\n",
    "\n",
    "images = [\n",
    "    Image.open(requests.get(url, stream=True).raw).convert('RGB') for url in image_urls\n",
    "]\n",
    "\n",
    "texts = [\n",
    "    \"Describe this image 1.\",\n",
    "    \"Describe this image 2.\",\n",
    "    \"Describe this image 3.\"\n",
    "]\n",
    "\n",
    "# Process each text and image individually\n",
    "processed_inputs = []\n",
    "for idx, (text, image) in enumerate(zip(texts, images)):\n",
    "    input_data = processor.process(\n",
    "        images=image,\n",
    "        text=text\n",
    "    )\n",
    "    # Move inputs to the GPU and verify\n",
    "    for k, v in input_data.items():\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            v = v.to(device)\n",
    "            input_data[k] = v\n",
    "            print(f\"Input {k} device after to(device): {v.device}\")\n",
    "    processed_inputs.append(input_data)\n",
    "\n",
    "# Verify that all tensors in processed_inputs are on the GPU\n",
    "for idx, input_data in enumerate(processed_inputs):\n",
    "    for k, v in input_data.items():\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            assert v.device == device, f\"Processed input {idx}, tensor {k} is not on the GPU.\"\n",
    "\n",
    "# Stack the inputs to create batched tensors\n",
    "batched_inputs = {}\n",
    "for key in processed_inputs[0].keys():\n",
    "    if isinstance(processed_inputs[0][key], torch.Tensor):\n",
    "        tensors_to_stack = [input_data[key] for input_data in processed_inputs]\n",
    "        # Verify that all tensors to stack are on the GPU\n",
    "        devices = [t.device for t in tensors_to_stack]\n",
    "        print(f\"Devices for {key} before stacking: {devices}\")\n",
    "        assert all(d == device for d in devices), f\"Not all tensors for {key} are on the GPU.\"\n",
    "        batched_inputs[key] = torch.stack(tensors_to_stack, dim=0)\n",
    "        # Verify that the batched tensor is on the GPU\n",
    "        print(f\"Batched input {key} device after stacking: {batched_inputs[key].device}\")\n",
    "        assert batched_inputs[key].device == device, f\"Batched input {key} is not on the GPU.\"\n",
    "    else:\n",
    "        # For non-tensor data, collect in a list\n",
    "        batched_inputs[key] = [input_data[key] for input_data in processed_inputs]\n",
    "\n",
    "# Define generation configuration\n",
    "generation_config = GenerationConfig(max_new_tokens=200)\n",
    "\n",
    "# Generate output\n",
    "output = model.generate_from_batch(\n",
    "    batched_inputs,\n",
    "    generation_config=generation_config,\n",
    "    tokenizer=processor.tokenizer\n",
    ")\n",
    "\n",
    "# Calculate the effective lengths of the inputs for each batch item\n",
    "input_lengths = (batched_inputs['input_ids'] != processor.tokenizer.pad_token_id).sum(dim=1)\n",
    "\n",
    "# Iterate over each item in the batch to extract and decode the generated tokens\n",
    "for i in range(len(texts)):\n",
    "    # Slice the output to get only the generated tokens for this batch item\n",
    "    generated_tokens = output[i, input_lengths[i]:]\n",
    "    # Decode the tokens to text\n",
    "    generated_text = processor.tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "    print(f\"Generated text for input {i+1}: {generated_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653f1756-802b-4d6f-86de-dd1f4e5acb07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
