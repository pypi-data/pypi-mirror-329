{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f42b7482-e84f-46f1-ae32-39e684e6718a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.cache/pypoetry/virtualenvs/orign-Sz0VPFy2-py3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA L40S\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 11.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input input_ids device after to(device): cuda:0, dtype: torch.int64\n",
      "Input images device after to(device): cuda:0, dtype: torch.float32\n",
      "Input image_input_idx device after to(device): cuda:0, dtype: torch.int32\n",
      "Input image_masks device after to(device): cuda:0, dtype: torch.float32\n",
      "Input input_ids device after to(device): cuda:0, dtype: torch.int64\n",
      "Input images device after to(device): cuda:0, dtype: torch.float32\n",
      "Input image_input_idx device after to(device): cuda:0, dtype: torch.int32\n",
      "Input image_masks device after to(device): cuda:0, dtype: torch.float32\n",
      "Input input_ids device after to(device): cuda:0, dtype: torch.int64\n",
      "Input images device after to(device): cuda:0, dtype: torch.float32\n",
      "Input image_input_idx device after to(device): cuda:0, dtype: torch.int32\n",
      "Input image_masks device after to(device): cuda:0, dtype: torch.float32\n",
      "Processed input 0, tensor input_ids dtype: torch.int64\n",
      "Processed input 0, tensor images dtype: torch.float32\n",
      "Processed input 0, tensor image_input_idx dtype: torch.int32\n",
      "Processed input 0, tensor image_masks dtype: torch.float32\n",
      "Processed input 1, tensor input_ids dtype: torch.int64\n",
      "Processed input 1, tensor images dtype: torch.float32\n",
      "Processed input 1, tensor image_input_idx dtype: torch.int32\n",
      "Processed input 1, tensor image_masks dtype: torch.float32\n",
      "Processed input 2, tensor input_ids dtype: torch.int64\n",
      "Processed input 2, tensor images dtype: torch.float32\n",
      "Processed input 2, tensor image_input_idx dtype: torch.int32\n",
      "Processed input 2, tensor image_masks dtype: torch.float32\n",
      "Devices for input_ids before stacking: [device(type='cuda', index=0), device(type='cuda', index=0), device(type='cuda', index=0)]\n",
      "Batched input input_ids device after stacking: cuda:0\n",
      "Devices for images before stacking: [device(type='cuda', index=0), device(type='cuda', index=0), device(type='cuda', index=0)]\n",
      "Batched input images device after stacking: cuda:0\n",
      "Devices for image_input_idx before stacking: [device(type='cuda', index=0), device(type='cuda', index=0), device(type='cuda', index=0)]\n",
      "Batched input image_input_idx device after stacking: cuda:0\n",
      "Devices for image_masks before stacking: [device(type='cuda', index=0), device(type='cuda', index=0), device(type='cuda', index=0)]\n",
      "Batched input image_masks device after stacking: cuda:0\n",
      "\n",
      "Outputs using generate_from_batch:\n",
      "Generated text for input 1: : This image features an adorable black Labrador puppy sitting on a weathered wooden deck. The puppy's sleek, short fur is entirely black, creating a striking contrast against the light brown, grayish wooden planks beneath it. Its floppy ears frame its face, which is turned upwards with a curious and attentive expression. The puppy's eyes are a warm brown color, and its black nose stands out prominently.\n",
      "\n",
      "The wooden deck shows signs of age and exposure to the elements, with visible cracks and a slightly worn appearance. The puppy is positioned in the center of the frame, sitting on its hind legs with its front paws resting on the wooden surface. Its posture suggests a relaxed yet alert demeanor, as if it's waiting for a command or anticipating something.\n",
      "\n",
      "The lighting in the image is soft and natural, highlighting the puppy's glossy coat and the textures of the wooden deck. The overall composition creates a charming and endearing scene, capturing the innocence and curiosity of the young Labrador in a simple yet captivating setting\n",
      "Generated text for input 2: : This black and white photograph captures a stunning aerial view of New York City's iconic skyline. The image showcases an impressive array of skyscrapers and high-rise buildings, creating a dense urban landscape that stretches as far as the eye can see.\n",
      "\n",
      "The buildings vary in height and architectural style, with some featuring pointed spires while others have flat roofs. The contrast between the darker structures and lighter facades adds depth and visual interest to the composition.\n",
      "\n",
      "In the background, the sky is a light gray, adorned with wispy clouds that enhance the overall atmosphere. The monochromatic nature of the photograph emphasizes the geometric shapes and lines of the buildings, resulting in a striking and timeless representation of one of the world's most recognizable cityscapes.\n",
      "\n",
      "The photograph's perspective, likely taken from a high vantage point such as a helicopter or drone, offers a unique and expansive view of New York's urban planning and architectural achievements. It beautifully captures the essence of the city's vertical growth and its impact on the surrounding\n",
      "Generated text for input 3: : The image showcases a close-up view of a hand gently holding a dandelion in its seed head stage. The dandelion's delicate, white, fluffy seeds are clearly visible, creating a striking contrast against the person's skin. The hand is positioned with the thumb and index finger carefully cradling the dandelion, allowing us to appreciate its intricate structure.\n",
      "\n",
      "The background is dark and out of focus, which emphasizes the dandelion and hand as the main subjects of the photograph. This lighting technique creates a dramatic effect, drawing attention to the ethereal quality of the dandelion's seed head.\n",
      "\n",
      "The composition is simple yet captivating, highlighting the beauty of this common wildflower in its final life stage. The image evokes a sense of delicacy and the transient nature of life, as the seeds prepare to be carried away by the wind.This photograph beautifully captures the intricate details of nature, even in something as seemingly simple as a dandelion.Is there anything specific\n",
      "Initial input_ids shape: torch.Size([3, 327])\n",
      "Initial attention_mask shape: torch.Size([3, 327])\n",
      "Initial position_ids shape: torch.Size([3, 327])\n",
      "\n",
      "=== Generation Step 0 ===\n",
      "Step 0, input_ids shape: torch.Size([3, 327])\n",
      "Step 0, attention_mask shape: torch.Size([3, 327])\n",
      "Step 0, position_ids shape: torch.Size([3, 327])\n",
      "Step 0, position_ids: tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9]], device='cuda:0')\n",
      "Step 0, images shape: torch.Size([3, 2, 576, 588])\n",
      "Step 0, image_masks shape: torch.Size([3, 2, 576])\n",
      "Step 0, image_input_idx shape: torch.Size([3, 2, 144])\n",
      "\n",
      "=== Generation Step 1 ===\n",
      "Step 1, input_ids shape: torch.Size([3, 1])\n",
      "Step 1, attention_mask shape: torch.Size([3, 328])\n",
      "Step 1, position_ids shape: torch.Size([3, 1])\n",
      "Step 1, position_ids: tensor([[11],\n",
      "        [11],\n",
      "        [11]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 2 ===\n",
      "Step 2, input_ids shape: torch.Size([3, 1])\n",
      "Step 2, attention_mask shape: torch.Size([3, 329])\n",
      "Step 2, position_ids shape: torch.Size([3, 1])\n",
      "Step 2, position_ids: tensor([[12],\n",
      "        [12],\n",
      "        [12]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 3 ===\n",
      "Step 3, input_ids shape: torch.Size([3, 1])\n",
      "Step 3, attention_mask shape: torch.Size([3, 330])\n",
      "Step 3, position_ids shape: torch.Size([3, 1])\n",
      "Step 3, position_ids: tensor([[13],\n",
      "        [13],\n",
      "        [13]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 4 ===\n",
      "Step 4, input_ids shape: torch.Size([3, 1])\n",
      "Step 4, attention_mask shape: torch.Size([3, 331])\n",
      "Step 4, position_ids shape: torch.Size([3, 1])\n",
      "Step 4, position_ids: tensor([[14],\n",
      "        [14],\n",
      "        [14]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 5 ===\n",
      "Step 5, input_ids shape: torch.Size([3, 1])\n",
      "Step 5, attention_mask shape: torch.Size([3, 332])\n",
      "Step 5, position_ids shape: torch.Size([3, 1])\n",
      "Step 5, position_ids: tensor([[15],\n",
      "        [15],\n",
      "        [15]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 6 ===\n",
      "Step 6, input_ids shape: torch.Size([3, 1])\n",
      "Step 6, attention_mask shape: torch.Size([3, 333])\n",
      "Step 6, position_ids shape: torch.Size([3, 1])\n",
      "Step 6, position_ids: tensor([[16],\n",
      "        [16],\n",
      "        [16]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 7 ===\n",
      "Step 7, input_ids shape: torch.Size([3, 1])\n",
      "Step 7, attention_mask shape: torch.Size([3, 334])\n",
      "Step 7, position_ids shape: torch.Size([3, 1])\n",
      "Step 7, position_ids: tensor([[17],\n",
      "        [17],\n",
      "        [17]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 8 ===\n",
      "Step 8, input_ids shape: torch.Size([3, 1])\n",
      "Step 8, attention_mask shape: torch.Size([3, 335])\n",
      "Step 8, position_ids shape: torch.Size([3, 1])\n",
      "Step 8, position_ids: tensor([[18],\n",
      "        [18],\n",
      "        [18]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 9 ===\n",
      "Step 9, input_ids shape: torch.Size([3, 1])\n",
      "Step 9, attention_mask shape: torch.Size([3, 336])\n",
      "Step 9, position_ids shape: torch.Size([3, 1])\n",
      "Step 9, position_ids: tensor([[19],\n",
      "        [19],\n",
      "        [19]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 10 ===\n",
      "Step 10, input_ids shape: torch.Size([3, 1])\n",
      "Step 10, attention_mask shape: torch.Size([3, 337])\n",
      "Step 10, position_ids shape: torch.Size([3, 1])\n",
      "Step 10, position_ids: tensor([[20],\n",
      "        [20],\n",
      "        [20]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 11 ===\n",
      "Step 11, input_ids shape: torch.Size([3, 1])\n",
      "Step 11, attention_mask shape: torch.Size([3, 338])\n",
      "Step 11, position_ids shape: torch.Size([3, 1])\n",
      "Step 11, position_ids: tensor([[21],\n",
      "        [21],\n",
      "        [21]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 12 ===\n",
      "Step 12, input_ids shape: torch.Size([3, 1])\n",
      "Step 12, attention_mask shape: torch.Size([3, 339])\n",
      "Step 12, position_ids shape: torch.Size([3, 1])\n",
      "Step 12, position_ids: tensor([[22],\n",
      "        [22],\n",
      "        [22]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 13 ===\n",
      "Step 13, input_ids shape: torch.Size([3, 1])\n",
      "Step 13, attention_mask shape: torch.Size([3, 340])\n",
      "Step 13, position_ids shape: torch.Size([3, 1])\n",
      "Step 13, position_ids: tensor([[23],\n",
      "        [23],\n",
      "        [23]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 14 ===\n",
      "Step 14, input_ids shape: torch.Size([3, 1])\n",
      "Step 14, attention_mask shape: torch.Size([3, 341])\n",
      "Step 14, position_ids shape: torch.Size([3, 1])\n",
      "Step 14, position_ids: tensor([[24],\n",
      "        [24],\n",
      "        [24]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 15 ===\n",
      "Step 15, input_ids shape: torch.Size([3, 1])\n",
      "Step 15, attention_mask shape: torch.Size([3, 342])\n",
      "Step 15, position_ids shape: torch.Size([3, 1])\n",
      "Step 15, position_ids: tensor([[25],\n",
      "        [25],\n",
      "        [25]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 16 ===\n",
      "Step 16, input_ids shape: torch.Size([3, 1])\n",
      "Step 16, attention_mask shape: torch.Size([3, 343])\n",
      "Step 16, position_ids shape: torch.Size([3, 1])\n",
      "Step 16, position_ids: tensor([[26],\n",
      "        [26],\n",
      "        [26]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 17 ===\n",
      "Step 17, input_ids shape: torch.Size([3, 1])\n",
      "Step 17, attention_mask shape: torch.Size([3, 344])\n",
      "Step 17, position_ids shape: torch.Size([3, 1])\n",
      "Step 17, position_ids: tensor([[27],\n",
      "        [27],\n",
      "        [27]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 18 ===\n",
      "Step 18, input_ids shape: torch.Size([3, 1])\n",
      "Step 18, attention_mask shape: torch.Size([3, 345])\n",
      "Step 18, position_ids shape: torch.Size([3, 1])\n",
      "Step 18, position_ids: tensor([[28],\n",
      "        [28],\n",
      "        [28]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 19 ===\n",
      "Step 19, input_ids shape: torch.Size([3, 1])\n",
      "Step 19, attention_mask shape: torch.Size([3, 346])\n",
      "Step 19, position_ids shape: torch.Size([3, 1])\n",
      "Step 19, position_ids: tensor([[29],\n",
      "        [29],\n",
      "        [29]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 20 ===\n",
      "Step 20, input_ids shape: torch.Size([3, 1])\n",
      "Step 20, attention_mask shape: torch.Size([3, 347])\n",
      "Step 20, position_ids shape: torch.Size([3, 1])\n",
      "Step 20, position_ids: tensor([[30],\n",
      "        [30],\n",
      "        [30]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 21 ===\n",
      "Step 21, input_ids shape: torch.Size([3, 1])\n",
      "Step 21, attention_mask shape: torch.Size([3, 348])\n",
      "Step 21, position_ids shape: torch.Size([3, 1])\n",
      "Step 21, position_ids: tensor([[31],\n",
      "        [31],\n",
      "        [31]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 22 ===\n",
      "Step 22, input_ids shape: torch.Size([3, 1])\n",
      "Step 22, attention_mask shape: torch.Size([3, 349])\n",
      "Step 22, position_ids shape: torch.Size([3, 1])\n",
      "Step 22, position_ids: tensor([[32],\n",
      "        [32],\n",
      "        [32]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 23 ===\n",
      "Step 23, input_ids shape: torch.Size([3, 1])\n",
      "Step 23, attention_mask shape: torch.Size([3, 350])\n",
      "Step 23, position_ids shape: torch.Size([3, 1])\n",
      "Step 23, position_ids: tensor([[33],\n",
      "        [33],\n",
      "        [33]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 24 ===\n",
      "Step 24, input_ids shape: torch.Size([3, 1])\n",
      "Step 24, attention_mask shape: torch.Size([3, 351])\n",
      "Step 24, position_ids shape: torch.Size([3, 1])\n",
      "Step 24, position_ids: tensor([[34],\n",
      "        [34],\n",
      "        [34]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 25 ===\n",
      "Step 25, input_ids shape: torch.Size([3, 1])\n",
      "Step 25, attention_mask shape: torch.Size([3, 352])\n",
      "Step 25, position_ids shape: torch.Size([3, 1])\n",
      "Step 25, position_ids: tensor([[35],\n",
      "        [35],\n",
      "        [35]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 26 ===\n",
      "Step 26, input_ids shape: torch.Size([3, 1])\n",
      "Step 26, attention_mask shape: torch.Size([3, 353])\n",
      "Step 26, position_ids shape: torch.Size([3, 1])\n",
      "Step 26, position_ids: tensor([[36],\n",
      "        [36],\n",
      "        [36]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 27 ===\n",
      "Step 27, input_ids shape: torch.Size([3, 1])\n",
      "Step 27, attention_mask shape: torch.Size([3, 354])\n",
      "Step 27, position_ids shape: torch.Size([3, 1])\n",
      "Step 27, position_ids: tensor([[37],\n",
      "        [37],\n",
      "        [37]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 28 ===\n",
      "Step 28, input_ids shape: torch.Size([3, 1])\n",
      "Step 28, attention_mask shape: torch.Size([3, 355])\n",
      "Step 28, position_ids shape: torch.Size([3, 1])\n",
      "Step 28, position_ids: tensor([[38],\n",
      "        [38],\n",
      "        [38]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 29 ===\n",
      "Step 29, input_ids shape: torch.Size([3, 1])\n",
      "Step 29, attention_mask shape: torch.Size([3, 356])\n",
      "Step 29, position_ids shape: torch.Size([3, 1])\n",
      "Step 29, position_ids: tensor([[39],\n",
      "        [39],\n",
      "        [39]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 30 ===\n",
      "Step 30, input_ids shape: torch.Size([3, 1])\n",
      "Step 30, attention_mask shape: torch.Size([3, 357])\n",
      "Step 30, position_ids shape: torch.Size([3, 1])\n",
      "Step 30, position_ids: tensor([[40],\n",
      "        [40],\n",
      "        [40]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 31 ===\n",
      "Step 31, input_ids shape: torch.Size([3, 1])\n",
      "Step 31, attention_mask shape: torch.Size([3, 358])\n",
      "Step 31, position_ids shape: torch.Size([3, 1])\n",
      "Step 31, position_ids: tensor([[41],\n",
      "        [41],\n",
      "        [41]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 32 ===\n",
      "Step 32, input_ids shape: torch.Size([3, 1])\n",
      "Step 32, attention_mask shape: torch.Size([3, 359])\n",
      "Step 32, position_ids shape: torch.Size([3, 1])\n",
      "Step 32, position_ids: tensor([[42],\n",
      "        [42],\n",
      "        [42]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 33 ===\n",
      "Step 33, input_ids shape: torch.Size([3, 1])\n",
      "Step 33, attention_mask shape: torch.Size([3, 360])\n",
      "Step 33, position_ids shape: torch.Size([3, 1])\n",
      "Step 33, position_ids: tensor([[43],\n",
      "        [43],\n",
      "        [43]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 34 ===\n",
      "Step 34, input_ids shape: torch.Size([3, 1])\n",
      "Step 34, attention_mask shape: torch.Size([3, 361])\n",
      "Step 34, position_ids shape: torch.Size([3, 1])\n",
      "Step 34, position_ids: tensor([[44],\n",
      "        [44],\n",
      "        [44]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 35 ===\n",
      "Step 35, input_ids shape: torch.Size([3, 1])\n",
      "Step 35, attention_mask shape: torch.Size([3, 362])\n",
      "Step 35, position_ids shape: torch.Size([3, 1])\n",
      "Step 35, position_ids: tensor([[45],\n",
      "        [45],\n",
      "        [45]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 36 ===\n",
      "Step 36, input_ids shape: torch.Size([3, 1])\n",
      "Step 36, attention_mask shape: torch.Size([3, 363])\n",
      "Step 36, position_ids shape: torch.Size([3, 1])\n",
      "Step 36, position_ids: tensor([[46],\n",
      "        [46],\n",
      "        [46]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 37 ===\n",
      "Step 37, input_ids shape: torch.Size([3, 1])\n",
      "Step 37, attention_mask shape: torch.Size([3, 364])\n",
      "Step 37, position_ids shape: torch.Size([3, 1])\n",
      "Step 37, position_ids: tensor([[47],\n",
      "        [47],\n",
      "        [47]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 38 ===\n",
      "Step 38, input_ids shape: torch.Size([3, 1])\n",
      "Step 38, attention_mask shape: torch.Size([3, 365])\n",
      "Step 38, position_ids shape: torch.Size([3, 1])\n",
      "Step 38, position_ids: tensor([[48],\n",
      "        [48],\n",
      "        [48]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 39 ===\n",
      "Step 39, input_ids shape: torch.Size([3, 1])\n",
      "Step 39, attention_mask shape: torch.Size([3, 366])\n",
      "Step 39, position_ids shape: torch.Size([3, 1])\n",
      "Step 39, position_ids: tensor([[49],\n",
      "        [49],\n",
      "        [49]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 40 ===\n",
      "Step 40, input_ids shape: torch.Size([3, 1])\n",
      "Step 40, attention_mask shape: torch.Size([3, 367])\n",
      "Step 40, position_ids shape: torch.Size([3, 1])\n",
      "Step 40, position_ids: tensor([[50],\n",
      "        [50],\n",
      "        [50]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 41 ===\n",
      "Step 41, input_ids shape: torch.Size([3, 1])\n",
      "Step 41, attention_mask shape: torch.Size([3, 368])\n",
      "Step 41, position_ids shape: torch.Size([3, 1])\n",
      "Step 41, position_ids: tensor([[51],\n",
      "        [51],\n",
      "        [51]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 42 ===\n",
      "Step 42, input_ids shape: torch.Size([3, 1])\n",
      "Step 42, attention_mask shape: torch.Size([3, 369])\n",
      "Step 42, position_ids shape: torch.Size([3, 1])\n",
      "Step 42, position_ids: tensor([[52],\n",
      "        [52],\n",
      "        [52]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 43 ===\n",
      "Step 43, input_ids shape: torch.Size([3, 1])\n",
      "Step 43, attention_mask shape: torch.Size([3, 370])\n",
      "Step 43, position_ids shape: torch.Size([3, 1])\n",
      "Step 43, position_ids: tensor([[53],\n",
      "        [53],\n",
      "        [53]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 44 ===\n",
      "Step 44, input_ids shape: torch.Size([3, 1])\n",
      "Step 44, attention_mask shape: torch.Size([3, 371])\n",
      "Step 44, position_ids shape: torch.Size([3, 1])\n",
      "Step 44, position_ids: tensor([[54],\n",
      "        [54],\n",
      "        [54]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 45 ===\n",
      "Step 45, input_ids shape: torch.Size([3, 1])\n",
      "Step 45, attention_mask shape: torch.Size([3, 372])\n",
      "Step 45, position_ids shape: torch.Size([3, 1])\n",
      "Step 45, position_ids: tensor([[55],\n",
      "        [55],\n",
      "        [55]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 46 ===\n",
      "Step 46, input_ids shape: torch.Size([3, 1])\n",
      "Step 46, attention_mask shape: torch.Size([3, 373])\n",
      "Step 46, position_ids shape: torch.Size([3, 1])\n",
      "Step 46, position_ids: tensor([[56],\n",
      "        [56],\n",
      "        [56]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 47 ===\n",
      "Step 47, input_ids shape: torch.Size([3, 1])\n",
      "Step 47, attention_mask shape: torch.Size([3, 374])\n",
      "Step 47, position_ids shape: torch.Size([3, 1])\n",
      "Step 47, position_ids: tensor([[57],\n",
      "        [57],\n",
      "        [57]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 48 ===\n",
      "Step 48, input_ids shape: torch.Size([3, 1])\n",
      "Step 48, attention_mask shape: torch.Size([3, 375])\n",
      "Step 48, position_ids shape: torch.Size([3, 1])\n",
      "Step 48, position_ids: tensor([[58],\n",
      "        [58],\n",
      "        [58]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 49 ===\n",
      "Step 49, input_ids shape: torch.Size([3, 1])\n",
      "Step 49, attention_mask shape: torch.Size([3, 376])\n",
      "Step 49, position_ids shape: torch.Size([3, 1])\n",
      "Step 49, position_ids: tensor([[59],\n",
      "        [59],\n",
      "        [59]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 50 ===\n",
      "Step 50, input_ids shape: torch.Size([3, 1])\n",
      "Step 50, attention_mask shape: torch.Size([3, 377])\n",
      "Step 50, position_ids shape: torch.Size([3, 1])\n",
      "Step 50, position_ids: tensor([[60],\n",
      "        [60],\n",
      "        [60]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 51 ===\n",
      "Step 51, input_ids shape: torch.Size([3, 1])\n",
      "Step 51, attention_mask shape: torch.Size([3, 378])\n",
      "Step 51, position_ids shape: torch.Size([3, 1])\n",
      "Step 51, position_ids: tensor([[61],\n",
      "        [61],\n",
      "        [61]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 52 ===\n",
      "Step 52, input_ids shape: torch.Size([3, 1])\n",
      "Step 52, attention_mask shape: torch.Size([3, 379])\n",
      "Step 52, position_ids shape: torch.Size([3, 1])\n",
      "Step 52, position_ids: tensor([[62],\n",
      "        [62],\n",
      "        [62]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 53 ===\n",
      "Step 53, input_ids shape: torch.Size([3, 1])\n",
      "Step 53, attention_mask shape: torch.Size([3, 380])\n",
      "Step 53, position_ids shape: torch.Size([3, 1])\n",
      "Step 53, position_ids: tensor([[63],\n",
      "        [63],\n",
      "        [63]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 54 ===\n",
      "Step 54, input_ids shape: torch.Size([3, 1])\n",
      "Step 54, attention_mask shape: torch.Size([3, 381])\n",
      "Step 54, position_ids shape: torch.Size([3, 1])\n",
      "Step 54, position_ids: tensor([[64],\n",
      "        [64],\n",
      "        [64]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 55 ===\n",
      "Step 55, input_ids shape: torch.Size([3, 1])\n",
      "Step 55, attention_mask shape: torch.Size([3, 382])\n",
      "Step 55, position_ids shape: torch.Size([3, 1])\n",
      "Step 55, position_ids: tensor([[65],\n",
      "        [65],\n",
      "        [65]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 56 ===\n",
      "Step 56, input_ids shape: torch.Size([3, 1])\n",
      "Step 56, attention_mask shape: torch.Size([3, 383])\n",
      "Step 56, position_ids shape: torch.Size([3, 1])\n",
      "Step 56, position_ids: tensor([[66],\n",
      "        [66],\n",
      "        [66]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 57 ===\n",
      "Step 57, input_ids shape: torch.Size([3, 1])\n",
      "Step 57, attention_mask shape: torch.Size([3, 384])\n",
      "Step 57, position_ids shape: torch.Size([3, 1])\n",
      "Step 57, position_ids: tensor([[67],\n",
      "        [67],\n",
      "        [67]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 58 ===\n",
      "Step 58, input_ids shape: torch.Size([3, 1])\n",
      "Step 58, attention_mask shape: torch.Size([3, 385])\n",
      "Step 58, position_ids shape: torch.Size([3, 1])\n",
      "Step 58, position_ids: tensor([[68],\n",
      "        [68],\n",
      "        [68]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 59 ===\n",
      "Step 59, input_ids shape: torch.Size([3, 1])\n",
      "Step 59, attention_mask shape: torch.Size([3, 386])\n",
      "Step 59, position_ids shape: torch.Size([3, 1])\n",
      "Step 59, position_ids: tensor([[69],\n",
      "        [69],\n",
      "        [69]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 60 ===\n",
      "Step 60, input_ids shape: torch.Size([3, 1])\n",
      "Step 60, attention_mask shape: torch.Size([3, 387])\n",
      "Step 60, position_ids shape: torch.Size([3, 1])\n",
      "Step 60, position_ids: tensor([[70],\n",
      "        [70],\n",
      "        [70]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 61 ===\n",
      "Step 61, input_ids shape: torch.Size([3, 1])\n",
      "Step 61, attention_mask shape: torch.Size([3, 388])\n",
      "Step 61, position_ids shape: torch.Size([3, 1])\n",
      "Step 61, position_ids: tensor([[71],\n",
      "        [71],\n",
      "        [71]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 62 ===\n",
      "Step 62, input_ids shape: torch.Size([3, 1])\n",
      "Step 62, attention_mask shape: torch.Size([3, 389])\n",
      "Step 62, position_ids shape: torch.Size([3, 1])\n",
      "Step 62, position_ids: tensor([[72],\n",
      "        [72],\n",
      "        [72]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 63 ===\n",
      "Step 63, input_ids shape: torch.Size([3, 1])\n",
      "Step 63, attention_mask shape: torch.Size([3, 390])\n",
      "Step 63, position_ids shape: torch.Size([3, 1])\n",
      "Step 63, position_ids: tensor([[73],\n",
      "        [73],\n",
      "        [73]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 64 ===\n",
      "Step 64, input_ids shape: torch.Size([3, 1])\n",
      "Step 64, attention_mask shape: torch.Size([3, 391])\n",
      "Step 64, position_ids shape: torch.Size([3, 1])\n",
      "Step 64, position_ids: tensor([[74],\n",
      "        [74],\n",
      "        [74]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 65 ===\n",
      "Step 65, input_ids shape: torch.Size([3, 1])\n",
      "Step 65, attention_mask shape: torch.Size([3, 392])\n",
      "Step 65, position_ids shape: torch.Size([3, 1])\n",
      "Step 65, position_ids: tensor([[75],\n",
      "        [75],\n",
      "        [75]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 66 ===\n",
      "Step 66, input_ids shape: torch.Size([3, 1])\n",
      "Step 66, attention_mask shape: torch.Size([3, 393])\n",
      "Step 66, position_ids shape: torch.Size([3, 1])\n",
      "Step 66, position_ids: tensor([[76],\n",
      "        [76],\n",
      "        [76]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 67 ===\n",
      "Step 67, input_ids shape: torch.Size([3, 1])\n",
      "Step 67, attention_mask shape: torch.Size([3, 394])\n",
      "Step 67, position_ids shape: torch.Size([3, 1])\n",
      "Step 67, position_ids: tensor([[77],\n",
      "        [77],\n",
      "        [77]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 68 ===\n",
      "Step 68, input_ids shape: torch.Size([3, 1])\n",
      "Step 68, attention_mask shape: torch.Size([3, 395])\n",
      "Step 68, position_ids shape: torch.Size([3, 1])\n",
      "Step 68, position_ids: tensor([[78],\n",
      "        [78],\n",
      "        [78]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 69 ===\n",
      "Step 69, input_ids shape: torch.Size([3, 1])\n",
      "Step 69, attention_mask shape: torch.Size([3, 396])\n",
      "Step 69, position_ids shape: torch.Size([3, 1])\n",
      "Step 69, position_ids: tensor([[79],\n",
      "        [79],\n",
      "        [79]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 70 ===\n",
      "Step 70, input_ids shape: torch.Size([3, 1])\n",
      "Step 70, attention_mask shape: torch.Size([3, 397])\n",
      "Step 70, position_ids shape: torch.Size([3, 1])\n",
      "Step 70, position_ids: tensor([[80],\n",
      "        [80],\n",
      "        [80]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 71 ===\n",
      "Step 71, input_ids shape: torch.Size([3, 1])\n",
      "Step 71, attention_mask shape: torch.Size([3, 398])\n",
      "Step 71, position_ids shape: torch.Size([3, 1])\n",
      "Step 71, position_ids: tensor([[81],\n",
      "        [81],\n",
      "        [81]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 72 ===\n",
      "Step 72, input_ids shape: torch.Size([3, 1])\n",
      "Step 72, attention_mask shape: torch.Size([3, 399])\n",
      "Step 72, position_ids shape: torch.Size([3, 1])\n",
      "Step 72, position_ids: tensor([[82],\n",
      "        [82],\n",
      "        [82]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 73 ===\n",
      "Step 73, input_ids shape: torch.Size([3, 1])\n",
      "Step 73, attention_mask shape: torch.Size([3, 400])\n",
      "Step 73, position_ids shape: torch.Size([3, 1])\n",
      "Step 73, position_ids: tensor([[83],\n",
      "        [83],\n",
      "        [83]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 74 ===\n",
      "Step 74, input_ids shape: torch.Size([3, 1])\n",
      "Step 74, attention_mask shape: torch.Size([3, 401])\n",
      "Step 74, position_ids shape: torch.Size([3, 1])\n",
      "Step 74, position_ids: tensor([[84],\n",
      "        [84],\n",
      "        [84]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 75 ===\n",
      "Step 75, input_ids shape: torch.Size([3, 1])\n",
      "Step 75, attention_mask shape: torch.Size([3, 402])\n",
      "Step 75, position_ids shape: torch.Size([3, 1])\n",
      "Step 75, position_ids: tensor([[85],\n",
      "        [85],\n",
      "        [85]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 76 ===\n",
      "Step 76, input_ids shape: torch.Size([3, 1])\n",
      "Step 76, attention_mask shape: torch.Size([3, 403])\n",
      "Step 76, position_ids shape: torch.Size([3, 1])\n",
      "Step 76, position_ids: tensor([[86],\n",
      "        [86],\n",
      "        [86]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 77 ===\n",
      "Step 77, input_ids shape: torch.Size([3, 1])\n",
      "Step 77, attention_mask shape: torch.Size([3, 404])\n",
      "Step 77, position_ids shape: torch.Size([3, 1])\n",
      "Step 77, position_ids: tensor([[87],\n",
      "        [87],\n",
      "        [87]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 78 ===\n",
      "Step 78, input_ids shape: torch.Size([3, 1])\n",
      "Step 78, attention_mask shape: torch.Size([3, 405])\n",
      "Step 78, position_ids shape: torch.Size([3, 1])\n",
      "Step 78, position_ids: tensor([[88],\n",
      "        [88],\n",
      "        [88]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 79 ===\n",
      "Step 79, input_ids shape: torch.Size([3, 1])\n",
      "Step 79, attention_mask shape: torch.Size([3, 406])\n",
      "Step 79, position_ids shape: torch.Size([3, 1])\n",
      "Step 79, position_ids: tensor([[89],\n",
      "        [89],\n",
      "        [89]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 80 ===\n",
      "Step 80, input_ids shape: torch.Size([3, 1])\n",
      "Step 80, attention_mask shape: torch.Size([3, 407])\n",
      "Step 80, position_ids shape: torch.Size([3, 1])\n",
      "Step 80, position_ids: tensor([[90],\n",
      "        [90],\n",
      "        [90]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 81 ===\n",
      "Step 81, input_ids shape: torch.Size([3, 1])\n",
      "Step 81, attention_mask shape: torch.Size([3, 408])\n",
      "Step 81, position_ids shape: torch.Size([3, 1])\n",
      "Step 81, position_ids: tensor([[91],\n",
      "        [91],\n",
      "        [91]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 82 ===\n",
      "Step 82, input_ids shape: torch.Size([3, 1])\n",
      "Step 82, attention_mask shape: torch.Size([3, 409])\n",
      "Step 82, position_ids shape: torch.Size([3, 1])\n",
      "Step 82, position_ids: tensor([[92],\n",
      "        [92],\n",
      "        [92]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 83 ===\n",
      "Step 83, input_ids shape: torch.Size([3, 1])\n",
      "Step 83, attention_mask shape: torch.Size([3, 410])\n",
      "Step 83, position_ids shape: torch.Size([3, 1])\n",
      "Step 83, position_ids: tensor([[93],\n",
      "        [93],\n",
      "        [93]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 84 ===\n",
      "Step 84, input_ids shape: torch.Size([3, 1])\n",
      "Step 84, attention_mask shape: torch.Size([3, 411])\n",
      "Step 84, position_ids shape: torch.Size([3, 1])\n",
      "Step 84, position_ids: tensor([[94],\n",
      "        [94],\n",
      "        [94]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 85 ===\n",
      "Step 85, input_ids shape: torch.Size([3, 1])\n",
      "Step 85, attention_mask shape: torch.Size([3, 412])\n",
      "Step 85, position_ids shape: torch.Size([3, 1])\n",
      "Step 85, position_ids: tensor([[95],\n",
      "        [95],\n",
      "        [95]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 86 ===\n",
      "Step 86, input_ids shape: torch.Size([3, 1])\n",
      "Step 86, attention_mask shape: torch.Size([3, 413])\n",
      "Step 86, position_ids shape: torch.Size([3, 1])\n",
      "Step 86, position_ids: tensor([[96],\n",
      "        [96],\n",
      "        [96]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 87 ===\n",
      "Step 87, input_ids shape: torch.Size([3, 1])\n",
      "Step 87, attention_mask shape: torch.Size([3, 414])\n",
      "Step 87, position_ids shape: torch.Size([3, 1])\n",
      "Step 87, position_ids: tensor([[97],\n",
      "        [97],\n",
      "        [97]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 88 ===\n",
      "Step 88, input_ids shape: torch.Size([3, 1])\n",
      "Step 88, attention_mask shape: torch.Size([3, 415])\n",
      "Step 88, position_ids shape: torch.Size([3, 1])\n",
      "Step 88, position_ids: tensor([[98],\n",
      "        [98],\n",
      "        [98]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 89 ===\n",
      "Step 89, input_ids shape: torch.Size([3, 1])\n",
      "Step 89, attention_mask shape: torch.Size([3, 416])\n",
      "Step 89, position_ids shape: torch.Size([3, 1])\n",
      "Step 89, position_ids: tensor([[99],\n",
      "        [99],\n",
      "        [99]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 90 ===\n",
      "Step 90, input_ids shape: torch.Size([3, 1])\n",
      "Step 90, attention_mask shape: torch.Size([3, 417])\n",
      "Step 90, position_ids shape: torch.Size([3, 1])\n",
      "Step 90, position_ids: tensor([[100],\n",
      "        [100],\n",
      "        [100]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 91 ===\n",
      "Step 91, input_ids shape: torch.Size([3, 1])\n",
      "Step 91, attention_mask shape: torch.Size([3, 418])\n",
      "Step 91, position_ids shape: torch.Size([3, 1])\n",
      "Step 91, position_ids: tensor([[101],\n",
      "        [101],\n",
      "        [101]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 92 ===\n",
      "Step 92, input_ids shape: torch.Size([3, 1])\n",
      "Step 92, attention_mask shape: torch.Size([3, 419])\n",
      "Step 92, position_ids shape: torch.Size([3, 1])\n",
      "Step 92, position_ids: tensor([[102],\n",
      "        [102],\n",
      "        [102]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 93 ===\n",
      "Step 93, input_ids shape: torch.Size([3, 1])\n",
      "Step 93, attention_mask shape: torch.Size([3, 420])\n",
      "Step 93, position_ids shape: torch.Size([3, 1])\n",
      "Step 93, position_ids: tensor([[103],\n",
      "        [103],\n",
      "        [103]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 94 ===\n",
      "Step 94, input_ids shape: torch.Size([3, 1])\n",
      "Step 94, attention_mask shape: torch.Size([3, 421])\n",
      "Step 94, position_ids shape: torch.Size([3, 1])\n",
      "Step 94, position_ids: tensor([[104],\n",
      "        [104],\n",
      "        [104]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 95 ===\n",
      "Step 95, input_ids shape: torch.Size([3, 1])\n",
      "Step 95, attention_mask shape: torch.Size([3, 422])\n",
      "Step 95, position_ids shape: torch.Size([3, 1])\n",
      "Step 95, position_ids: tensor([[105],\n",
      "        [105],\n",
      "        [105]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 96 ===\n",
      "Step 96, input_ids shape: torch.Size([3, 1])\n",
      "Step 96, attention_mask shape: torch.Size([3, 423])\n",
      "Step 96, position_ids shape: torch.Size([3, 1])\n",
      "Step 96, position_ids: tensor([[106],\n",
      "        [106],\n",
      "        [106]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 97 ===\n",
      "Step 97, input_ids shape: torch.Size([3, 1])\n",
      "Step 97, attention_mask shape: torch.Size([3, 424])\n",
      "Step 97, position_ids shape: torch.Size([3, 1])\n",
      "Step 97, position_ids: tensor([[107],\n",
      "        [107],\n",
      "        [107]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 98 ===\n",
      "Step 98, input_ids shape: torch.Size([3, 1])\n",
      "Step 98, attention_mask shape: torch.Size([3, 425])\n",
      "Step 98, position_ids shape: torch.Size([3, 1])\n",
      "Step 98, position_ids: tensor([[108],\n",
      "        [108],\n",
      "        [108]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 99 ===\n",
      "Step 99, input_ids shape: torch.Size([3, 1])\n",
      "Step 99, attention_mask shape: torch.Size([3, 426])\n",
      "Step 99, position_ids shape: torch.Size([3, 1])\n",
      "Step 99, position_ids: tensor([[109],\n",
      "        [109],\n",
      "        [109]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 100 ===\n",
      "Step 100, input_ids shape: torch.Size([3, 1])\n",
      "Step 100, attention_mask shape: torch.Size([3, 427])\n",
      "Step 100, position_ids shape: torch.Size([3, 1])\n",
      "Step 100, position_ids: tensor([[110],\n",
      "        [110],\n",
      "        [110]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 101 ===\n",
      "Step 101, input_ids shape: torch.Size([3, 1])\n",
      "Step 101, attention_mask shape: torch.Size([3, 428])\n",
      "Step 101, position_ids shape: torch.Size([3, 1])\n",
      "Step 101, position_ids: tensor([[111],\n",
      "        [111],\n",
      "        [111]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 102 ===\n",
      "Step 102, input_ids shape: torch.Size([3, 1])\n",
      "Step 102, attention_mask shape: torch.Size([3, 429])\n",
      "Step 102, position_ids shape: torch.Size([3, 1])\n",
      "Step 102, position_ids: tensor([[112],\n",
      "        [112],\n",
      "        [112]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 103 ===\n",
      "Step 103, input_ids shape: torch.Size([3, 1])\n",
      "Step 103, attention_mask shape: torch.Size([3, 430])\n",
      "Step 103, position_ids shape: torch.Size([3, 1])\n",
      "Step 103, position_ids: tensor([[113],\n",
      "        [113],\n",
      "        [113]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 104 ===\n",
      "Step 104, input_ids shape: torch.Size([3, 1])\n",
      "Step 104, attention_mask shape: torch.Size([3, 431])\n",
      "Step 104, position_ids shape: torch.Size([3, 1])\n",
      "Step 104, position_ids: tensor([[114],\n",
      "        [114],\n",
      "        [114]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 105 ===\n",
      "Step 105, input_ids shape: torch.Size([3, 1])\n",
      "Step 105, attention_mask shape: torch.Size([3, 432])\n",
      "Step 105, position_ids shape: torch.Size([3, 1])\n",
      "Step 105, position_ids: tensor([[115],\n",
      "        [115],\n",
      "        [115]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 106 ===\n",
      "Step 106, input_ids shape: torch.Size([3, 1])\n",
      "Step 106, attention_mask shape: torch.Size([3, 433])\n",
      "Step 106, position_ids shape: torch.Size([3, 1])\n",
      "Step 106, position_ids: tensor([[116],\n",
      "        [116],\n",
      "        [116]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 107 ===\n",
      "Step 107, input_ids shape: torch.Size([3, 1])\n",
      "Step 107, attention_mask shape: torch.Size([3, 434])\n",
      "Step 107, position_ids shape: torch.Size([3, 1])\n",
      "Step 107, position_ids: tensor([[117],\n",
      "        [117],\n",
      "        [117]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 108 ===\n",
      "Step 108, input_ids shape: torch.Size([3, 1])\n",
      "Step 108, attention_mask shape: torch.Size([3, 435])\n",
      "Step 108, position_ids shape: torch.Size([3, 1])\n",
      "Step 108, position_ids: tensor([[118],\n",
      "        [118],\n",
      "        [118]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 109 ===\n",
      "Step 109, input_ids shape: torch.Size([3, 1])\n",
      "Step 109, attention_mask shape: torch.Size([3, 436])\n",
      "Step 109, position_ids shape: torch.Size([3, 1])\n",
      "Step 109, position_ids: tensor([[119],\n",
      "        [119],\n",
      "        [119]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 110 ===\n",
      "Step 110, input_ids shape: torch.Size([3, 1])\n",
      "Step 110, attention_mask shape: torch.Size([3, 437])\n",
      "Step 110, position_ids shape: torch.Size([3, 1])\n",
      "Step 110, position_ids: tensor([[120],\n",
      "        [120],\n",
      "        [120]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 111 ===\n",
      "Step 111, input_ids shape: torch.Size([3, 1])\n",
      "Step 111, attention_mask shape: torch.Size([3, 438])\n",
      "Step 111, position_ids shape: torch.Size([3, 1])\n",
      "Step 111, position_ids: tensor([[121],\n",
      "        [121],\n",
      "        [121]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 112 ===\n",
      "Step 112, input_ids shape: torch.Size([3, 1])\n",
      "Step 112, attention_mask shape: torch.Size([3, 439])\n",
      "Step 112, position_ids shape: torch.Size([3, 1])\n",
      "Step 112, position_ids: tensor([[122],\n",
      "        [122],\n",
      "        [122]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 113 ===\n",
      "Step 113, input_ids shape: torch.Size([3, 1])\n",
      "Step 113, attention_mask shape: torch.Size([3, 440])\n",
      "Step 113, position_ids shape: torch.Size([3, 1])\n",
      "Step 113, position_ids: tensor([[123],\n",
      "        [123],\n",
      "        [123]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 114 ===\n",
      "Step 114, input_ids shape: torch.Size([3, 1])\n",
      "Step 114, attention_mask shape: torch.Size([3, 441])\n",
      "Step 114, position_ids shape: torch.Size([3, 1])\n",
      "Step 114, position_ids: tensor([[124],\n",
      "        [124],\n",
      "        [124]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 115 ===\n",
      "Step 115, input_ids shape: torch.Size([3, 1])\n",
      "Step 115, attention_mask shape: torch.Size([3, 442])\n",
      "Step 115, position_ids shape: torch.Size([3, 1])\n",
      "Step 115, position_ids: tensor([[125],\n",
      "        [125],\n",
      "        [125]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 116 ===\n",
      "Step 116, input_ids shape: torch.Size([3, 1])\n",
      "Step 116, attention_mask shape: torch.Size([3, 443])\n",
      "Step 116, position_ids shape: torch.Size([3, 1])\n",
      "Step 116, position_ids: tensor([[126],\n",
      "        [126],\n",
      "        [126]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 117 ===\n",
      "Step 117, input_ids shape: torch.Size([3, 1])\n",
      "Step 117, attention_mask shape: torch.Size([3, 444])\n",
      "Step 117, position_ids shape: torch.Size([3, 1])\n",
      "Step 117, position_ids: tensor([[127],\n",
      "        [127],\n",
      "        [127]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 118 ===\n",
      "Step 118, input_ids shape: torch.Size([3, 1])\n",
      "Step 118, attention_mask shape: torch.Size([3, 445])\n",
      "Step 118, position_ids shape: torch.Size([3, 1])\n",
      "Step 118, position_ids: tensor([[128],\n",
      "        [128],\n",
      "        [128]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 119 ===\n",
      "Step 119, input_ids shape: torch.Size([3, 1])\n",
      "Step 119, attention_mask shape: torch.Size([3, 446])\n",
      "Step 119, position_ids shape: torch.Size([3, 1])\n",
      "Step 119, position_ids: tensor([[129],\n",
      "        [129],\n",
      "        [129]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 120 ===\n",
      "Step 120, input_ids shape: torch.Size([3, 1])\n",
      "Step 120, attention_mask shape: torch.Size([3, 447])\n",
      "Step 120, position_ids shape: torch.Size([3, 1])\n",
      "Step 120, position_ids: tensor([[130],\n",
      "        [130],\n",
      "        [130]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 121 ===\n",
      "Step 121, input_ids shape: torch.Size([3, 1])\n",
      "Step 121, attention_mask shape: torch.Size([3, 448])\n",
      "Step 121, position_ids shape: torch.Size([3, 1])\n",
      "Step 121, position_ids: tensor([[131],\n",
      "        [131],\n",
      "        [131]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 122 ===\n",
      "Step 122, input_ids shape: torch.Size([3, 1])\n",
      "Step 122, attention_mask shape: torch.Size([3, 449])\n",
      "Step 122, position_ids shape: torch.Size([3, 1])\n",
      "Step 122, position_ids: tensor([[132],\n",
      "        [132],\n",
      "        [132]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 123 ===\n",
      "Step 123, input_ids shape: torch.Size([3, 1])\n",
      "Step 123, attention_mask shape: torch.Size([3, 450])\n",
      "Step 123, position_ids shape: torch.Size([3, 1])\n",
      "Step 123, position_ids: tensor([[133],\n",
      "        [133],\n",
      "        [133]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 124 ===\n",
      "Step 124, input_ids shape: torch.Size([3, 1])\n",
      "Step 124, attention_mask shape: torch.Size([3, 451])\n",
      "Step 124, position_ids shape: torch.Size([3, 1])\n",
      "Step 124, position_ids: tensor([[134],\n",
      "        [134],\n",
      "        [134]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 125 ===\n",
      "Step 125, input_ids shape: torch.Size([3, 1])\n",
      "Step 125, attention_mask shape: torch.Size([3, 452])\n",
      "Step 125, position_ids shape: torch.Size([3, 1])\n",
      "Step 125, position_ids: tensor([[135],\n",
      "        [135],\n",
      "        [135]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 126 ===\n",
      "Step 126, input_ids shape: torch.Size([3, 1])\n",
      "Step 126, attention_mask shape: torch.Size([3, 453])\n",
      "Step 126, position_ids shape: torch.Size([3, 1])\n",
      "Step 126, position_ids: tensor([[136],\n",
      "        [136],\n",
      "        [136]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 127 ===\n",
      "Step 127, input_ids shape: torch.Size([3, 1])\n",
      "Step 127, attention_mask shape: torch.Size([3, 454])\n",
      "Step 127, position_ids shape: torch.Size([3, 1])\n",
      "Step 127, position_ids: tensor([[137],\n",
      "        [137],\n",
      "        [137]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 128 ===\n",
      "Step 128, input_ids shape: torch.Size([3, 1])\n",
      "Step 128, attention_mask shape: torch.Size([3, 455])\n",
      "Step 128, position_ids shape: torch.Size([3, 1])\n",
      "Step 128, position_ids: tensor([[138],\n",
      "        [138],\n",
      "        [138]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 129 ===\n",
      "Step 129, input_ids shape: torch.Size([3, 1])\n",
      "Step 129, attention_mask shape: torch.Size([3, 456])\n",
      "Step 129, position_ids shape: torch.Size([3, 1])\n",
      "Step 129, position_ids: tensor([[139],\n",
      "        [139],\n",
      "        [139]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 130 ===\n",
      "Step 130, input_ids shape: torch.Size([3, 1])\n",
      "Step 130, attention_mask shape: torch.Size([3, 457])\n",
      "Step 130, position_ids shape: torch.Size([3, 1])\n",
      "Step 130, position_ids: tensor([[140],\n",
      "        [140],\n",
      "        [140]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 131 ===\n",
      "Step 131, input_ids shape: torch.Size([3, 1])\n",
      "Step 131, attention_mask shape: torch.Size([3, 458])\n",
      "Step 131, position_ids shape: torch.Size([3, 1])\n",
      "Step 131, position_ids: tensor([[141],\n",
      "        [141],\n",
      "        [141]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 132 ===\n",
      "Step 132, input_ids shape: torch.Size([3, 1])\n",
      "Step 132, attention_mask shape: torch.Size([3, 459])\n",
      "Step 132, position_ids shape: torch.Size([3, 1])\n",
      "Step 132, position_ids: tensor([[142],\n",
      "        [142],\n",
      "        [142]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 133 ===\n",
      "Step 133, input_ids shape: torch.Size([3, 1])\n",
      "Step 133, attention_mask shape: torch.Size([3, 460])\n",
      "Step 133, position_ids shape: torch.Size([3, 1])\n",
      "Step 133, position_ids: tensor([[143],\n",
      "        [143],\n",
      "        [143]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 134 ===\n",
      "Step 134, input_ids shape: torch.Size([3, 1])\n",
      "Step 134, attention_mask shape: torch.Size([3, 461])\n",
      "Step 134, position_ids shape: torch.Size([3, 1])\n",
      "Step 134, position_ids: tensor([[144],\n",
      "        [144],\n",
      "        [144]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 135 ===\n",
      "Step 135, input_ids shape: torch.Size([3, 1])\n",
      "Step 135, attention_mask shape: torch.Size([3, 462])\n",
      "Step 135, position_ids shape: torch.Size([3, 1])\n",
      "Step 135, position_ids: tensor([[145],\n",
      "        [145],\n",
      "        [145]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 136 ===\n",
      "Step 136, input_ids shape: torch.Size([3, 1])\n",
      "Step 136, attention_mask shape: torch.Size([3, 463])\n",
      "Step 136, position_ids shape: torch.Size([3, 1])\n",
      "Step 136, position_ids: tensor([[146],\n",
      "        [146],\n",
      "        [146]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 137 ===\n",
      "Step 137, input_ids shape: torch.Size([3, 1])\n",
      "Step 137, attention_mask shape: torch.Size([3, 464])\n",
      "Step 137, position_ids shape: torch.Size([3, 1])\n",
      "Step 137, position_ids: tensor([[147],\n",
      "        [147],\n",
      "        [147]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 138 ===\n",
      "Step 138, input_ids shape: torch.Size([3, 1])\n",
      "Step 138, attention_mask shape: torch.Size([3, 465])\n",
      "Step 138, position_ids shape: torch.Size([3, 1])\n",
      "Step 138, position_ids: tensor([[148],\n",
      "        [148],\n",
      "        [148]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 139 ===\n",
      "Step 139, input_ids shape: torch.Size([3, 1])\n",
      "Step 139, attention_mask shape: torch.Size([3, 466])\n",
      "Step 139, position_ids shape: torch.Size([3, 1])\n",
      "Step 139, position_ids: tensor([[149],\n",
      "        [149],\n",
      "        [149]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 140 ===\n",
      "Step 140, input_ids shape: torch.Size([3, 1])\n",
      "Step 140, attention_mask shape: torch.Size([3, 467])\n",
      "Step 140, position_ids shape: torch.Size([3, 1])\n",
      "Step 140, position_ids: tensor([[150],\n",
      "        [150],\n",
      "        [150]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 141 ===\n",
      "Step 141, input_ids shape: torch.Size([3, 1])\n",
      "Step 141, attention_mask shape: torch.Size([3, 468])\n",
      "Step 141, position_ids shape: torch.Size([3, 1])\n",
      "Step 141, position_ids: tensor([[151],\n",
      "        [151],\n",
      "        [151]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 142 ===\n",
      "Step 142, input_ids shape: torch.Size([3, 1])\n",
      "Step 142, attention_mask shape: torch.Size([3, 469])\n",
      "Step 142, position_ids shape: torch.Size([3, 1])\n",
      "Step 142, position_ids: tensor([[152],\n",
      "        [152],\n",
      "        [152]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 143 ===\n",
      "Step 143, input_ids shape: torch.Size([3, 1])\n",
      "Step 143, attention_mask shape: torch.Size([3, 470])\n",
      "Step 143, position_ids shape: torch.Size([3, 1])\n",
      "Step 143, position_ids: tensor([[153],\n",
      "        [153],\n",
      "        [153]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 144 ===\n",
      "Step 144, input_ids shape: torch.Size([3, 1])\n",
      "Step 144, attention_mask shape: torch.Size([3, 471])\n",
      "Step 144, position_ids shape: torch.Size([3, 1])\n",
      "Step 144, position_ids: tensor([[154],\n",
      "        [154],\n",
      "        [154]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 145 ===\n",
      "Step 145, input_ids shape: torch.Size([3, 1])\n",
      "Step 145, attention_mask shape: torch.Size([3, 472])\n",
      "Step 145, position_ids shape: torch.Size([3, 1])\n",
      "Step 145, position_ids: tensor([[155],\n",
      "        [155],\n",
      "        [155]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 146 ===\n",
      "Step 146, input_ids shape: torch.Size([3, 1])\n",
      "Step 146, attention_mask shape: torch.Size([3, 473])\n",
      "Step 146, position_ids shape: torch.Size([3, 1])\n",
      "Step 146, position_ids: tensor([[156],\n",
      "        [156],\n",
      "        [156]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 147 ===\n",
      "Step 147, input_ids shape: torch.Size([3, 1])\n",
      "Step 147, attention_mask shape: torch.Size([3, 474])\n",
      "Step 147, position_ids shape: torch.Size([3, 1])\n",
      "Step 147, position_ids: tensor([[157],\n",
      "        [157],\n",
      "        [157]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 148 ===\n",
      "Step 148, input_ids shape: torch.Size([3, 1])\n",
      "Step 148, attention_mask shape: torch.Size([3, 475])\n",
      "Step 148, position_ids shape: torch.Size([3, 1])\n",
      "Step 148, position_ids: tensor([[158],\n",
      "        [158],\n",
      "        [158]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 149 ===\n",
      "Step 149, input_ids shape: torch.Size([3, 1])\n",
      "Step 149, attention_mask shape: torch.Size([3, 476])\n",
      "Step 149, position_ids shape: torch.Size([3, 1])\n",
      "Step 149, position_ids: tensor([[159],\n",
      "        [159],\n",
      "        [159]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 150 ===\n",
      "Step 150, input_ids shape: torch.Size([3, 1])\n",
      "Step 150, attention_mask shape: torch.Size([3, 477])\n",
      "Step 150, position_ids shape: torch.Size([3, 1])\n",
      "Step 150, position_ids: tensor([[160],\n",
      "        [160],\n",
      "        [160]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 151 ===\n",
      "Step 151, input_ids shape: torch.Size([3, 1])\n",
      "Step 151, attention_mask shape: torch.Size([3, 478])\n",
      "Step 151, position_ids shape: torch.Size([3, 1])\n",
      "Step 151, position_ids: tensor([[161],\n",
      "        [161],\n",
      "        [161]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 152 ===\n",
      "Step 152, input_ids shape: torch.Size([3, 1])\n",
      "Step 152, attention_mask shape: torch.Size([3, 479])\n",
      "Step 152, position_ids shape: torch.Size([3, 1])\n",
      "Step 152, position_ids: tensor([[162],\n",
      "        [162],\n",
      "        [162]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 153 ===\n",
      "Step 153, input_ids shape: torch.Size([3, 1])\n",
      "Step 153, attention_mask shape: torch.Size([3, 480])\n",
      "Step 153, position_ids shape: torch.Size([3, 1])\n",
      "Step 153, position_ids: tensor([[163],\n",
      "        [163],\n",
      "        [163]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 154 ===\n",
      "Step 154, input_ids shape: torch.Size([3, 1])\n",
      "Step 154, attention_mask shape: torch.Size([3, 481])\n",
      "Step 154, position_ids shape: torch.Size([3, 1])\n",
      "Step 154, position_ids: tensor([[164],\n",
      "        [164],\n",
      "        [164]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 155 ===\n",
      "Step 155, input_ids shape: torch.Size([3, 1])\n",
      "Step 155, attention_mask shape: torch.Size([3, 482])\n",
      "Step 155, position_ids shape: torch.Size([3, 1])\n",
      "Step 155, position_ids: tensor([[165],\n",
      "        [165],\n",
      "        [165]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 156 ===\n",
      "Step 156, input_ids shape: torch.Size([3, 1])\n",
      "Step 156, attention_mask shape: torch.Size([3, 483])\n",
      "Step 156, position_ids shape: torch.Size([3, 1])\n",
      "Step 156, position_ids: tensor([[166],\n",
      "        [166],\n",
      "        [166]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 157 ===\n",
      "Step 157, input_ids shape: torch.Size([3, 1])\n",
      "Step 157, attention_mask shape: torch.Size([3, 484])\n",
      "Step 157, position_ids shape: torch.Size([3, 1])\n",
      "Step 157, position_ids: tensor([[167],\n",
      "        [167],\n",
      "        [167]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 158 ===\n",
      "Step 158, input_ids shape: torch.Size([3, 1])\n",
      "Step 158, attention_mask shape: torch.Size([3, 485])\n",
      "Step 158, position_ids shape: torch.Size([3, 1])\n",
      "Step 158, position_ids: tensor([[168],\n",
      "        [168],\n",
      "        [168]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 159 ===\n",
      "Step 159, input_ids shape: torch.Size([3, 1])\n",
      "Step 159, attention_mask shape: torch.Size([3, 486])\n",
      "Step 159, position_ids shape: torch.Size([3, 1])\n",
      "Step 159, position_ids: tensor([[169],\n",
      "        [169],\n",
      "        [169]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 160 ===\n",
      "Step 160, input_ids shape: torch.Size([3, 1])\n",
      "Step 160, attention_mask shape: torch.Size([3, 487])\n",
      "Step 160, position_ids shape: torch.Size([3, 1])\n",
      "Step 160, position_ids: tensor([[170],\n",
      "        [170],\n",
      "        [170]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 161 ===\n",
      "Step 161, input_ids shape: torch.Size([3, 1])\n",
      "Step 161, attention_mask shape: torch.Size([3, 488])\n",
      "Step 161, position_ids shape: torch.Size([3, 1])\n",
      "Step 161, position_ids: tensor([[171],\n",
      "        [171],\n",
      "        [171]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 162 ===\n",
      "Step 162, input_ids shape: torch.Size([3, 1])\n",
      "Step 162, attention_mask shape: torch.Size([3, 489])\n",
      "Step 162, position_ids shape: torch.Size([3, 1])\n",
      "Step 162, position_ids: tensor([[172],\n",
      "        [172],\n",
      "        [172]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 163 ===\n",
      "Step 163, input_ids shape: torch.Size([3, 1])\n",
      "Step 163, attention_mask shape: torch.Size([3, 490])\n",
      "Step 163, position_ids shape: torch.Size([3, 1])\n",
      "Step 163, position_ids: tensor([[173],\n",
      "        [173],\n",
      "        [173]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 164 ===\n",
      "Step 164, input_ids shape: torch.Size([3, 1])\n",
      "Step 164, attention_mask shape: torch.Size([3, 491])\n",
      "Step 164, position_ids shape: torch.Size([3, 1])\n",
      "Step 164, position_ids: tensor([[174],\n",
      "        [174],\n",
      "        [174]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 165 ===\n",
      "Step 165, input_ids shape: torch.Size([3, 1])\n",
      "Step 165, attention_mask shape: torch.Size([3, 492])\n",
      "Step 165, position_ids shape: torch.Size([3, 1])\n",
      "Step 165, position_ids: tensor([[175],\n",
      "        [175],\n",
      "        [175]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 166 ===\n",
      "Step 166, input_ids shape: torch.Size([3, 1])\n",
      "Step 166, attention_mask shape: torch.Size([3, 493])\n",
      "Step 166, position_ids shape: torch.Size([3, 1])\n",
      "Step 166, position_ids: tensor([[176],\n",
      "        [176],\n",
      "        [176]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 167 ===\n",
      "Step 167, input_ids shape: torch.Size([3, 1])\n",
      "Step 167, attention_mask shape: torch.Size([3, 494])\n",
      "Step 167, position_ids shape: torch.Size([3, 1])\n",
      "Step 167, position_ids: tensor([[177],\n",
      "        [177],\n",
      "        [177]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 168 ===\n",
      "Step 168, input_ids shape: torch.Size([3, 1])\n",
      "Step 168, attention_mask shape: torch.Size([3, 495])\n",
      "Step 168, position_ids shape: torch.Size([3, 1])\n",
      "Step 168, position_ids: tensor([[178],\n",
      "        [178],\n",
      "        [178]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 169 ===\n",
      "Step 169, input_ids shape: torch.Size([3, 1])\n",
      "Step 169, attention_mask shape: torch.Size([3, 496])\n",
      "Step 169, position_ids shape: torch.Size([3, 1])\n",
      "Step 169, position_ids: tensor([[179],\n",
      "        [179],\n",
      "        [179]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 170 ===\n",
      "Step 170, input_ids shape: torch.Size([3, 1])\n",
      "Step 170, attention_mask shape: torch.Size([3, 497])\n",
      "Step 170, position_ids shape: torch.Size([3, 1])\n",
      "Step 170, position_ids: tensor([[180],\n",
      "        [180],\n",
      "        [180]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 171 ===\n",
      "Step 171, input_ids shape: torch.Size([3, 1])\n",
      "Step 171, attention_mask shape: torch.Size([3, 498])\n",
      "Step 171, position_ids shape: torch.Size([3, 1])\n",
      "Step 171, position_ids: tensor([[181],\n",
      "        [181],\n",
      "        [181]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 172 ===\n",
      "Step 172, input_ids shape: torch.Size([3, 1])\n",
      "Step 172, attention_mask shape: torch.Size([3, 499])\n",
      "Step 172, position_ids shape: torch.Size([3, 1])\n",
      "Step 172, position_ids: tensor([[182],\n",
      "        [182],\n",
      "        [182]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 173 ===\n",
      "Step 173, input_ids shape: torch.Size([3, 1])\n",
      "Step 173, attention_mask shape: torch.Size([3, 500])\n",
      "Step 173, position_ids shape: torch.Size([3, 1])\n",
      "Step 173, position_ids: tensor([[183],\n",
      "        [183],\n",
      "        [183]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 174 ===\n",
      "Step 174, input_ids shape: torch.Size([3, 1])\n",
      "Step 174, attention_mask shape: torch.Size([3, 501])\n",
      "Step 174, position_ids shape: torch.Size([3, 1])\n",
      "Step 174, position_ids: tensor([[184],\n",
      "        [184],\n",
      "        [184]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 175 ===\n",
      "Step 175, input_ids shape: torch.Size([3, 1])\n",
      "Step 175, attention_mask shape: torch.Size([3, 502])\n",
      "Step 175, position_ids shape: torch.Size([3, 1])\n",
      "Step 175, position_ids: tensor([[185],\n",
      "        [185],\n",
      "        [185]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 176 ===\n",
      "Step 176, input_ids shape: torch.Size([3, 1])\n",
      "Step 176, attention_mask shape: torch.Size([3, 503])\n",
      "Step 176, position_ids shape: torch.Size([3, 1])\n",
      "Step 176, position_ids: tensor([[186],\n",
      "        [186],\n",
      "        [186]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 177 ===\n",
      "Step 177, input_ids shape: torch.Size([3, 1])\n",
      "Step 177, attention_mask shape: torch.Size([3, 504])\n",
      "Step 177, position_ids shape: torch.Size([3, 1])\n",
      "Step 177, position_ids: tensor([[187],\n",
      "        [187],\n",
      "        [187]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 178 ===\n",
      "Step 178, input_ids shape: torch.Size([3, 1])\n",
      "Step 178, attention_mask shape: torch.Size([3, 505])\n",
      "Step 178, position_ids shape: torch.Size([3, 1])\n",
      "Step 178, position_ids: tensor([[188],\n",
      "        [188],\n",
      "        [188]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 179 ===\n",
      "Step 179, input_ids shape: torch.Size([3, 1])\n",
      "Step 179, attention_mask shape: torch.Size([3, 506])\n",
      "Step 179, position_ids shape: torch.Size([3, 1])\n",
      "Step 179, position_ids: tensor([[189],\n",
      "        [189],\n",
      "        [189]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 180 ===\n",
      "Step 180, input_ids shape: torch.Size([3, 1])\n",
      "Step 180, attention_mask shape: torch.Size([3, 507])\n",
      "Step 180, position_ids shape: torch.Size([3, 1])\n",
      "Step 180, position_ids: tensor([[190],\n",
      "        [190],\n",
      "        [190]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 181 ===\n",
      "Step 181, input_ids shape: torch.Size([3, 1])\n",
      "Step 181, attention_mask shape: torch.Size([3, 508])\n",
      "Step 181, position_ids shape: torch.Size([3, 1])\n",
      "Step 181, position_ids: tensor([[191],\n",
      "        [191],\n",
      "        [191]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 182 ===\n",
      "Step 182, input_ids shape: torch.Size([3, 1])\n",
      "Step 182, attention_mask shape: torch.Size([3, 509])\n",
      "Step 182, position_ids shape: torch.Size([3, 1])\n",
      "Step 182, position_ids: tensor([[192],\n",
      "        [192],\n",
      "        [192]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 183 ===\n",
      "Step 183, input_ids shape: torch.Size([3, 1])\n",
      "Step 183, attention_mask shape: torch.Size([3, 510])\n",
      "Step 183, position_ids shape: torch.Size([3, 1])\n",
      "Step 183, position_ids: tensor([[193],\n",
      "        [193],\n",
      "        [193]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 184 ===\n",
      "Step 184, input_ids shape: torch.Size([3, 1])\n",
      "Step 184, attention_mask shape: torch.Size([3, 511])\n",
      "Step 184, position_ids shape: torch.Size([3, 1])\n",
      "Step 184, position_ids: tensor([[194],\n",
      "        [194],\n",
      "        [194]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 185 ===\n",
      "Step 185, input_ids shape: torch.Size([3, 1])\n",
      "Step 185, attention_mask shape: torch.Size([3, 512])\n",
      "Step 185, position_ids shape: torch.Size([3, 1])\n",
      "Step 185, position_ids: tensor([[195],\n",
      "        [195],\n",
      "        [195]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 186 ===\n",
      "Step 186, input_ids shape: torch.Size([3, 1])\n",
      "Step 186, attention_mask shape: torch.Size([3, 513])\n",
      "Step 186, position_ids shape: torch.Size([3, 1])\n",
      "Step 186, position_ids: tensor([[196],\n",
      "        [196],\n",
      "        [196]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 187 ===\n",
      "Step 187, input_ids shape: torch.Size([3, 1])\n",
      "Step 187, attention_mask shape: torch.Size([3, 514])\n",
      "Step 187, position_ids shape: torch.Size([3, 1])\n",
      "Step 187, position_ids: tensor([[197],\n",
      "        [197],\n",
      "        [197]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 188 ===\n",
      "Step 188, input_ids shape: torch.Size([3, 1])\n",
      "Step 188, attention_mask shape: torch.Size([3, 515])\n",
      "Step 188, position_ids shape: torch.Size([3, 1])\n",
      "Step 188, position_ids: tensor([[198],\n",
      "        [198],\n",
      "        [198]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 189 ===\n",
      "Step 189, input_ids shape: torch.Size([3, 1])\n",
      "Step 189, attention_mask shape: torch.Size([3, 516])\n",
      "Step 189, position_ids shape: torch.Size([3, 1])\n",
      "Step 189, position_ids: tensor([[199],\n",
      "        [199],\n",
      "        [199]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 190 ===\n",
      "Step 190, input_ids shape: torch.Size([3, 1])\n",
      "Step 190, attention_mask shape: torch.Size([3, 517])\n",
      "Step 190, position_ids shape: torch.Size([3, 1])\n",
      "Step 190, position_ids: tensor([[200],\n",
      "        [200],\n",
      "        [200]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 191 ===\n",
      "Step 191, input_ids shape: torch.Size([3, 1])\n",
      "Step 191, attention_mask shape: torch.Size([3, 518])\n",
      "Step 191, position_ids shape: torch.Size([3, 1])\n",
      "Step 191, position_ids: tensor([[201],\n",
      "        [201],\n",
      "        [201]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 192 ===\n",
      "Step 192, input_ids shape: torch.Size([3, 1])\n",
      "Step 192, attention_mask shape: torch.Size([3, 519])\n",
      "Step 192, position_ids shape: torch.Size([3, 1])\n",
      "Step 192, position_ids: tensor([[202],\n",
      "        [202],\n",
      "        [202]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 193 ===\n",
      "Step 193, input_ids shape: torch.Size([3, 1])\n",
      "Step 193, attention_mask shape: torch.Size([3, 520])\n",
      "Step 193, position_ids shape: torch.Size([3, 1])\n",
      "Step 193, position_ids: tensor([[203],\n",
      "        [203],\n",
      "        [203]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 194 ===\n",
      "Step 194, input_ids shape: torch.Size([3, 1])\n",
      "Step 194, attention_mask shape: torch.Size([3, 521])\n",
      "Step 194, position_ids shape: torch.Size([3, 1])\n",
      "Step 194, position_ids: tensor([[204],\n",
      "        [204],\n",
      "        [204]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 195 ===\n",
      "Step 195, input_ids shape: torch.Size([3, 1])\n",
      "Step 195, attention_mask shape: torch.Size([3, 522])\n",
      "Step 195, position_ids shape: torch.Size([3, 1])\n",
      "Step 195, position_ids: tensor([[205],\n",
      "        [205],\n",
      "        [205]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 196 ===\n",
      "Step 196, input_ids shape: torch.Size([3, 1])\n",
      "Step 196, attention_mask shape: torch.Size([3, 523])\n",
      "Step 196, position_ids shape: torch.Size([3, 1])\n",
      "Step 196, position_ids: tensor([[206],\n",
      "        [206],\n",
      "        [206]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 197 ===\n",
      "Step 197, input_ids shape: torch.Size([3, 1])\n",
      "Step 197, attention_mask shape: torch.Size([3, 524])\n",
      "Step 197, position_ids shape: torch.Size([3, 1])\n",
      "Step 197, position_ids: tensor([[207],\n",
      "        [207],\n",
      "        [207]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 198 ===\n",
      "Step 198, input_ids shape: torch.Size([3, 1])\n",
      "Step 198, attention_mask shape: torch.Size([3, 525])\n",
      "Step 198, position_ids shape: torch.Size([3, 1])\n",
      "Step 198, position_ids: tensor([[208],\n",
      "        [208],\n",
      "        [208]], device='cuda:0')\n",
      "\n",
      "=== Generation Step 199 ===\n",
      "Step 199, input_ids shape: torch.Size([3, 1])\n",
      "Step 199, attention_mask shape: torch.Size([3, 526])\n",
      "Step 199, position_ids shape: torch.Size([3, 1])\n",
      "Step 199, position_ids: tensor([[209],\n",
      "        [209],\n",
      "        [209]], device='cuda:0')\n",
      "Generated text for input 1:  User: Describe this image 1. Assistant: From the bottom edge of the image and looking up towards the camera, at the bottom edge of the image and looking up towards the camera, at the bottom edge of the image and looking up towards the camera, at the bottom edge of the image and looking up towards the camera, at the bottom edge of the image and looking up towards the camera, at the bottom edge of the image and looking up towards the camera, at the bottom edge of the image and looking up towards the camera, at the bottom edge of the image and looking up towards the camera, at the bottom edge of the image and looking up towards the camera, at the bottom edge of the image and looking up towards the camera, at the bottom edge of the image and looking up towards the camera, at the bottom edge of the image and looking up towards the camera, at the bottom edge of the image and looking up towards the camera, at the bottom edge of the image and looking up towards the camera, at the bottom edge\n",
      "Generated text for input 2:  User: Describe this image 2. Assistant: This image captures a striking black and white aerial view of the New York City skyline. It's a classic photograph showcasing the iconic Manhattan landscape with its tall skyscrapers and towering buildings. The perspective is from high above, looking down on the dense urban landscape.\n",
      "\n",
      "The scene is framed by a cloudy sky, creating a dramatic backdrop for the city's architectural skyline. The skyscrapers vary in height and design, with some featuring pointed spires and others flat roofs. One particularly prominent tall building stands out on the left side of the image, while another tall structure with a pointed top is visible on the right.\n",
      "\n",
      "The black and white medium emphasizes the contrast between the buildings and the sky, giving the image a timeless and somewhat mysterious quality. The monochromatic palette also accentuates the vertical lines of the skyscrapers, creating a powerful visual impact.\n",
      "\n",
      "This aerial view beautifully captures the essence of New York City's dense urban environment and its skyline, showcasing the city's architectural diversity and imposing presence.\n",
      "Generated text for input 3:  User: Describe this image 3. Assistant: A sp\n",
      "密切\n",
      " 此\n",
      "硅胶\n",
      "6.0\n",
      "充电\n",
      "服务\n",
      "目标\n",
      " 小\n",
      "商\n",
      "贸\n",
      "管\n",
      "理\n",
      "培\n",
      "训\n",
      "管\n",
      "理\n",
      "培\n",
      "训\n",
      "管\n",
      "理\n",
      "培\n",
      "训\n",
      "管\n",
      "理\n",
      "培\n",
      "训\n",
      "管\n",
      "理\n",
      "培\n",
      "训\n",
      "管\n",
      "理\n",
      "培\n",
      "训\n",
      "管\n",
      "理\n",
      "培\n",
      "训\n",
      "管\n",
      "理\n",
      "培\n",
      "训\n",
      "管\n",
      "理\n",
      "培\n",
      "训\n",
      "管\n",
      "理\n",
      "培\n",
      "训\n",
      "管\n",
      "理\n",
      "培\n",
      "训\n",
      "管\n",
      "理\n",
      "培\n",
      "训\n",
      "管\n",
      "理\n",
      "培\n",
      "训\n",
      "管\n",
      "理\n",
      "培\n",
      "训\n",
      "管\n",
      "理\n",
      "培\n",
      "训\n",
      "管\n",
      "理\n",
      "培\n",
      "训\n",
      "管\n",
      "理\n",
      "培\n",
      "训\n",
      "管\n",
      "理\n",
      "培\n",
      "训\n",
      "管\n",
      "理\n",
      "培\n",
      "训\n",
      "管\n",
      "理\n",
      "培\n",
      "训\n",
      "管\n",
      "理\n",
      "培\n",
      "训\n",
      "管\n",
      "理\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoProcessor, GenerationConfig\n",
    "from PIL import Image\n",
    "import requests\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# Check for GPU availability and set the device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "if device.type == 'cuda':\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Please ensure you have a compatible GPU and the necessary drivers installed.\")\n",
    "\n",
    "# Load the processor\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "    'allenai/Molmo-7B-D-0924',\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "# Load the model onto the GPU with half-precision\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    'allenai/Molmo-7B-D-0924',\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.float32,\n",
    ").to(device)\n",
    "model.eval()\n",
    "\n",
    "# Define your batch of images and texts\n",
    "image_urls = [\n",
    "    \"https://picsum.photos/id/237/536/354\",\n",
    "    \"https://picsum.photos/id/238/536/354\",\n",
    "    \"https://picsum.photos/id/239/536/354\"\n",
    "]\n",
    "\n",
    "# Load and preprocess images\n",
    "images = []\n",
    "for url in image_urls:\n",
    "    # Load the image\n",
    "    image = Image.open(requests.get(url, stream=True).raw).convert('RGB')\n",
    "    # Resize the image to reduce memory usage\n",
    "    image = image.resize((224, 224))  # Adjust dimensions as needed\n",
    "    images.append(image)\n",
    "\n",
    "texts = [\n",
    "    \"Describe this image 1.\",\n",
    "    \"Describe this image 2.\",\n",
    "    \"Describe this image 3.\"\n",
    "]\n",
    "\n",
    "# Process each text and image individually\n",
    "processed_inputs = []\n",
    "for idx, (text, image) in enumerate(zip(texts, images)):\n",
    "    input_data = processor.process(\n",
    "        images=image,\n",
    "        text=text\n",
    "    )\n",
    "    # Move inputs to the GPU and set dtypes appropriately\n",
    "    for k, v in input_data.items():\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            v = v.to(device)\n",
    "            if v.dtype in [torch.float16, torch.float32]:\n",
    "                v = v.float()  # Ensure FP32 for floating-point tensors\n",
    "            input_data[k] = v\n",
    "            print(f\"Input {k} device after to(device): {v.device}, dtype: {v.dtype}\")\n",
    "    processed_inputs.append(input_data)\n",
    "\n",
    "# Verify that tensors have correct dtypes\n",
    "for idx, input_data in enumerate(processed_inputs):\n",
    "    for k, v in input_data.items():\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            print(f\"Processed input {idx}, tensor {k} dtype: {v.dtype}\")\n",
    "            if k in ['input_ids', 'attention_mask', 'position_ids', 'image_input_idx']:\n",
    "                assert v.dtype in [torch.int32, torch.int64], f\"Tensor {k} should be integer type but is {v.dtype}\"\n",
    "            elif k in ['images', 'image_masks']:\n",
    "                assert v.dtype == torch.float32, f\"Tensor {k} should be float32 but is {v.dtype}\"\n",
    "\n",
    "# Stack the inputs to create batched tensors\n",
    "batched_inputs = {}\n",
    "for key in processed_inputs[0].keys():\n",
    "    if isinstance(processed_inputs[0][key], torch.Tensor):\n",
    "        tensors_to_stack = [input_data[key] for input_data in processed_inputs]\n",
    "        # Verify that all tensors to stack are on the GPU\n",
    "        devices = [t.device for t in tensors_to_stack]\n",
    "        print(f\"Devices for {key} before stacking: {devices}\")\n",
    "        assert all(d == device for d in devices), f\"Not all tensors for {key} are on the GPU.\"\n",
    "        batched_inputs[key] = torch.stack(tensors_to_stack, dim=0)\n",
    "        # Verify that the batched tensor is on the GPU\n",
    "        print(f\"Batched input {key} device after stacking: {batched_inputs[key].device}\")\n",
    "        assert batched_inputs[key].device == device, f\"Batched input {key} is not on the GPU.\"\n",
    "    else:\n",
    "        # For non-tensor data, collect in a list\n",
    "        batched_inputs[key] = [input_data[key] for input_data in processed_inputs]\n",
    "\n",
    "# Define generation configuration\n",
    "generation_config = GenerationConfig(max_new_tokens=200)\n",
    "\n",
    "# ============================================================\n",
    "# Suggestion 1: Verify Model Output Without Iterative Generation\n",
    "# ============================================================\n",
    "\n",
    "# Generate outputs using the standard generate_from_batch method\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate_from_batch(\n",
    "        batched_inputs,\n",
    "        generation_config=generation_config,\n",
    "        tokenizer=processor.tokenizer\n",
    "    )\n",
    "\n",
    "# Calculate the effective lengths of the inputs for each batch item\n",
    "input_lengths = (batched_inputs['input_ids'] != processor.tokenizer.pad_token_id).sum(dim=1)\n",
    "\n",
    "# Iterate over each item in the batch to extract and decode the generated tokens\n",
    "print(\"\\nOutputs using generate_from_batch:\")\n",
    "for i in range(len(texts)):\n",
    "    # Slice the output to get only the generated tokens for this batch item\n",
    "    generated_tokens = outputs[i, input_lengths[i]:]\n",
    "    # Decode the tokens to text\n",
    "    generated_text = processor.tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "    print(f\"Generated text for input {i+1}: {generated_text}\")\n",
    "\n",
    "# ============================================================\n",
    "# Implementing Iterative Generation with Adjustments\n",
    "# ============================================================\n",
    "\n",
    "# Initialize variables for iterative generation\n",
    "input_ids = batched_inputs['input_ids']\n",
    "batch_size, seq_len = input_ids.shape\n",
    "print(f\"Initial input_ids shape: {input_ids.shape}\")\n",
    "\n",
    "# Prepare attention mask\n",
    "attention_mask = batched_inputs.get('attention_mask')\n",
    "if attention_mask is None:\n",
    "    attention_mask = input_ids != processor.tokenizer.pad_token_id\n",
    "print(f\"Initial attention_mask shape: {attention_mask.shape}\")\n",
    "\n",
    "use_position_ids = getattr(model.config, 'use_position_ids', False)\n",
    "if use_position_ids:\n",
    "    # Get the special token IDs for image tokens directly using their string representations\n",
    "    image_token_ids = [\n",
    "        processor.tokenizer.convert_tokens_to_ids(token)\n",
    "        for token in [\"<im_start>\", \"<im_end>\", \"<im_patch>\", \"<im_col>\", \"<|image|>\"]\n",
    "        if token in processor.tokenizer.get_vocab()\n",
    "    ]\n",
    "\n",
    "    # Identify positions of image tokens\n",
    "    image_token_mask = torch.zeros_like(input_ids, dtype=torch.bool)\n",
    "    for token_id in image_token_ids:\n",
    "        image_token_mask |= (input_ids == token_id)\n",
    "\n",
    "    # Compute position_ids, assigning fixed position_ids to image tokens (e.g., 0)\n",
    "    position_ids = torch.zeros_like(input_ids, dtype=torch.long)\n",
    "    text_token_mask = ~image_token_mask & attention_mask.bool()\n",
    "\n",
    "    # Assign incremental position_ids to text tokens\n",
    "    position_ids[text_token_mask] = (torch.cumsum(text_token_mask.to(torch.long), dim=-1) - 1)[text_token_mask]\n",
    "    print(f\"Initial position_ids shape: {position_ids.shape}\")\n",
    "else:\n",
    "    position_ids = None\n",
    "\n",
    "# Extract image-related inputs\n",
    "images = batched_inputs.get('images')\n",
    "image_masks = batched_inputs.get('image_masks')\n",
    "image_input_idx = batched_inputs.get('image_input_idx')\n",
    "append_last_valid_logits = batched_inputs.get('append_last_valid_logits')\n",
    "\n",
    "# Initialize generated sequences\n",
    "generated_sequences = input_ids.clone()\n",
    "\n",
    "# Initialize 'done' flags\n",
    "done = torch.zeros(batch_size, dtype=torch.bool, device=input_ids.device)\n",
    "\n",
    "# Set maximum number of new tokens to generate\n",
    "max_new_tokens = generation_config.max_new_tokens\n",
    "\n",
    "# Set temperature and top_p values\n",
    "temperature = 1.0\n",
    "top_p = 0.9\n",
    "\n",
    "# Initialize past_key_values\n",
    "past_key_values = None\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step in range(max_new_tokens):\n",
    "        print(f\"\\n=== Generation Step {step} ===\")\n",
    "\n",
    "        if past_key_values is None:\n",
    "            # First step\n",
    "            model_inputs = {\n",
    "                'input_ids': input_ids,\n",
    "                'attention_mask': attention_mask,\n",
    "                'position_ids': position_ids,\n",
    "                'images': images,\n",
    "                'image_masks': image_masks,\n",
    "                'image_input_idx': image_input_idx,\n",
    "                'append_last_valid_logits': append_last_valid_logits,\n",
    "                'use_cache': True,\n",
    "            }\n",
    "        else:\n",
    "            # Subsequent steps\n",
    "            # Pass only the last position ID incremented by one\n",
    "            last_position_ids = position_ids[:, -1:] + 1\n",
    "            model_inputs = {\n",
    "                'input_ids': next_tokens.unsqueeze(-1),\n",
    "                'attention_mask': attention_mask,\n",
    "                'position_ids': last_position_ids,\n",
    "                'past_key_values': past_key_values,\n",
    "                'use_cache': True,\n",
    "            }\n",
    "\n",
    "        # Debug statements\n",
    "        print(f\"Step {step}, input_ids shape: {model_inputs['input_ids'].shape}\")\n",
    "        print(f\"Step {step}, attention_mask shape: {model_inputs['attention_mask'].shape}\")\n",
    "        if position_ids is not None:\n",
    "            print(f\"Step {step}, position_ids shape: {model_inputs['position_ids'].shape}\")\n",
    "            print(f\"Step {step}, position_ids: {model_inputs['position_ids']}\")\n",
    "        if images is not None and past_key_values is None:\n",
    "            print(f\"Step {step}, images shape: {images.shape}\")\n",
    "            print(f\"Step {step}, image_masks shape: {image_masks.shape}\")\n",
    "            print(f\"Step {step}, image_input_idx shape: {image_input_idx.shape}\")\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(**model_inputs)\n",
    "        next_token_logits = outputs.logits[:, -1, :]\n",
    "\n",
    "\n",
    "        # Check for NaNs\n",
    "        if torch.isnan(next_token_logits).any() or torch.isinf(next_token_logits).any():\n",
    "            print(f\"Logits contain NaN or Inf values at step {step}\")\n",
    "            break\n",
    "\n",
    "        # Apply temperature\n",
    "        next_token_logits = next_token_logits / temperature\n",
    "\n",
    "        # === Adjusted Top-p Sampling Implementation ===\n",
    "        # Apply top_p sampling\n",
    "        sorted_logits, sorted_indices = torch.sort(next_token_logits, descending=True)\n",
    "        probs = torch.softmax(sorted_logits, dim=-1)\n",
    "        cumulative_probs = torch.cumsum(probs, dim=-1)\n",
    "\n",
    "        # Remove tokens with cumulative probability above top_p\n",
    "        sorted_indices_to_remove = cumulative_probs > top_p\n",
    "\n",
    "        # Ensure at least min_tokens_to_keep tokens are kept\n",
    "        min_tokens_to_keep = 1\n",
    "        sorted_indices_to_remove[:, :min_tokens_to_keep] = False\n",
    "\n",
    "        # Create a mask over the original logits\n",
    "        indices_to_remove = torch.zeros_like(next_token_logits, dtype=torch.bool)\n",
    "        indices_to_remove.scatter_(1, sorted_indices, sorted_indices_to_remove)\n",
    "\n",
    "        # Apply the mask\n",
    "        next_token_logits = next_token_logits.masked_fill(indices_to_remove, -float('inf'))\n",
    "        # === End of Adjusted Section ===\n",
    "\n",
    "        # Sample next token\n",
    "        next_tokens = torch.multinomial(torch.softmax(next_token_logits, dim=-1), num_samples=1).squeeze(-1)\n",
    "\n",
    "        # Append next tokens to generated_sequences\n",
    "        generated_sequences = torch.cat([generated_sequences, next_tokens.unsqueeze(-1)], dim=1)\n",
    "\n",
    "        # Update past_key_values\n",
    "        past_key_values = outputs.past_key_values\n",
    "\n",
    "        # Update input_ids for the next iteration (only last token)\n",
    "        input_ids = next_tokens.unsqueeze(-1)\n",
    "\n",
    "        # Update attention_mask\n",
    "        new_attention_mask = torch.ones((batch_size, 1), dtype=attention_mask.dtype, device=attention_mask.device)\n",
    "        attention_mask = torch.cat([attention_mask, new_attention_mask], dim=1)\n",
    "\n",
    "        # Update position_ids\n",
    "        if use_position_ids:\n",
    "            # For image tokens, position_ids remain the same\n",
    "            last_position_ids = position_ids[:, -1:]\n",
    "            new_position_ids = last_position_ids + 1\n",
    "            position_ids = torch.cat([position_ids, new_position_ids], dim=1)\n",
    "\n",
    "        # Check for EOS token\n",
    "        eos_token_id = processor.tokenizer.eos_token_id or processor.tokenizer.encode(\"</s>\")[0]\n",
    "        done |= next_tokens == eos_token_id\n",
    "\n",
    "        # Break if all sequences are done\n",
    "        if done.all():\n",
    "            print(f\"All sequences are done at step {step}\")\n",
    "            break\n",
    "\n",
    "    # Decode generated sequences\n",
    "    generated_texts = []\n",
    "    for sequence in generated_sequences:\n",
    "        # Remove special tokens if necessary\n",
    "        text = processor.tokenizer.decode(sequence, skip_special_tokens=True)\n",
    "        generated_texts.append(text)\n",
    "\n",
    "    # Print generated texts\n",
    "    for idx, text in enumerate(generated_texts):\n",
    "        print(f\"Generated text for input {idx + 1}: {text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06da7329-73cd-4705-a46a-9e4d8045f047",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
