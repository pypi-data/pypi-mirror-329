2025-02-08 20:06:52,927 - INFO - Starting benchmark script
2025-02-08 20:06:52,927 - INFO - Starting benchmark tests - 3 runs with 30 max concurrent requests
2025-02-08 20:06:52,927 - INFO - Model: gpt-4o-mini
2025-02-08 20:06:52,927 - INFO - Number of prompts per run: 48
2025-02-08 20:06:52,927 - INFO - 
Starting Run 1/3
2025-02-08 20:06:52,927 - INFO - Testing LiteLLM(async)
2025-02-08 20:06:52,929 - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2025-02-08 20:06:52,929 - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2025-02-08 20:06:52,930 - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2025-02-08 20:06:52,930 - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2025-02-08 20:06:52,931 - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2025-02-08 20:06:52,931 - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2025-02-08 20:06:52,932 - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2025-02-08 20:06:52,932 - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2025-02-08 20:06:52,932 - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2025-02-08 20:06:52,932 - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2025-02-08 20:06:52,933 - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2025-02-08 20:06:52,933 - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2025-02-08 20:06:52,933 - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2025-02-08 20:06:52,934 - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2025-02-08 20:06:52,936 - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2025-02-08 20:06:52,936 - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2025-02-08 20:06:52,937 - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2025-02-08 20:06:52,935 - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2025-02-08 20:06:56,360 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-08 20:06:56,383 - INFO - Wrapper: Completed Call, calling success_handler
2025-02-08 20:06:56,384 - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2025-02-08 20:06:56,410 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-08 20:06:56,414 - INFO - Wrapper: Completed Call, calling success_handler
2025-02-08 20:06:56,415 - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2025-02-08 20:06:56,433 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-08 20:06:56,433 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-08 20:06:56,434 - INFO - Wrapper: Completed Call, calling success_handler
2025-02-08 20:06:56,434 - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2025-02-08 20:06:56,437 - INFO - Wrapper: Completed Call, calling success_handler
2025-02-08 20:06:56,437 - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2025-02-08 20:06:56,451 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-08 20:06:56,453 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-08 20:06:56,455 - INFO - Wrapper: Completed Call, calling success_handler
2025-02-08 20:06:56,456 - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2025-02-08 20:06:56,458 - INFO - Wrapper: Completed Call, calling success_handler
2025-02-08 20:06:56,459 - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2025-02-08 20:06:56,499 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-08 20:06:56,500 - INFO - Wrapper: Completed Call, calling success_handler
2025-02-08 20:06:56,500 - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2025-02-08 20:06:56,578 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-08 20:06:56,579 - INFO - Wrapper: Completed Call, calling success_handler
2025-02-08 20:06:56,579 - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2025-02-08 20:06:56,589 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-08 20:06:56,591 - INFO - Wrapper: Completed Call, calling success_handler
2025-02-08 20:06:56,592 - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2025-02-08 20:06:56,611 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-08 20:06:56,618 - INFO - Wrapper: Completed Call, calling success_handler
2025-02-08 20:06:56,619 - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2025-02-08 20:06:56,681 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-08 20:06:56,682 - INFO - Wrapper: Completed Call, calling success_handler
2025-02-08 20:06:56,683 - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2025-02-08 20:06:56,687 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-08 20:06:56,689 - INFO - Wrapper: Completed Call, calling success_handler
2025-02-08 20:06:56,689 - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2025-02-08 20:06:57,082 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-08 20:06:57,085 - INFO - Wrapper: Completed Call, calling success_handler
2025-02-08 20:06:57,087 - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2025-02-08 20:06:57,096 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-08 20:06:57,098 - INFO - Wrapper: Completed Call, calling success_handler
2025-02-08 20:06:57,099 - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2025-02-08 20:06:57,191 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-08 20:06:57,192 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-08 20:06:57,195 - INFO - Wrapper: Completed Call, calling success_handler
2025-02-08 20:06:57,197 - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2025-02-08 20:06:57,201 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-08 20:06:57,202 - INFO - Wrapper: Completed Call, calling success_handler
2025-02-08 20:06:57,203 - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2025-02-08 20:06:57,204 - INFO - Wrapper: Completed Call, calling success_handler
2025-02-08 20:06:57,206 - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2025-02-08 20:06:57,309 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-08 20:06:57,312 - INFO - Wrapper: Completed Call, calling success_handler
2025-02-08 20:06:57,314 - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2025-02-08 20:06:57,400 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-08 20:06:57,435 - INFO - Wrapper: Completed Call, calling success_handler
2025-02-08 20:06:57,438 - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2025-02-08 20:06:57,487 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-08 20:06:57,494 - INFO - Wrapper: Completed Call, calling success_handler
2025-02-08 20:06:57,497 - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2025-02-08 20:06:57,719 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-08 20:06:57,721 - INFO - Wrapper: Completed Call, calling success_handler
2025-02-08 20:06:57,723 - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2025-02-08 20:06:57,844 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-08 20:06:57,847 - INFO - Wrapper: Completed Call, calling success_handler
2025-02-08 20:06:57,849 - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2025-02-08 20:06:57,855 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-08 20:06:57,860 - INFO - Wrapper: Completed Call, calling success_handler
2025-02-08 20:06:57,861 - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2025-02-08 20:06:57,909 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-08 20:06:57,912 - INFO - Wrapper: Completed Call, calling success_handler
2025-02-08 20:06:57,913 - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2025-02-08 20:06:57,932 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-08 20:06:57,935 - INFO - Wrapper: Completed Call, calling success_handler
2025-02-08 20:06:57,936 - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2025-02-08 20:06:57,986 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-08 20:06:57,993 - INFO - Wrapper: Completed Call, calling success_handler
2025-02-08 20:06:57,994 - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2025-02-08 20:06:58,070 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-08 20:06:58,072 - INFO - Wrapper: Completed Call, calling success_handler
2025-02-08 20:06:58,073 - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2025-02-08 20:06:58,365 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-08 20:06:58,367 - INFO - Wrapper: Completed Call, calling success_handler
2025-02-08 20:06:58,369 - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2025-02-08 20:06:58,391 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-08 20:06:58,394 - INFO - Wrapper: Completed Call, calling success_handler
2025-02-08 20:06:58,395 - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2025-02-08 20:06:58,411 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-08 20:06:58,414 - INFO - Wrapper: Completed Call, calling success_handler
2025-02-08 20:06:58,415 - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2025-02-08 20:06:58,464 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-08 20:06:58,482 - INFO - Wrapper: Completed Call, calling success_handler
2025-02-08 20:06:58,490 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-08 20:06:58,492 - INFO - Wrapper: Completed Call, calling success_handler
2025-02-08 20:06:58,559 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-08 20:06:58,559 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-08 20:06:58,560 - INFO - Wrapper: Completed Call, calling success_handler
2025-02-08 20:06:58,563 - INFO - Wrapper: Completed Call, calling success_handler
2025-02-08 20:06:58,623 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-08 20:06:58,624 - INFO - Wrapper: Completed Call, calling success_handler
2025-02-08 20:06:58,654 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-08 20:06:58,655 - INFO - Wrapper: Completed Call, calling success_handler
2025-02-08 20:06:59,079 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-08 20:06:59,082 - INFO - Wrapper: Completed Call, calling success_handler
2025-02-08 20:06:59,143 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-08 20:06:59,148 - INFO - Wrapper: Completed Call, calling success_handler
2025-02-08 20:06:59,198 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-08 20:06:59,199 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-08 20:06:59,202 - INFO - Wrapper: Completed Call, calling success_handler
2025-02-08 20:06:59,205 - INFO - Wrapper: Completed Call, calling success_handler
2025-02-08 20:06:59,795 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-08 20:06:59,798 - INFO - Wrapper: Completed Call, calling success_handler
2025-02-08 20:07:01,670 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-08 20:07:01,673 - INFO - Wrapper: Completed Call, calling success_handler
2025-02-08 20:07:01,758 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-08 20:07:01,776 - INFO - Wrapper: Completed Call, calling success_handler
2025-02-08 20:07:03,579 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-08 20:07:03,588 - INFO - Wrapper: Completed Call, calling success_handler
2025-02-08 20:07:07,176 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-08 20:07:07,179 - INFO - Wrapper: Completed Call, calling success_handler
2025-02-08 20:07:09,065 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-08 20:07:09,075 - INFO - Wrapper: Completed Call, calling success_handler
2025-02-08 20:07:10,512 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-08 20:07:10,531 - INFO - Wrapper: Completed Call, calling success_handler
2025-02-08 20:07:14,101 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-08 20:07:14,104 - INFO - Wrapper: Completed Call, calling success_handler
2025-02-08 20:07:14,107 - INFO - LiteLLM(async) - Run 1 - Time: 21.18s, Memory: 220.44MB
2025-02-08 20:07:14,107 - INFO - Testing Native(aiohttp)
2025-02-08 20:07:32,463 - INFO - Native(aiohttp) - Run 1 - Time: 18.36s, Memory: 225.50MB
2025-02-08 20:07:32,463 - INFO - Testing Bhumi(native)
