# AI Palette ğŸ¨

è½»é‡ä¼˜é›…çš„ç»Ÿä¸€ AI æ¥å£ï¼Œä¸€ä¸ªè°ƒç”¨æ»¡è¶³æ‰€æœ‰éœ€æ±‚ã€‚
æ”¯æŒå¤šç§ä¸»æµ AI æ¨¡å‹ï¼Œå¦‚åŒè°ƒè‰²æ¿ä¸€æ ·ï¼Œéšå¿ƒæ‰€æ¬²åœ°åˆ‡æ¢ä¸åŒçš„ AI æœåŠ¡ã€‚
éå¸¸é€‚åˆåœ¨ Cursor ç­‰ AI IDE ä½œä¸ºä¸Šä¸‹æ–‡ä½¿ç”¨ã€‚

## ğŸŒŸ ä¸ºä»€ä¹ˆé€‰æ‹© AI Palette?

- ğŸ”„ **ç»Ÿä¸€æ¥å£**: ä¸€å¥—ä»£ç é€‚é…å¤šä¸ªå¤§æ¨¡å‹ï¼Œæ— éœ€é‡å¤å¼€å‘
- ğŸ›  **é™ä½æˆæœ¬**: çµæ´»åˆ‡æ¢ä¸åŒæ¨¡å‹ï¼Œä¼˜åŒ–ä½¿ç”¨æˆæœ¬
- ğŸš€ **å¿«é€Ÿæ¥å…¥**: 5åˆ†é’Ÿå³å¯å®Œæˆæ¥å…¥ï¼Œæ”¯æŒæµå¼è¾“å‡º
- ğŸ”Œ **é«˜å¯ç”¨æ€§**: å†…ç½®å®Œå–„çš„é‡è¯•æœºåˆ¶ï¼Œç¡®ä¿æœåŠ¡ç¨³å®šæ€§
- ğŸ¯ **å¼€ç®±å³ç”¨**: ä¸»æµæ¨¡å‹å¼€ç®±å³ç”¨ï¼Œæ¥å£ç»Ÿä¸€è§„èŒƒ

## âœ¨ ç‰¹æ€§

- ğŸ¨ ç»Ÿä¸€ä¼˜é›…çš„æ¥å£è®¾è®¡
- ğŸ’ å•æ–‡ä»¶å®ç°ï¼Œè½»é‡çº§ä¸”æ–¹ä¾¿é›†æˆ
- ğŸŒŠ æ”¯æŒæµå¼è¾“å‡º
- ğŸ”„ å®Œå–„çš„é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
- ğŸ“ ç±»å‹æç¤ºå’Œæ–‡æ¡£å®Œå¤‡
- âš™ï¸ é…ç½®çµæ´»ï¼Œæ”¯æŒç›´æ¥ä¼ å‚å’Œç¯å¢ƒå˜é‡
- ğŸ’¬ æ”¯æŒä¸Šä¸‹æ–‡å¯¹è¯

## ğŸ¯ æ”¯æŒçš„æ¨¡å‹

### OpenAI
- GPT-4 Turbo
- GPT-3.5 Turbo

### ç™¾åº¦æ–‡å¿ƒä¸€è¨€
- ERNIE Bot 4.0
- ERNIE Bot 8K

### é˜¿é‡Œé€šä¹‰åƒé—®
- Qwen Turbo
- Qwen Plus
- Qwen Max

### æ™ºè°± AI
- GLM-4
- GLM-4-32K

### MiniMax
- ABAB-6
- ABAB-5.5

### DeepSeek
- DeepSeek Chat V3
- DeepSeek Chat R1

### ç¡…åŸºæµåŠ¨ï¼š
- DeepSeek-R1 / V3
- Qwen 2.5 (72B/32B/14B/7B)
- Meta Llama 3 (70B/8B)
- Google Gemma 2 (27B/9B)
- InternLM 2.5 (20B/7B)
- Yi 1.5 (34B/9B/6B)
- ChatGLM 4 (9B)

### Ollama (æœ¬åœ°éƒ¨ç½²)
- Llama 2
- Mistral
- CodeLlama
- Gemma
â€¦â€¦


## ğŸš€ å¿«é€Ÿå¼€å§‹

## ğŸ“¦ å®‰è£…

```bash
pip install ai_palette
```

### Web åº”ç”¨

å¯åŠ¨æœåŠ¡å™¨ï¼š
```bash
python -m ai_palette.app
```

æœåŠ¡å™¨å¯åŠ¨åï¼Œè®¿é—® http://127.0.0.1:18000 å³å¯ä½¿ç”¨ã€‚

ä¸»è¦åŠŸèƒ½ï¼š
- æ”¯æŒæ‰€æœ‰å·²é…ç½®æ¨¡å‹çš„åœ¨çº¿å¯¹è¯
- æ”¯æŒæµå¼è¾“å‡º
- æ”¯æŒè‡ªå®šä¹‰ç³»ç»Ÿæç¤ºè¯
- æ”¯æŒæŸ¥çœ‹å¯¹è¯å†å²
- æ”¯æŒå¯¼å‡ºå¯¹è¯è®°å½•

<img src="ai_palette/static/image/web_demo.png" width="600" alt="AI Palette">

### Python API ä½¿ç”¨

```python
from ai_palette import AIChat, Message

# æ–¹å¼1ï¼šç›´æ¥ä¼ å…¥é…ç½®
chat = AIChat(
    provider="openai",  # æ”¯æŒ: openai, ernie, dashscope, zhipu, ollama, minimax, deepseek, siliconflow
    model="gpt-3.5-turbo",
    api_key="your-api-key"
)

# æ–¹å¼2ï¼šä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®
chat = AIChat(provider="openai")  # ä¼šè‡ªåŠ¨è¯»å–å¯¹åº”çš„ç¯å¢ƒå˜é‡ï¼Œå¦‚ OPENAI_API_KEY å’Œ OPENAI_MODEL

# åŸºæœ¬å¯¹è¯
response = chat.ask("ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±")
print(response)

# å¸¦ç³»ç»Ÿæç¤ºè¯çš„å¯¹è¯
chat.add_context("ä½ æ˜¯ä¸€ä¸ªä¸­åŒ»ä¸“å®¶")
response = chat.ask("å¤´ç—›è¯¥æ€ä¹ˆåŠï¼Ÿ")
print(response)

# æµå¼è¾“å‡º
chat = AIChat(provider="openai", enable_streaming=True)
for chunk in chat.ask("è®²ä¸€ä¸ªæ•…äº‹"):
    print(chunk["content"], end="", flush=True)

# ä¸Šä¸‹æ–‡å¯¹è¯
messages = []
messages.append(Message(role="user", content="ä½ å¥½ï¼Œæˆ‘å«å°æ˜"))
response = chat.ask("ä½ å¥½ï¼Œæˆ‘å«å°æ˜", messages=messages)
messages.append(Message(role="assistant", content=response))

messages.append(Message(role="user", content="ä½ è¿˜è®°å¾—æˆ‘çš„åå­—å—ï¼Ÿ"))
response = chat.ask("ä½ è¿˜è®°å¾—æˆ‘çš„åå­—å—ï¼Ÿ", messages=messages)

# ä¸Šä¸‹æ–‡ç®¡ç†
chat = AIChat(provider="openai")

# æ·»åŠ ç³»ç»Ÿæç¤ºè¯ï¼ˆåªèƒ½æ·»åŠ ä¸€ä¸ªï¼‰
chat.add_context("ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„Pythonå¯¼å¸ˆ", role="system")

# æ·»åŠ å¯¹è¯å†å²
chat.add_context("æˆ‘æƒ³å­¦ä¹ Python", role="user")
chat.add_context("å¾ˆå¥½ï¼Œæˆ‘ä»¬å¼€å§‹å§", role="assistant")

# å‘é€æ–°çš„é—®é¢˜
response = chat.ask("æˆ‘åº”è¯¥ä»å“ªé‡Œå¼€å§‹ï¼Ÿ")

# æ¸…é™¤æ™®é€šä¸Šä¸‹æ–‡ï¼Œä¿ç•™ç³»ç»Ÿæç¤ºè¯
chat.clear_context()

# æ¸…é™¤æ‰€æœ‰ä¸Šä¸‹æ–‡ï¼ˆåŒ…æ‹¬ç³»ç»Ÿæç¤ºè¯ï¼‰
chat.clear_context(include_system_prompt=True)
```


## âš™ï¸ ç¯å¢ƒå˜é‡é…ç½®

åˆ›å»º `.env` æ–‡ä»¶ï¼Œå‚è€ƒ `.env.example` è¿›è¡Œé…ç½®ï¼š

```bash
# OpenAI GPT é…ç½®
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxx
OPENAI_MODEL=gpt-3.5-turbo

# æ–‡å¿ƒä¸€è¨€é…ç½®
ERNIE_API_KEY=xxxxxxxxxxxxxxxx
ERNIE_API_SECRET=xxxxxxxxxxxxxxxx
ERNIE_MODEL=ernie-bot-4

# é€šä¹‰åƒé—®é…ç½®
# https://bailian.console.aliyun.com/?apiKey=1
DASHSCOPE_API_KEY=xxxxxxxxxxxxxxxx
DASHSCOPE_MODEL=qwen-max

# ChatGLMé…ç½®
# https://open.bigmodel.cn/usercenter/proj-mgmt/apikeys
ZHIPU_API_KEY=xxxxxxxxxxxxxxxx
ZHIPU_MODEL=glm-4

# Ollamaé…ç½®
OLLAMA_API_URL=http://localhost:11434/api/chat
OLLAMA_MODEL=llama2

# MiniMaxé…ç½®
# https://platform.minimaxi.com/user-center/basic-information/interface-key
MINIMAX_API_KEY=xxxxxxxxxxxxxxxx
MINIMAX_API_SECRET=xxxxxxxxxxxxxxxx
MINIMAX_MODEL=abab5.5-chat

# Deepseeké…ç½®
# https://platform.deepseek.com/
DEEPSEEK_API_KEY=xxxxxxxxxxxxxxxx
DEEPSEEK_MODEL=deepseek-chat

# Siliconflowé…ç½®
SILICONFLOW_API_KEY=xxxxxxxxxxxxxxxx
SILICONFLOW_MODEL=siliconflow-chat
```

## ğŸ¯ é«˜çº§ç”¨æ³•

### Deepseek æ¨¡å‹ä½¿ç”¨

Deepseek æ¨¡å‹å…·æœ‰ç‹¬ç‰¹çš„æ¨ç†èƒ½åŠ›ï¼Œå¯ä»¥å±•ç¤º AI çš„æ€è€ƒè¿‡ç¨‹ï¼š

```python
from ai_palette import AIChat

# åˆ›å»º Deepseek å®ä¾‹
chat = AIChat(
    provider="deepseek",
    model="deepseek-chat",
    enable_streaming=True  # å¯ç”¨æµå¼è¾“å‡º
)

# éæµå¼è¯·æ±‚
response = chat.ask("è§£é‡Šé‡å­çº ç¼ ç°è±¡")
print("å›ç­”:", response)
print("æ¨ç†è¿‡ç¨‹:", chat.get_last_reasoning_content())

# æµå¼è¯·æ±‚
for chunk in chat.ask("ä¸ºä»€ä¹ˆæœˆäº®æ€»æ˜¯åŒä¸€é¢æœå‘åœ°çƒï¼Ÿ"):
    if chunk["type"] == "reasoning":
        print("\n[æ¨ç†è¿‡ç¨‹]", chunk["content"], end="")
    else:  # type == "content"
        print("\n[æœ€ç»ˆç­”æ¡ˆ]", chunk["content"], end="")
```

#### Deepseek API Key è®¾ç½®

æœ‰ä¸‰ç§æ–¹å¼è®¾ç½® Deepseek API Keyï¼š

1. å‘½ä»¤è¡Œå‚æ•°ï¼š
```bash
python test_deepseek.py --api-key YOUR_API_KEY --save
```

2. ç¯å¢ƒå˜é‡ï¼š
```bash
export DEEPSEEK_API_KEY="your-api-key"
```

3. äº¤äº’å¼è¾“å…¥ï¼š
ç›´æ¥è¿è¡Œç¨‹åºï¼Œæ ¹æ®æç¤ºè¾“å…¥ API Keyã€‚

#### Deepseek ç‰¹æœ‰åŠŸèƒ½

- æ¨ç†è¿‡ç¨‹å±•ç¤ºï¼šé€šè¿‡ `get_last_reasoning_content()` è·å– AI çš„æ¨ç†è¿‡ç¨‹
- æµå¼è¾“å‡ºåŒºåˆ†ï¼šæ”¯æŒåŒæ—¶è·å–æ¨ç†è¿‡ç¨‹å’Œæœ€ç»ˆç­”æ¡ˆçš„æµå¼è¾“å‡º
- è¶…æ—¶æ§åˆ¶ï¼šå¯ä»¥æ ¹æ®é—®é¢˜å¤æ‚åº¦è®¾ç½®ä¸åŒçš„è¶…æ—¶æ—¶é—´
  ```python
  # å¤æ‚é—®é¢˜ä½¿ç”¨æ›´é•¿çš„è¶…æ—¶æ—¶é—´
  chat = AIChat(
      provider="deepseek",
      model="deepseek-chat",
      timeout=180  # 3åˆ†é’Ÿè¶…æ—¶
  )
  ```

### é€‰æ‹©æ€§æµ‹è¯•

å¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡é€‰æ‹©è¦æµ‹è¯•çš„æ¨¡å‹ï¼š

```bash
# åªæµ‹è¯•æŒ‡å®šçš„æ¨¡å‹
export TEST_MODELS=openai,deepseek,ollama
python test_ai_palette.py

# æµ‹è¯•æ‰€æœ‰æ¨¡å‹
python test_ai_palette.py
```

### æ¶ˆæ¯å†å²

```python
messages = [
    Message(role="system", content="ä½ æ˜¯ä¸€ä¸ªhelpfulåŠ©æ‰‹"),
    Message(role="user", content="ä»Šå¤©å¤©æ°”çœŸå¥½"),
    Message(role="assistant", content="æ˜¯çš„ï¼Œé˜³å…‰æ˜åªš")
]
response = chat.ask("æˆ‘ä»¬å»æ•£æ­¥å§", messages=messages)
```

### é”™è¯¯é‡è¯•

é»˜è®¤å¯ç”¨æŒ‡æ•°é€€é¿é‡è¯•æœºåˆ¶ï¼š
- æœ€å¤§é‡è¯•æ¬¡æ•°ï¼š3æ¬¡
- åŸºç¡€å»¶è¿Ÿï¼š1ç§’
- æœ€å¤§å»¶è¿Ÿï¼š10ç§’

å¯ä»¥åœ¨åˆ›å»ºå®ä¾‹æ—¶è‡ªå®šä¹‰ï¼š

```python
chat = AIChat(
    provider="openai",
    retry_count=5,  # æœ€å¤§é‡è¯•5æ¬¡
    timeout=60     # è¯·æ±‚è¶…æ—¶æ—¶é—´60ç§’
)
```

### ä¸Šä¸‹æ–‡ç®¡ç†

AI Palette æä¾›äº†çµæ´»çš„ä¸Šä¸‹æ–‡ç®¡ç†åŠŸèƒ½ï¼š

- **ç³»ç»Ÿæç¤ºè¯**: åªèƒ½è®¾ç½®ä¸€ä¸ªï¼Œå§‹ç»ˆä½äºå¯¹è¯æœ€å‰é¢
- **å¯¹è¯å†å²**: å¯ä»¥æ·»åŠ å¤šæ¡ç”¨æˆ·å’ŒåŠ©æ‰‹çš„å¯¹è¯è®°å½•
- **ä¸Šä¸‹æ–‡æ¸…ç†**: æ”¯æŒé€‰æ‹©æ€§æ¸…é™¤æ™®é€šå¯¹è¯æˆ–åŒ…å«ç³»ç»Ÿæç¤ºè¯

```python
# æ·»åŠ ç³»ç»Ÿæç¤ºè¯
chat.add_context("ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„Pythonå¯¼å¸ˆ", role="system")

# æ·»åŠ å¯¹è¯å†å²
chat.add_context("æˆ‘æƒ³å­¦ä¹ Python", role="user")
chat.add_context("å¾ˆå¥½ï¼Œæˆ‘ä»¬å¼€å§‹å§", role="assistant")

# æ¸…é™¤ä¸Šä¸‹æ–‡
chat.clear_context()  # åªæ¸…é™¤æ™®é€šå¯¹è¯
chat.clear_context(include_system_prompt=True)  # æ¸…é™¤æ‰€æœ‰ä¸Šä¸‹æ–‡
```

### æ¨ç†é“¾åŠŸèƒ½

æ¨ç†é“¾å…è®¸ä½ ä½¿ç”¨ä¸¤ä¸ªä¸åŒçš„æ¨¡å‹è¿›è¡Œä¸¤é˜¶æ®µæ¨ç†ï¼šä¸€ä¸ªç”¨äºæ€è€ƒï¼Œä¸€ä¸ªç”¨äºç”Ÿæˆæœ€ç»ˆç»“æœã€‚è¿™å¯¹äºéœ€è¦æ·±åº¦æ€è€ƒå’Œæ¨ç†çš„å¤æ‚ä»»åŠ¡ç‰¹åˆ«æœ‰ç”¨ã€‚

```python
import requests
import json

# æ¨ç†é“¾é…ç½®ç¤ºä¾‹
chain_config = {
    "query": "ä¸ºä»€ä¹ˆå¤©ä¼šä¸‹é›¨ï¼Ÿ",  # ç”¨æˆ·é—®é¢˜
    "enable_streaming": True,     # æ˜¯å¦å¯ç”¨æµå¼è¾“å‡º
    "use_reasoning_field": True,  # True: ä½¿ç”¨ reasoning_content å­—æ®µè¿”å›æ€è€ƒè¿‡ç¨‹
                                 # False: ä½¿ç”¨ <think></think> æ ‡ç­¾åŒ…è£¹æ€è€ƒè¿‡ç¨‹
    "thinkingConfig": {          # æ€è€ƒé˜¶æ®µçš„æ¨¡å‹é…ç½®
        "modelType": "siliconflow",
        "model": "Qwen/Qwen2.5-7B-Instruct",
        "apiKey": "your-api-key"
    },
    "resultConfig": {            # ç»“æœé˜¶æ®µçš„æ¨¡å‹é…ç½®
        "modelType": "siliconflow",
        "model": "Qwen/Qwen2.5-7B-Instruct",
        "apiKey": "your-api-key"
    },
    "thinkingPrompt": "è¿™ä¸ªæ˜¯æ€è€ƒçš„ promptï¼Œ ä¼šåŒ…æ‹¬ [$query$]",
    "resultPrompt": "è¿™ä¸ªæ˜¯ç»“æœï¼Œä¸ä½†åŒ…æ‹¬[$thought$]ï¼Œè¿˜ä¼šåŒ…æ‹¬[$query$]",
    "context": [                 # å¯é€‰çš„ä¸Šä¸‹æ–‡å†å²
        {"role": "user", "content": "ä¹‹å‰çš„é—®é¢˜"},
        {"role": "assistant", "content": "ä¹‹å‰çš„å›ç­”"}
    ]
}

# å‘é€è¯·æ±‚
response = requests.post(
    "http://localhost:18000/api/chain_chat",
    json=chain_config
)

# å¤„ç†éæµå¼å“åº”
if not chain_config["enable_streaming"]:
    result = response.json()
    if result["success"]:
        if chain_config["use_reasoning_field"]:
            print("æ€è€ƒè¿‡ç¨‹:", result["reasoning_content"])
            print("æœ€ç»ˆç­”æ¡ˆ:", result["response"])
        else:
            print("å®Œæ•´å›ç­”:", result["response"])  # åŒ…å« <think></think> æ ‡ç­¾
    else:
        print("é”™è¯¯:", result["error"])

# å¤„ç†æµå¼å“åº”
else:
    for line in response.iter_lines():
        if line:
            line = line.decode('utf-8')
            if line.startswith('data: '):
                data = json.loads(line[6:])
                if data.get("type") == "thinking":
                    print("æ€è€ƒä¸­:", data["content"])
                elif data.get("type") == "content":
                    if chain_config["use_reasoning_field"]:
                        print("æœ€ç»ˆç­”æ¡ˆ:", data["content"])
                        if "reasoning_content" in data:
                            print("æ€è€ƒè¿‡ç¨‹:", data["reasoning_content"])
                    else:
                        print("å®Œæ•´å›ç­”:", data["content"])  # åŒ…å« <think></think> æ ‡ç­¾
```

æ¨ç†é“¾çš„ä¸»è¦ç‰¹ç‚¹ï¼š

- ğŸ”„ **ä¸¤é˜¶æ®µæ¨ç†**: åˆ†åˆ«ä½¿ç”¨æ€è€ƒæ¨¡å‹å’Œç»“æœæ¨¡å‹
- ğŸ¯ **çµæ´»é…ç½®**: å¯ä»¥ä¸ºæ¯ä¸ªé˜¶æ®µé…ç½®ä¸åŒçš„æ¨¡å‹å’Œå‚æ•°
- ğŸ’­ **æ€è€ƒè¿‡ç¨‹**: å¯é€‰æ‹©ä½¿ç”¨å•ç‹¬å­—æ®µæˆ–æ ‡ç­¾å½¢å¼å±•ç¤ºæ€è€ƒè¿‡ç¨‹
- ğŸŒŠ **æµå¼è¾“å‡º**: æ”¯æŒå®æ—¶æŸ¥çœ‹æ€è€ƒå’Œç»“æœçš„ç”Ÿæˆè¿‡ç¨‹
- ğŸ“œ **ä¸Šä¸‹æ–‡æ”¯æŒ**: ä¿æŒå¯¹è¯å†å²ï¼Œè‡ªåŠ¨å¤„ç†æ€è€ƒå†…å®¹

## ğŸ“„ è®¸å¯è¯

MIT 


<img src="ai_palette/static/image/connect.jpg" width="400" alt="AI Palette">
