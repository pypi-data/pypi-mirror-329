Metadata-Version: 2.1
Name: simple-llm-api
Version: 1.0.0
Summary: A simple and easy-to-use LLM API Wrapper
Home-page: https://github.com/SoAp9035/simple-llm-api
Author: Ahmet Burhan Kayalƒ±
Author-email: ahmetburhan1703@gmail.com
Keywords: simple,llm,openai,mistral,gemini,api,wrapper
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Science/Research
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Classifier: Topic :: Internet :: WWW/HTTP
Classifier: License :: OSI Approved :: MIT License
Description-Content-Type: text/markdown
Requires-Dist: requests

# Simple LLM API

A simple and easy-to-use Python wrapper for popular LLM APIs (OpenAI, Mistral, Google Gemini).

## Installation

```bash
pip install simple-llm-api
```

## Features

- üéØ Simple and consistent interface for multiple LLM providers
- ü§ñ Support for OpenAI, Mistral, and Google Gemini APIs
- üöÄ Easy to use with minimal configuration
- ‚öôÔ∏è Customizable parameters for each provider

## Quick Start

### OpenAI

```python
from simple_llm_api import OpenAIAPI

openai = OpenAIAPI("YOUR_API_KEY")
response = openai.simple_request("Hi!")
print(response)
```

### Mistral

```python
from simple_llm_api import MistralAPI

mistral = MistralAPI("YOUR_API_KEY")
response = mistral.simple_request("Hi!")
print(response)
```

### Google Gemini

```python
from simple_llm_api import GeminiAPI

gemini = GeminiAPI("YOUR_API_KEY")
response = gemini.simple_request("Hi!")
print(response)
```

## Advanced Usage

Each API wrapper supports various parameters for fine-tuning the response:

### OpenAI
```python
openai.simple_request(
    user_prompt="Your prompt here",
    system_prompt="Custom system prompt",
    temperature=0.7,
    top_p=0.9,
    max_completion_tokens=2048
)
```

### Mistral
```python
mistral.simple_request(
    user_prompt="Your prompt here",
    system_prompt="Custom system prompt",
    temperature=0.7,
    top_p=0.9,
    max_tokens=2048
)
```

### Gemini
```python
gemini.simple_request(
    user_prompt="Your prompt here",
    system_prompt="Custom system prompt",
    temperature=0.7,
    top_k=40,
    top_p=0.9,
    max_output_tokens=2048
)
```

## Error Handling

The library includes custom exceptions for each API:

- `GeminiError`: GeminiAPI Error
- `MistralError`: MistralError Error
- `OpenAIError`: OpenAIError Error

## Requirements

- requests

## License

This project is licensed under the [MIT](https://choosealicense.com/licenses/mit/) License.

## Links

- [GitHub Repository](https://github.com/SoAp9035/simple-llm-api)
- [PyPI Package](https://pypi.org/project/simple-llm-api/)
