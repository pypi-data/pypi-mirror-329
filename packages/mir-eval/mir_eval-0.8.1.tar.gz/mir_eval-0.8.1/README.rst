.. image:: https://anaconda.org/conda-forge/mir_eval/badges/version.svg 
    :target: https://anaconda.org/conda-forge/mir_eval

.. image:: https://img.shields.io/pypi/v/mir_eval.svg
    :target: https://pypi.python.org/pypi/mir_eval

.. image:: https://github.com/mir-evaluation/mir_eval/actions/workflows/test.yml/badge.svg
    :target: https://github.com/mir-evaluation/mir_eval/actions/workflows/test.yml

.. image:: https://codecov.io/gh/mir-evaluation/mir_eval/graph/badge.svg?token=OzRL3aW7TX 
    :target: https://codecov.io/gh/mir-evaluation/mir_eval

.. image:: https://img.shields.io/pypi/l/mir_eval.svg
    :target: https://github.com/mir-evaluation/mir_eval/blob/main/LICENSE.txt


mir_eval
========

Python library for computing common heuristic accuracy scores for various music/audio information retrieval/signal processing tasks.

Documentation, including installation and usage information: https://mir-evaluation.github.io/mir_eval/

Dependencies:

* `Scipy/Numpy <http://www.scipy.org/>`_
* `decorator <https://github.com/micheles/decorator>`_

If you use mir_eval in a research project, please cite the following paper:

Colin Raffel, Brian McFee, Eric J. Humphrey, Justin Salamon, Oriol Nieto, Dawen Liang, and Daniel P. W. Ellis, "`mir_eval: A Transparent Implementation of Common MIR Metrics <http://colinraffel.com/publications/ismir2014mir_eval.pdf>`_", Proceedings of the 15th International Conference on Music Information Retrieval, 2014.


