{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Iterable, Optional, TypedDict\n",
    "from polaroids import DataFrame, Field\n",
    "from polaroids.dataframe import _Metadata\n",
    "import polars as pl\n",
    "from polaroids import _utils\n",
    "\n",
    "from typing import Annotated, TypedDict\n",
    "from polaroids import DataFrame, Field\n",
    "from polaroids.types import int32, float64\n",
    "import polars as pl\n",
    "\n",
    "class Schema(TypedDict):\n",
    "    a: Annotated[list[int32 | None], Field()]\n",
    "    b: Annotated[list[list[bool]], Field()]\n",
    "    c: Annotated[list[int] | None, Field()]\n",
    "    d: Optional[int]\n",
    "    e: int32 | None\n",
    "    f: int | None\n",
    "\n",
    "# _utils.typeddict_to_polats_schema(Schema)\n",
    "\n",
    "\n",
    "raw = (\n",
    "    pl.DataFrame({\"a\": [0.0, 1.0], \"b\": [None, 0]})\n",
    "    .pipe(DataFrame[Schema])\n",
    ")\n",
    "# df = (\n",
    "#     raw\n",
    "#     .sort(\"a\")\n",
    "#      # <- Add a Schema to your dataframe\n",
    "#     # .select(pl.all())\n",
    "#     .validate()\n",
    "#     # .rows()\n",
    "#     # .sort(\"a\")\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from polaroids._parse_types import typeddict_to_polats_schema\n",
    "\n",
    "class SubSchema(TypedDict):\n",
    "    a: int\n",
    "    b: str\n",
    "\n",
    "class Schema(TypedDict):\n",
    "    a: Annotated[list[int32 | None], Field()]\n",
    "    b: Annotated[list[list[bool]], Field()]\n",
    "    c: Annotated[list[int] | None, Field()]\n",
    "    d: Optional[int]\n",
    "    e: int32 | None\n",
    "    f: int | None\n",
    "    g: Literal[\"a\", \"b\"]\n",
    "    h: list[Literal[\"a\", \"b\"] | None]\n",
    "\n",
    "expected = pl.Schema({\n",
    "    \"a\": pl.List(pl.Int32),\n",
    "    \"b\": pl.List(pl.List(pl.Boolean)),\n",
    "    \"c\": pl.List(pl.Int64),\n",
    "    \"d\": pl.Int64,\n",
    "    \"e\": pl.Int32,\n",
    "    \"f\": pl.Int64,\n",
    "    \"g\": pl.Enum([\"a\", \"b\"]),\n",
    "    \"h\": pl.List(pl.Enum([\"a\", \"b\"])),\n",
    "}) \n",
    "assert expected == typeddict_to_polats_schema(Schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubSchema(TypedDict):\n",
    "    a: int\n",
    "    b: str\n",
    "\n",
    "class Schema(TypedDict):\n",
    "    s: list[SubSchema]\n",
    "    t: int\n",
    "\n",
    "expected = pl.Schema([('s', pl.List(pl.Struct({'a': pl.Int64, 'b': pl.String}))), ('t', pl.Int64)])\n",
    "assert expected == typeddict_to_polats_schema(Schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 3)\n",
      "â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ a   â”† b    â”† s                   â”‚\n",
      "â”‚ --- â”† ---  â”† ---                 â”‚\n",
      "â”‚ i64 â”† i64  â”† struct[2]           â”‚\n",
      "â•žâ•â•â•â•â•â•ªâ•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 0   â”† null â”† {[true],\"0\"}        â”‚\n",
      "â”‚ 1   â”† 0    â”† {[true, false],\"1\"} â”‚\n",
      "â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
     ]
    }
   ],
   "source": [
    "from gc import set_debug\n",
    "from typing import Annotated, TypedDict\n",
    "from polaroids import DataFrame, Field\n",
    "import polars as pl\n",
    "\n",
    "class SubSchema(TypedDict):\n",
    "    c: list[bool]\n",
    "    d: str\n",
    "\n",
    "class Schema(TypedDict):\n",
    "    a: Annotated[int, Field(\n",
    "        sorted=\"ascending\",\n",
    "        coerce=True,\n",
    "        unique=True,\n",
    "        checks=[lambda d: d.ge(0)],\n",
    "    )]\n",
    "    b: int | None\n",
    "    s: SubSchema\n",
    "\n",
    "df = (\n",
    "    pl.DataFrame({\n",
    "        \"a\": [0.0, 1.0], \n",
    "        \"b\": [None, 0], \n",
    "        \"s\": [{\"c\": [True], \"d\": \"0\"}, {\"c\": [True, False], \"d\": \"1\"}]\n",
    "    })   \n",
    "    .pipe(DataFrame[Schema]) # <- Add a Schema to your dataframe\n",
    "    .validate() # Validate it from the Schema annotations!\n",
    ")\n",
    "shape: (2, 3)\n",
    "â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ a   â”† b    â”† s                   â”‚\n",
    "â”‚ --- â”† ---  â”† ---                 â”‚\n",
    "â”‚ i64 â”† i64  â”† struct[2]           â”‚\n",
    "â•žâ•â•â•â•â•â•ªâ•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
    "â”‚ 0   â”† null â”† {[true],\"0\"}        â”‚\n",
    "â”‚ 1   â”† 0    â”† {[true, false],\"1\"} â”‚\n",
    "â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = pl.DataFrame(df).row(0, named=True)\n",
    "a: bool = row[\"s\"][\"c\"][0]\n",
    "# row[\"not_exists\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Runtime type is 'int'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Any, reveal_type\n",
    "\n",
    "\n",
    "a : dict[str, int]= {\"a\": 1}\n",
    "b = a[\"a\"]\n",
    "reveal_type(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(typeddict_to_polats_schema(Schema))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import get_type_hints, is_typeddict\n",
    "import typing\n",
    "\n",
    "\n",
    "input = Schema.__annotations__[\"s\"]\n",
    "is_typeddict(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.Struct(pl.Schema({\"a\": pl.Int16}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input.__annotations__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from polaroids._parse_types import parse_into_dtype\n",
    "\n",
    "\n",
    "parse_into_dtype(input.__annotations__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = SubSchema()\n",
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_utils.typeddict_to_polats_schema(Schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.Series(\"a\", [[1, 2], [4, 3]], dtype=pl.Array(pl.Int64, 2)).to_frame().rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_utils.typeddict_to_polats_schema(Schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_utils.typeddict_to_polats_schema(Schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input.__origin__\n",
    "input.__args__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw._schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.Series([], dtype=dict[str, str])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.Str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import UnionType\n",
    "from typing import ForwardRef, Union, get_type_hints\n",
    "\n",
    "UnionTypeOld = type(Union[int, str])\n",
    "\n",
    "isinstance(get_type_hints(Schema)[\"b\"], ForwardRef)\n",
    "isinstance(input, (UnionType, UnionTypeOld))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int32.__forward_arg__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Schema.__annotations__[\"a\"].__forward_arg__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from polars.datatypes._parse import parse_py_type_into_dtype\n",
    "\n",
    "__forward_arg__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "from inspect import isclass\n",
    "import sys\n",
    "from typing import TYPE_CHECKING, Any, NoReturn\n",
    "from polars.datatypes.classes import (\n",
    "    Binary,\n",
    "    Boolean,\n",
    "    Date,\n",
    "    Datetime,\n",
    "    Decimal,\n",
    "    Duration,\n",
    "    Enum,\n",
    "    Float64,\n",
    "    Int64,\n",
    "    List,\n",
    "    Null,\n",
    "    Object,\n",
    "    String,\n",
    "    Time,\n",
    "    Unknown,\n",
    ")\n",
    "\n",
    "from datetime import date, datetime, time, timedelta\n",
    "from decimal import Decimal as PyDecimal\n",
    "\n",
    "from polars.datatypes.convert import is_polars_dtype\n",
    "\n",
    "from polars._typing import PolarsDataType, PythonDataType, SchemaDict\n",
    "\n",
    "from types import NoneType, UnionType\n",
    "\n",
    "\n",
    "def parse_py_type_into_dtype(input: PythonDataType | type[object]) -> PolarsDataType:\n",
    "    \"\"\"Convert Python data type to Polars data type.\"\"\"\n",
    "    if input is int:\n",
    "        return Int64()\n",
    "    elif input is float:\n",
    "        return Float64()\n",
    "    elif input is str:\n",
    "        return String()\n",
    "    elif input is bool:\n",
    "        return Boolean()\n",
    "    elif isinstance(input, type) and issubclass(input, datetime):  # type: ignore[redundant-expr]\n",
    "        return Datetime(\"us\")\n",
    "    elif isinstance(input, type) and issubclass(input, date):  # type: ignore[redundant-expr]\n",
    "        return Date()\n",
    "    elif input is timedelta:\n",
    "        return Duration\n",
    "    elif input is time:\n",
    "        return Time()\n",
    "    elif input is PyDecimal:\n",
    "        return Decimal\n",
    "    elif input is bytes:\n",
    "        return Binary()\n",
    "    elif input is object:\n",
    "        return Object()\n",
    "    elif input is NoneType:\n",
    "        return Null()\n",
    "    elif input is list or input is tuple:\n",
    "        return List\n",
    "    elif isclass(input) and issubclass(input, enum.Enum):\n",
    "        return Enum(input)\n",
    "    # this is required as pass through. Don't remove\n",
    "    elif input == Unknown:\n",
    "        return Unknown\n",
    "    elif hasattr(input, \"__origin__\") and hasattr(input, \"__args__\"):\n",
    "        return _parse_generic_into_dtype(input)\n",
    "    # -- Custom code --\n",
    "    elif input.__module__ == \"polaroids.types\":\n",
    "        return _utils.annotation_to_polars_dtype(input)\n",
    "    # -- Custom code --\n",
    "    else:\n",
    "        _raise_on_invalid_dtype(input)\n",
    "\n",
    "\n",
    "def _parse_generic_into_dtype(input: Any) -> PolarsDataType:\n",
    "    \"\"\"Parse a generic type (from typing annotation) into a Polars data type.\"\"\"\n",
    "    base_type = input.__origin__\n",
    "    if base_type not in (tuple, list):\n",
    "        _raise_on_invalid_dtype(input)\n",
    "\n",
    "    inner_types = input.__args__\n",
    "    inner_type = inner_types[0]\n",
    "    if len(inner_types) > 1:\n",
    "        all_equal = all(t in (inner_type, ...) for t in inner_types)\n",
    "        if not all_equal:\n",
    "            _raise_on_invalid_dtype(input)\n",
    "\n",
    "    inner_type = inner_types[0]\n",
    "    inner_dtype = parse_py_type_into_dtype(inner_type)\n",
    "    return List(inner_dtype)\n",
    "\n",
    "\n",
    "def _raise_on_invalid_dtype(input: Any) -> NoReturn:\n",
    "    \"\"\"Raise an informative error if the input could not be parsed.\"\"\"\n",
    "    input_type = input if type(input) is type else f\"of type {type(input).__name__!r}\"\n",
    "    input_detail = \"\" if type(input) is type else f\" (given: {input!r})\"\n",
    "    msg = f\"cannot parse input {input_type} into Polars data type{input_detail}\"\n",
    "    raise TypeError(msg) from None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_py_type_into_dtype(int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw._schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import get_type_hints\n",
    "\n",
    "\n",
    "t = get_type_hints(Schema)[\"b\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.__module__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.datatypes.dtype_str_to_dtype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.DataType.from_python(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column, checks = (\n",
    "    self\n",
    "    ._metadata\n",
    "    .filter(pl.col.checks.is_not_null())\n",
    "    .select(\"column\", \"checks\")\n",
    "    .row(0)\n",
    ")\n",
    "\n",
    "result = raw.select([\n",
    "    check(pl.col(column)).alias(str(i))\n",
    "    for i, check in enumerate(checks)\n",
    "])\n",
    "for i, check_ok in result.select(pl.all().all()).row(0, named=True).items():\n",
    "    if not check_ok:\n",
    "        df_failure = raw.filter(result.get_column(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.with_columns(result.get_column(i).alias(\"__polaroids_tmp__\")).fil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.get_column(i).arg_true()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.select(pl.all().all()).transpose(include_header = True, column_names = [\"check_ok\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.DataFrame({\"a\": [0.0, 1.0], \"b\": [None, 0]})\n",
    "DataFrame[Schema](df)._metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasattr(pl.DataFrame, \"validate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(getattr(df, \"__orig_class__\", 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df._typeddict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.__orig_class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df).__orig_bases__[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getattr(df, \"__orig_class__\", type(df).__orig_bases__[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df).__orig_bases__[0].__args__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.DataFrame(pl.DataFrame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pl.DataFrame(df).__getattribute__(\"validate\")\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.DataFrame.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = df.row(0, named=True)\n",
    "row[\"a\"]\n",
    "row[\"not_exists\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from typing import Annotated, Self, TypedDict\n",
    "from polaroids import DataFrame, Field\n",
    "import polars as pl\n",
    "\n",
    "class BasicSchema(TypedDict):\n",
    "    a: Annotated[pl.Int64, Field(\n",
    "        sorted=\"ascending\",\n",
    "        coerce=True,\n",
    "        unique=True,\n",
    "        checks=[lambda d: d.ge(0)],\n",
    "    )]\n",
    "    b: int | None\n",
    "\n",
    "df = pl.DataFrame({\"a\": [0.0, 1.0], \"b\": [None, 0]})\n",
    "\n",
    "df_validated = df.pipe(DataFrame[BasicSchema]).validate()\n",
    "df_validated\n",
    "# shape: (2, 2)\n",
    "# â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”\n",
    "# â”‚ a   â”† b    â”‚\n",
    "# â”‚ --- â”† ---  â”‚\n",
    "# â”‚ i64 â”† i64  â”‚\n",
    "# â•žâ•â•â•â•â•â•ªâ•â•â•â•â•â•â•¡\n",
    "# â”‚ 0   â”† null â”‚\n",
    "# â”‚ 1   â”† 10   â”‚\n",
    "# â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "\n",
    "class BasicSchemaDataFrame(DataFrame[BasicSchema]):\n",
    "    def check_a_greater_then_b(self) -> None:\n",
    "        assert self.select((pl.col(\"a\") >= pl.col(\"b\")).all()).item(), \"a should be greater the b\"\n",
    "\n",
    "# Example usage\n",
    "BasicSchemaDataFrame(df).validate() # Passes validation\n",
    "\n",
    "# This will raise an AssertionError\n",
    "(\n",
    "    pl.DataFrame({\"a\": [5, 6], \"b\": [None, 10]})\n",
    "    .pipe(BasicSchemaDataFrame)\n",
    "    .validate() # This will raise ðŸ’£ !\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_validated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from polaroids import DataFrame, Field\n",
    "import polars as pl\n",
    "\n",
    "class BasicSchema(TypedDict):\n",
    "    a: Annotated[pl.Int64, Field(\n",
    "        sorted=\"ascending\",\n",
    "        coerce=True,\n",
    "        unique=True,\n",
    "        checks=[lambda d: d.ge(0)],\n",
    "    )]\n",
    "    b: str | None\n",
    "\n",
    "print(\n",
    "    pl.DataFrame({\"a\": [2.0, 5.0], \"b\": [\"a\", None]})\n",
    "    .pipe(DataFrame[BasicSchema])\n",
    "    .validate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from collections.abc import Callable\n",
    "\n",
    "from polars import String\n",
    "\n",
    "\n",
    "\n",
    "df = (\n",
    "    pl.DataFrame({\"a\": [0,None,2,3], \"b\": [None,0,0,0], \"c\": [-1.0, 2, 4,10]})\n",
    "    .pipe(DataFrame[BasicSchema])\n",
    "    # ._typeddict\n",
    "    # .__annotations__\n",
    "    # .set_sorted(\"a\")\n",
    "    # .__annotations__\n",
    "    # ._metadata\n",
    "    .validate()\n",
    "    # .schema\n",
    "    # ._metadata\n",
    "    # .validate()\n",
    "    # .pipe(pl.DataFrame).select(\"sorted\", \"column\")\n",
    "    # .schema[\"sorted\"]\n",
    "    # .pipe(lambda d: d.to_dict())\n",
    "    # .group_by(\"sorted\").agg(pl.col(\"column\"))\n",
    "    # .group_by(\"sorted\").agg(pl.col(\"column\"))\n",
    "    # .filter(pl.col(\"unique\"))[\"column\"].to_list()\n",
    "    \n",
    "    # [\"checks\"] \n",
    "    # .__args__[0].__origin__ is Callable\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctypes import util\n",
    "\n",
    "\n",
    "_utils.typeddict_to_polats_schema(_Metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import get_type_hints\n",
    "\n",
    "class BasicSchema(TypedDict):\n",
    "    a: Annotated[pl.Int64, Field(\n",
    "        sorted=\"ascending\",\n",
    "        coerce=True,\n",
    "        unique=True,\n",
    "        checks=[lambda d: d.ge(0)],\n",
    "    )]\n",
    "    b: Annotated[pl.Int64, Field(primary_key=False)]\n",
    "    c: Annotated[int | None, Field(coerce=True)]\n",
    "\n",
    "get_type_hints(BasicSchema)\n",
    "# 'a': Int64, 'b': Int64, 'c': int | None}\n",
    "\n",
    "# I want to retrieve the nullable columns \n",
    "# here : nullable_cols == [\"c\"] \n",
    "nullable_cols = [name for name, hint in get_type_hints(BasicSchema).items() if type(None) in getattr(hint, \"__args__\", [])]\n",
    "nullable_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "None.__class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.DataFrame({\"sorted\": [\"ascending\"], \"column\": [\"a\"]}, schema_overrides={\"sorted\": e}).group_by(\"sorted\").agg(pl.col(\"column\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.DataFrame({'A' : [1,2,3]})\n",
    "df = df.set_sorted(\"A\")\n",
    "df[\"A\"].flags\n",
    "# (\n",
    "#     pl.DataFrame({'A' : [1,2,3]})\n",
    "#     .with_columns(pl.col('A').set_sorted())\n",
    "#     # .write_parquet('tmp.parquet')\n",
    "# )\n",
    "\n",
    "# pl.read_parquet('tmp.parquet')['A'].flags \n",
    "# Today: {'SORTED_ASC': False, 'SORTED_DESC': False}\n",
    "# Wish: {'SORTED_ASC': True, 'SORTED_DESC': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pl.DataFrame({\"a\": [0,1,2,3], \"b\": [0,0,0,0]})\n",
    "    .select(pl.all().is_duplicated().any())\n",
    "    .transpose(include_header = True, column_names = [\"is_duplicated\"])\n",
    "    .filter(pl.col(\"is_duplicated\")).get_column(\"column\").to_list()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pl.DataFrame({\"a\": [0,1,2,3], \"b\": [0,0,0,0]})\n",
    "    \n",
    "    # .select(pl.all().filter(pl.element().is_duplicated()).implode())\n",
    "    # .select(pl.all().is_unique().all())\n",
    "    # .transpose(include_header = True, column_names = [\"is_unique\"])\n",
    "    # .filter(~pl.col(\"is_unique\")).get_column(\"column\").to_list()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
