{"title":"pybiber","markdown":{"yaml":{"jupyter":"python3"},"headingText":"pybiber","containsRefs":false,"markdown":"\n\n\nThe pybiber package aggregates [the lexicogrammatical and functional features](feature-categories.qmd) described by Biber [-@biber1988variation] and widely used for text-type, register, and genre classification tasks.\n\nThe package uses [spaCy](https://spacy.io/models){.external target=\"_blank\"} part-of-speech tagging and dependency parsing to summarize and aggregate patterns.\n\nBecause feature extraction builds from the outputs of probabilistic taggers, the accuracy of the resulting counts are reliant on the accuracy of those models. Thus, texts with irregular spellings, non-normative punctuation, etc. will likely produce unreliable outputs, unless taggers are tuned specifically for those purposes.\n\n---\n\nAll DataFrames are rendered using [polars](https://docs.pola.rs/api/python/stable/reference/index.html){.external target=\"_blank\"}. If you prefer to conduct any post-processing using pandas, please refer to [the documentation](https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.to_pandas.html){.external target=\"_blank\"} for converting polars to pandas. Note that conversion requires both pandas and pyarrow to be installed into your working environment.\n\nSee [pseudobibeR](https://cran.r-project.org/web/packages/pseudobibeR/index.html){.external target=\"_blank\"} for the R implementation.\n\n---\n\n## Installation\n\nYou can install the released version of pybiber from [PyPI](https://pypi.org/project/pybiber/){.external target=\"_blank\"}:\n\n```bash\npip install pybiber\n```\n\nInstall a [spaCy model](https://spacy.io/usage){.external target=\"_blank\"}:\n\n```bash\npython -m spacy download en_core_web_sm\n\n# models can also be installed using pip\n# pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl\n```\n\n## Usage\n\nTo use the pybiber package, you must first import [spaCy](https://spacy.io/models){.external target=\"_blank\"} and initiate an instance. You will also need to create a corpus. The [](`~pybiber.biber`) function expects a [polars DataFrame](https://docs.pola.rs/api/python/stable/reference/dataframe/index.html){.external target=\"_blank\"} with a `doc_id` column and a `text` column. This follows the convention for [`readtext`](https://readtext.quanteda.io/articles/readtext_vignette.html){.external target=\"_blank\"} and corpus processing using [quanteda](https://quanteda.io/){.external target=\"_blank\"} in R.\n\n\n```{python}\nimport spacy\nimport pybiber as pb\nfrom pybiber.data import micusp_mini\n```\n\nYou can see the simple data structure of a corpus:\n\n```{python}\nmicusp_mini.head()\n```\n\n::: {.callout-tip}\n## Building your own corpus\n\nTo build your own corpus, a good place to start is [](`~pybiber.parse_utils.corpus_from_folder`), which reads in all of the text files from a directory.\n:::\n\n### Initiate an instance\n\nThe pybiber package requires a model that will carry out part-of-speech tagging and [dependency parsing](https://spacy.io/usage/linguistic-features){.external target=\"_blank\"}, like one of spaCy's `en_core` models.\n\n```{python}\nnlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\"])\n```\n\n::: {.callout-note}\nHere we are disabling `ner` or \"Named Entity Recognition\" from the pipeline to increase processing speed, but doing so is not necessary.\n:::\n\n### Process the corpus\n\nTo process the corpus, use [](`~pybiber.parse_utils.spacy_parse`). Processing the `micusp_mini` corpus should take between 20-30 seconds.\n\n```{python}\ndf_spacy = pb.spacy_parse(micusp_mini, nlp)\n```\n\nThe function returns a DataFrame, which is structured like a [spacyr](https://cran.r-project.org/web/packages/spacyr/vignettes/using_spacyr.html){.external target=\"_blank\"} output.\n\n```{python}\ndf_spacy.head()\n```\n\n### Aggregate features\n\nAfter parsing the corpus, features can then be aggregated using [](`~pybiber.parse_functions.biber`).\n\n```{python}\ndf_biber = pb.biber(df_spacy)\n```\n\n\n::: {.callout-important}\n## Feature counts\n\nIn the [documentation](`~pybiber.parse_functions.biber`), note the difference beween type-token ratio (TTR) and moving average type-token ration (MATTR). For most use-cases, forcing TTR is unnecessary, but when comparing multiple corpora that haven't been processed together, it is important to make sure the same measure is being used.\n\nAlso, the default is to normalize frequencies per 1000 tokens. However, absolute frequencies can be returned by setting `normalize=False`.\n:::\n\nThe resulting document-feature matrix has 67 variables and a column of document ids.\n\n```{python}\ndf_biber.shape\n```\n\n::: {.callout-tip}\n\nEncoding metadata into your document id's (i.e., file names) is key to further processing and analysis. In the `micusp_mini` data, for example, the first three letters before the underscore represent an academic discipline (e.g., BIO for biology, ENG for English, etc.).\n:::\n\n```{python}\ndf_biber.head()\n```\n\n\n","srcMarkdownNoYaml":"\n\n# pybiber\n\nThe pybiber package aggregates [the lexicogrammatical and functional features](feature-categories.qmd) described by Biber [-@biber1988variation] and widely used for text-type, register, and genre classification tasks.\n\nThe package uses [spaCy](https://spacy.io/models){.external target=\"_blank\"} part-of-speech tagging and dependency parsing to summarize and aggregate patterns.\n\nBecause feature extraction builds from the outputs of probabilistic taggers, the accuracy of the resulting counts are reliant on the accuracy of those models. Thus, texts with irregular spellings, non-normative punctuation, etc. will likely produce unreliable outputs, unless taggers are tuned specifically for those purposes.\n\n---\n\nAll DataFrames are rendered using [polars](https://docs.pola.rs/api/python/stable/reference/index.html){.external target=\"_blank\"}. If you prefer to conduct any post-processing using pandas, please refer to [the documentation](https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.to_pandas.html){.external target=\"_blank\"} for converting polars to pandas. Note that conversion requires both pandas and pyarrow to be installed into your working environment.\n\nSee [pseudobibeR](https://cran.r-project.org/web/packages/pseudobibeR/index.html){.external target=\"_blank\"} for the R implementation.\n\n---\n\n## Installation\n\nYou can install the released version of pybiber from [PyPI](https://pypi.org/project/pybiber/){.external target=\"_blank\"}:\n\n```bash\npip install pybiber\n```\n\nInstall a [spaCy model](https://spacy.io/usage){.external target=\"_blank\"}:\n\n```bash\npython -m spacy download en_core_web_sm\n\n# models can also be installed using pip\n# pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl\n```\n\n## Usage\n\nTo use the pybiber package, you must first import [spaCy](https://spacy.io/models){.external target=\"_blank\"} and initiate an instance. You will also need to create a corpus. The [](`~pybiber.biber`) function expects a [polars DataFrame](https://docs.pola.rs/api/python/stable/reference/dataframe/index.html){.external target=\"_blank\"} with a `doc_id` column and a `text` column. This follows the convention for [`readtext`](https://readtext.quanteda.io/articles/readtext_vignette.html){.external target=\"_blank\"} and corpus processing using [quanteda](https://quanteda.io/){.external target=\"_blank\"} in R.\n\n\n```{python}\nimport spacy\nimport pybiber as pb\nfrom pybiber.data import micusp_mini\n```\n\nYou can see the simple data structure of a corpus:\n\n```{python}\nmicusp_mini.head()\n```\n\n::: {.callout-tip}\n## Building your own corpus\n\nTo build your own corpus, a good place to start is [](`~pybiber.parse_utils.corpus_from_folder`), which reads in all of the text files from a directory.\n:::\n\n### Initiate an instance\n\nThe pybiber package requires a model that will carry out part-of-speech tagging and [dependency parsing](https://spacy.io/usage/linguistic-features){.external target=\"_blank\"}, like one of spaCy's `en_core` models.\n\n```{python}\nnlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\"])\n```\n\n::: {.callout-note}\nHere we are disabling `ner` or \"Named Entity Recognition\" from the pipeline to increase processing speed, but doing so is not necessary.\n:::\n\n### Process the corpus\n\nTo process the corpus, use [](`~pybiber.parse_utils.spacy_parse`). Processing the `micusp_mini` corpus should take between 20-30 seconds.\n\n```{python}\ndf_spacy = pb.spacy_parse(micusp_mini, nlp)\n```\n\nThe function returns a DataFrame, which is structured like a [spacyr](https://cran.r-project.org/web/packages/spacyr/vignettes/using_spacyr.html){.external target=\"_blank\"} output.\n\n```{python}\ndf_spacy.head()\n```\n\n### Aggregate features\n\nAfter parsing the corpus, features can then be aggregated using [](`~pybiber.parse_functions.biber`).\n\n```{python}\ndf_biber = pb.biber(df_spacy)\n```\n\n\n::: {.callout-important}\n## Feature counts\n\nIn the [documentation](`~pybiber.parse_functions.biber`), note the difference beween type-token ratio (TTR) and moving average type-token ration (MATTR). For most use-cases, forcing TTR is unnecessary, but when comparing multiple corpora that haven't been processed together, it is important to make sure the same measure is being used.\n\nAlso, the default is to normalize frequencies per 1000 tokens. However, absolute frequencies can be returned by setting `normalize=False`.\n:::\n\nThe resulting document-feature matrix has 67 variables and a column of document ids.\n\n```{python}\ndf_biber.shape\n```\n\n::: {.callout-tip}\n\nEncoding metadata into your document id's (i.e., file names) is key to further processing and analysis. In the `micusp_mini` data, for example, the first three letters before the underscore represent an academic discipline (e.g., BIO for biology, ENG for English, etc.).\n:::\n\n```{python}\ndf_biber.head()\n```\n\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","filters":["interlinks"],"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.549","bibliography":["references.bib"],"quartodoc":{"title":"Reference","package":"pybiber","sections":[{"title":"pybiber utility functions","desc":"Read in and prepare data","package":"pybiber.parse_utils","contents":["corpus_from_folder","get_text_paths","readtext","spacy_parse","get_noun_phrases"]},{"title":"pybiber parse","desc":"Generate a biber document-feature matrix","package":"pybiber.parse_functions","contents":["biber"]},{"title":"pybiber methods","desc":"Analyze a biber document-feature matrix","package":"pybiber.BiberAnalyzer","contents":["mda","pca","mdaviz_screeplot","mdaviz_groupmeans","pcaviz_groupmeans","pcaviz_contrib"]}]},"interlinks":{"sources":{}},"sidebar":false,"jupyter":"python3"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}