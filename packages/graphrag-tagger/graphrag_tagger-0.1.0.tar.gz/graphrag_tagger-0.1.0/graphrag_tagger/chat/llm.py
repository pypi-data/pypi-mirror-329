import aisuite as ai

from .parser import parse_json
from .prompts import CLASSIFY_PROMPT, CREATE_TOPICS


class LLM:
    """
    A wrapper for the LLM model to clean topics and classify document chunks.
    """

    def __init__(self, model="ollama:phi4"):
        self.model = ai.Client()
        self.model_name = model

    def __call__(self, messages: list):
        """
        Send a chat completion request to the underlying LLM.

        :param messages: A list of message dictionaries as per the LLM API.
        :type messages: list
        :return: The content of the first choice's message from the LLM response.
        :rtype: str
        """
        return (
            self.model.chat.completions.create(
                model=self.model_name, temperature=0.75, messages=messages
            )
            .choices[0]
            .message.content
        )

    def clean_topics(self, topics: list):
        """
        Clean a list of messy topics by transforming them into concise, clear topic labels.

        :param topics: A list of raw topics generated by a topic extractor.
        :type topics: list
        :return: Parsed JSON object containing cleaned topics.
        :rtype: dict
        """
        topics_str = "\n".join(topics)
        prompt = CREATE_TOPICS.format(topics=topics_str)
        results = self.__call__([{"role": "system", "content": prompt}])
        return parse_json(results)

    def classify(self, document_chunk: str, topics: list):
        """
        Classify a given text chunk by selecting relevant topics from a provided list.

        :param document_chunk: The text excerpt that needs to be classified.
        :type document_chunk: str
        :param topics: A list of candidate topic labels.
        :type topics: list
        :return: Parsed JSON object containing the selected topics.
        :rtype: list
        """
        topics_str = "\n".join(topics)
        prompt = CLASSIFY_PROMPT.format(text=document_chunk, topics=topics_str)
        results = self.__call__([{"role": "system", "content": prompt}])
        return parse_json(results)
