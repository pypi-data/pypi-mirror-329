{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "papermill": {
     "duration": 0.005881,
     "end_time": "2024-08-28T06:17:47.318938",
     "exception": false,
     "start_time": "2024-08-28T06:17:47.313057",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# preface \n",
    "I was inspired by @AmbrosM idea https://www.kaggle.com/competitions/ariel-data-challenge-2024/discussion/530152#2969648\n",
    "\n",
    "The idea of ​​this approach is to predict the average answer for each test sample. Instead of building models, we will search for the correct answer experimentally. We will select for each spectrum such a multiplier that the transit part multiplied by it will \"line up\" with the other points. The line can be either a straight line or a polynomial up to the 5th degree. For selection, we will use the Nelder-Mead method. The found multiplication factor minus one is our answer.\n",
    "\n",
    "There are some changes in data preparation here.\n",
    "* dt for dark calibration changed in favor https://www.kaggle.com/code/gordonyip/update-calibrating-and-binning-astronomical-data/comments#2964759\n",
    "* signal clipped to zero due this https://www.kaggle.com/competitions/ariel-data-challenge-2024/discussion/530247#2970709\n",
    "* I masked hot and dead pixels with NaN in flat and averaging through spatial dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "papermill": {
     "duration": 0.005138,
     "end_time": "2024-08-28T06:17:47.329769",
     "exception": false,
     "start_time": "2024-08-28T06:17:47.324631",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **upd for version 2**: it seems I forgot to remove **5x sigma** copied from somewhere. I wonder how this will affect the score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "papermill": {
     "duration": 0.005115,
     "end_time": "2024-08-28T06:17:47.340301",
     "exception": false,
     "start_time": "2024-08-28T06:17:47.335186",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 3.694036,
     "end_time": "2024-08-28T06:17:51.039673",
     "exception": false,
     "start_time": "2024-08-28T06:17:47.345637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy.stats\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import itertools\n",
    "from scipy.optimize import minimize\n",
    "from functools import partial\n",
    "import random, os\n",
    "from astropy.stats import sigma_clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kego.plotting.lines import plot_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_COMPETITION = os.environ[\"PATH_EFOLDER\"] + \"ariel-data-challenge-2024/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "papermill": {
     "duration": 0.227703,
     "end_time": "2024-08-28T06:17:51.273004",
     "exception": false,
     "start_time": "2024-08-28T06:17:51.045301",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_adc_info = pd.read_csv(\n",
    "    FOLDER_COMPETITION + \"test_adc_info.csv\", index_col=\"planet_id\"\n",
    ")\n",
    "axis_info = pd.read_parquet(FOLDER_COMPETITION + \"axis_info.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "papermill": {
     "duration": 14.145993,
     "end_time": "2024-08-28T06:18:05.424543",
     "exception": false,
     "start_time": "2024-08-28T06:17:51.278550",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_linear_corr(linear_corr, clean_signal):\n",
    "    linear_corr = np.flip(linear_corr, axis=0)\n",
    "    for x, y in itertools.product(\n",
    "        range(clean_signal.shape[1]), range(clean_signal.shape[2])\n",
    "    ):\n",
    "        poli = np.poly1d(linear_corr[:, x, y])\n",
    "        clean_signal[:, x, y] = poli(clean_signal[:, x, y])\n",
    "    return clean_signal\n",
    "\n",
    "\n",
    "def clean_dark(signal, dark, dt):\n",
    "    dark = np.tile(dark, (signal.shape[0], 1, 1))\n",
    "    signal -= dark * dt[:, np.newaxis, np.newaxis]\n",
    "    return signal\n",
    "\n",
    "\n",
    "def preproc(dataset, adc_info, sensor, binning=15, return_plot_data=False):\n",
    "    cut_inf, cut_sup = 39, 321\n",
    "    sensor_sizes_dict = {\n",
    "        \"AIRS-CH0\": [[11250, 32, 356], [1, 32, cut_sup - cut_inf]],\n",
    "        \"FGS1\": [[135000, 32, 32], [1, 32, 32]],\n",
    "    }\n",
    "    binned_dict = {\n",
    "        \"AIRS-CH0\": [11250 // binning // 2, 282],\n",
    "        \"FGS1\": [135000 // binning // 2],\n",
    "    }\n",
    "    linear_corr_dict = {\"AIRS-CH0\": (6, 32, 356), \"FGS1\": (6, 32, 32)}\n",
    "    planet_ids = adc_info.index\n",
    "\n",
    "    feats = []\n",
    "    to_plot = {}\n",
    "    for i, planet_id in tqdm(list(enumerate(planet_ids))):\n",
    "        signal, dark_frame, dead_frame, flat_frame, linear_corr = load_data_per_planet(\n",
    "            dataset, sensor, linear_corr_dict, planet_id\n",
    "        )\n",
    "        signal = signal.reshape(sensor_sizes_dict[sensor][0])\n",
    "        to_plot[planet_id] = {\"signal_raw\": signal}\n",
    "        gain = adc_info[f\"{sensor}_adc_gain\"].values[i]\n",
    "        offset = adc_info[f\"{sensor}_adc_offset\"].values[i]\n",
    "        signal = signal / gain + offset\n",
    "\n",
    "        hot = sigma_clip(dark_frame, sigma=5, maxiters=5).mask\n",
    "        to_plot[planet_id][\"signal_gain\"] = signal\n",
    "        if sensor != \"FGS1\":\n",
    "            signal = signal[:, :, cut_inf:cut_sup]  # 11250 * 32 * 282\n",
    "            # dt = axis_info['AIRS-CH0-integration_time'].dropna().values\n",
    "            dt = np.ones(len(signal)) * 0.1\n",
    "            dt[1::2] += 4.5  # @bilzard idea\n",
    "            linear_corr = linear_corr[:, :, cut_inf:cut_sup]\n",
    "            dark_frame = dark_frame[:, cut_inf:cut_sup]\n",
    "            dead_frame = dead_frame[:, cut_inf:cut_sup]\n",
    "            flat_frame = flat_frame[:, cut_inf:cut_sup]\n",
    "            hot = hot[:, cut_inf:cut_sup]\n",
    "        else:\n",
    "            dt = np.ones(len(signal)) * 0.1\n",
    "            dt[1::2] += 0.1\n",
    "\n",
    "        signal = signal.clip(0)  # @graySnow idea\n",
    "        linear_corr_signal = apply_linear_corr(linear_corr, signal)\n",
    "        to_plot[planet_id][\"signal_corr\"] = linear_corr_signal\n",
    "        signal = clean_dark(linear_corr_signal, dark_frame, dt)\n",
    "        to_plot[planet_id][\"signal_clean_dark\"] = signal\n",
    "\n",
    "        flat = flat_frame.reshape(sensor_sizes_dict[sensor][1])\n",
    "        flat[dead_frame.reshape(sensor_sizes_dict[sensor][1])] = np.nan\n",
    "        flat[hot.reshape(sensor_sizes_dict[sensor][1])] = np.nan\n",
    "        signal = signal / flat\n",
    "        to_plot[planet_id][\"signal_flat\"] = signal\n",
    "\n",
    "        if sensor == \"FGS1\":\n",
    "            signal = signal.reshape(\n",
    "                (\n",
    "                    sensor_sizes_dict[sensor][0][0],\n",
    "                    sensor_sizes_dict[sensor][0][1] * sensor_sizes_dict[sensor][0][2],\n",
    "                )\n",
    "            )\n",
    "\n",
    "        mean_signal = np.nanmean(\n",
    "            signal, axis=1\n",
    "        )  # mean over the 32*32(FGS1) or 32(CH0) pixels\n",
    "        cds_signal = mean_signal[1::2] - mean_signal[0::2]\n",
    "\n",
    "        binned = np.zeros((binned_dict[sensor]))\n",
    "        for j in range(cds_signal.shape[0] // binning):\n",
    "            binned[j] = cds_signal[j * binning : j * binning + binning].mean(axis=0)\n",
    "\n",
    "        if sensor == \"FGS1\":\n",
    "            binned = binned.reshape((binned.shape[0], 1))\n",
    "\n",
    "        feats.append(binned)\n",
    "    if return_plot_data:\n",
    "        return np.stack(feats), to_plot\n",
    "    return np.stack(feats)\n",
    "\n",
    "\n",
    "def load_data_per_planet(dataset, sensor, linear_corr_dict, planet_id):\n",
    "    signal = pd.read_parquet(\n",
    "        FOLDER_COMPETITION + f\"{dataset}/{planet_id}/{sensor}_signal.parquet\"\n",
    "    ).to_numpy()\n",
    "    dark_frame = pd.read_parquet(\n",
    "        FOLDER_COMPETITION\n",
    "        + f\"{dataset}/\"\n",
    "        + str(planet_id)\n",
    "        + \"/\"\n",
    "        + sensor\n",
    "        + \"_calibration/dark.parquet\",\n",
    "        engine=\"pyarrow\",\n",
    "    ).to_numpy()\n",
    "    dead_frame = pd.read_parquet(\n",
    "        FOLDER_COMPETITION\n",
    "        + f\"{dataset}/\"\n",
    "        + str(planet_id)\n",
    "        + \"/\"\n",
    "        + sensor\n",
    "        + \"_calibration/dead.parquet\",\n",
    "        engine=\"pyarrow\",\n",
    "    ).to_numpy()\n",
    "    flat_frame = pd.read_parquet(\n",
    "        FOLDER_COMPETITION\n",
    "        + f\"{dataset}/\"\n",
    "        + str(planet_id)\n",
    "        + \"/\"\n",
    "        + sensor\n",
    "        + \"_calibration/flat.parquet\",\n",
    "        engine=\"pyarrow\",\n",
    "    ).to_numpy()\n",
    "    linear_corr = (\n",
    "        pd.read_parquet(\n",
    "            FOLDER_COMPETITION\n",
    "            + f\"{dataset}/\"\n",
    "            + str(planet_id)\n",
    "            + \"/\"\n",
    "            + sensor\n",
    "            + \"_calibration/linear_corr.parquet\"\n",
    "        )\n",
    "        .values.astype(np.float64)\n",
    "        .reshape(linear_corr_dict[sensor])\n",
    "    )\n",
    "\n",
    "    return signal, dark_frame, dead_frame, flat_frame, linear_corr\n",
    "\n",
    "\n",
    "pre_train = np.concatenate(\n",
    "    [\n",
    "        preproc(\"test\", test_adc_info, \"FGS1\", 30 * 12),\n",
    "        preproc(\"test\", test_adc_info, \"AIRS-CH0\", 30),\n",
    "    ],\n",
    "    axis=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preproc_dict = {}\n",
    "feats, to_plot = preproc(\"test\", test_adc_info, \"FGS1\", 30 * 12, return_plot_data=True)\n",
    "test_preproc_dict[\"FGS1\"] = {\"feats\": feats, \"to_plot\": to_plot}\n",
    "feats, to_plot = preproc(\"test\", test_adc_info, \"AIRS-CH0\", 30, return_plot_data=True)\n",
    "test_preproc_dict[\"AIRS-CH0\"] = {\"feats\": feats, \"to_plot\": to_plot}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    key: data.shape\n",
    "    for key, data in test_preproc_dict[\"FGS1\"][\"to_plot\"][499191466].items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kego.plotting.grid_plot\n",
    "\n",
    "kego.plotting.grid_plot.grid_plot(\n",
    "    data_as_dict={\n",
    "        f\"{k}_{i}\": v[i, :, :]\n",
    "        for i in [0, 5_000, 10_000]\n",
    "        for k, v in test_preproc_dict[\"FGS1\"][\"to_plot\"][499191466].items()\n",
    "    },\n",
    "    nx_max=5,\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {
    "papermill": {
     "duration": 0.006749,
     "end_time": "2024-08-28T06:18:05.437832",
     "exception": false,
     "start_time": "2024-08-28T06:18:05.431083",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### fit polynoms for each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "papermill": {
     "duration": 0.091539,
     "end_time": "2024-08-28T06:18:05.535683",
     "exception": false,
     "start_time": "2024-08-28T06:18:05.444144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def phase_detector(signal):\n",
    "    phase1, phase2 = None, None\n",
    "    best_drop = 0\n",
    "    for i in range(50 // 2, 150 // 2):\n",
    "        t1 = signal[i : i + 20 // 2].max() - signal[i : i + 20 // 2].min()\n",
    "        if t1 > best_drop:\n",
    "            phase1 = i + (20 + 5) // 2\n",
    "            best_drop = t1\n",
    "\n",
    "    best_drop = 0\n",
    "    for i in range(200 // 2, 250 // 2):\n",
    "        t1 = signal[i : i + 20 // 2].max() - signal[i : i + 20 // 2].min()\n",
    "        if t1 > best_drop:\n",
    "            phase2 = i - 5 // 2\n",
    "            best_drop = t1\n",
    "\n",
    "    return phase1, phase2\n",
    "\n",
    "\n",
    "def try_s(signal, p1, p2, deg, s):\n",
    "    out = list(range(p1 - 30)) + list(range(p2 + 30, signal.shape[0]))\n",
    "    x, y = out, signal[out].tolist()\n",
    "    x = x + list(range(p1, p2))\n",
    "\n",
    "    y = y + (signal[p1:p2] * (1 + s[0])).tolist()\n",
    "    z = np.polyfit(x, y, deg)\n",
    "    p = np.poly1d(z)\n",
    "    q = np.abs(p(x) - y).mean()\n",
    "\n",
    "    if s < 1e-4:\n",
    "        return q + 1e3\n",
    "\n",
    "    return q\n",
    "\n",
    "\n",
    "def calibrate_signal(signal):\n",
    "    p1, p2 = phase_detector(signal)\n",
    "\n",
    "    best_deg, best_score = 1, 1e12\n",
    "    for deg in range(1, 6):\n",
    "        f = partial(try_s, signal, p1, p2, deg)\n",
    "        r = minimize(f, [0.001], method=\"Nelder-Mead\")\n",
    "        s = r.x[0]\n",
    "\n",
    "        out = list(range(p1 - 30)) + list(range(p2 + 30, signal.shape[0]))\n",
    "        x, y = out, signal[out].tolist()\n",
    "        x = x + list(range(p1, p2))\n",
    "        y = y + (signal[p1:p2] * (1 + s)).tolist()\n",
    "\n",
    "        z = np.polyfit(x, y, deg)\n",
    "        p = np.poly1d(z)\n",
    "        q = np.abs(p(x) - y).mean()\n",
    "\n",
    "        if q < best_score:\n",
    "            best_score = q\n",
    "            best_deg = deg\n",
    "\n",
    "        print(deg, q)\n",
    "\n",
    "    z = np.polyfit(x, y, best_deg)\n",
    "    p = np.poly1d(z)\n",
    "\n",
    "    return s, x, y, p(x)\n",
    "\n",
    "\n",
    "def calibrate_train(signal):\n",
    "    p1, p2 = phase_detector(signal)\n",
    "\n",
    "    best_deg, best_score = 1, 1e12\n",
    "    for deg in range(1, 6):\n",
    "        f = partial(try_s, signal, p1, p2, deg)\n",
    "        r = minimize(f, [0.001], method=\"Nelder-Mead\")\n",
    "        s = r.x[0]\n",
    "\n",
    "        out = list(range(p1 - 30)) + list(range(p2 + 30, signal.shape[0]))\n",
    "        x, y = out, signal[out].tolist()\n",
    "        x = x + list(range(p1, p2))\n",
    "        y = y + (signal[p1:p2] * (1 + s)).tolist()\n",
    "\n",
    "        z = np.polyfit(x, y, deg)\n",
    "        p = np.poly1d(z)\n",
    "        q = np.abs(p(x) - y).mean()\n",
    "\n",
    "        if q < best_score:\n",
    "            best_score = q\n",
    "            best_deg = deg\n",
    "\n",
    "    z = np.polyfit(x, y, best_deg)\n",
    "    p = np.poly1d(z)\n",
    "\n",
    "    return s, p(np.arange(signal.shape[0])), p1, p2\n",
    "\n",
    "\n",
    "train = pre_train.copy()\n",
    "all_s = []\n",
    "for i in range(len(test_adc_info)):\n",
    "    signal = train[i, :, 1:].mean(axis=1)\n",
    "    s, p, p1, p2 = calibrate_train(pre_train[i, :, 1:].mean(axis=1))\n",
    "    all_s.append(s)\n",
    "\n",
    "# copy answer 283 times because we predict mean value\n",
    "train_s = np.repeat(np.array(all_s), 283).reshape((len(all_s), 283))\n",
    "train_sigma = np.ones_like(train_s) * 0.00016"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {
    "papermill": {
     "duration": 0.005984,
     "end_time": "2024-08-28T06:18:05.548026",
     "exception": false,
     "start_time": "2024-08-28T06:18:05.542042",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Probably we can accurately estimate sigma from train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "papermill": {
     "duration": 0.391813,
     "end_time": "2024-08-28T06:18:05.946089",
     "exception": false,
     "start_time": "2024-08-28T06:18:05.554276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n = 0\n",
    "s, x, y, y_new = calibrate_signal(pre_train[n, :, 1:].mean(axis=1))\n",
    "plt.scatter(x, y)\n",
    "plt.scatter(x, y_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {
    "papermill": {
     "duration": 0.006753,
     "end_time": "2024-08-28T06:18:05.960121",
     "exception": false,
     "start_time": "2024-08-28T06:18:05.953368",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "I call the orange line \"starline\". This is probably what we would see if the planet weren't in the way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {
    "papermill": {
     "duration": 0.006782,
     "end_time": "2024-08-28T06:18:05.973871",
     "exception": false,
     "start_time": "2024-08-28T06:18:05.967089",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Making submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "papermill": {
     "duration": 0.050908,
     "end_time": "2024-08-28T06:18:06.031985",
     "exception": false,
     "start_time": "2024-08-28T06:18:05.981077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ss = pd.read_csv(FOLDER_COMPETITION + \"sample_submission.csv\")\n",
    "display(ss)\n",
    "preds = train_s.clip(0)\n",
    "sigmas = train_sigma\n",
    "submission = pd.DataFrame(\n",
    "    np.concatenate([preds, sigmas], axis=1), columns=ss.columns[1:]\n",
    ")\n",
    "submission.index = test_adc_info.index\n",
    "submission.to_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "papermill": {
     "duration": 0.040462,
     "end_time": "2024-08-28T06:18:06.079766",
     "exception": false,
     "start_time": "2024-08-28T06:18:06.039304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "papermill": {
     "duration": 0.007071,
     "end_time": "2024-08-28T06:18:06.094384",
     "exception": false,
     "start_time": "2024-08-28T06:18:06.087313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9188054,
     "sourceId": 70367,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 23.26157,
   "end_time": "2024-08-28T06:18:06.824217",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-28T06:17:43.562647",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
