{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "papermill": {
     "duration": 0.004651,
     "end_time": "2024-05-02T00:43:09.559513",
     "exception": false,
     "start_time": "2024-05-02T00:43:09.554862",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- trained model\n",
    "    - https://www.kaggle.com/datasets/motono0223/belka-autogluon-gpu-3m  \n",
    "        This model was trained with the following data:\n",
    "            binds=1 data : 1.5M records (all positive data in train data)\n",
    "            binds=0 data : 1.5M records (random picked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "_kg_hide-output": true,
    "papermill": {
     "duration": 110.452334,
     "end_time": "2024-05-02T00:45:00.016337",
     "exception": false,
     "start_time": "2024-05-02T00:43:09.564003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install -q autogluon==1.1.0\n",
    "# !pip install -q ray==2.6.3\n",
    "# tips: https://github.com/autogluon/autogluon/issues/3365\n",
    "\n",
    "# !pip install rdkit\n",
    "# !pip install duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "papermill": {
     "duration": 0.213085,
     "end_time": "2024-05-02T00:45:30.976645",
     "exception": false,
     "start_time": "2024-05-02T00:45:30.763560",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "import duckdb\n",
    "import pickle\n",
    "\n",
    "\n",
    "import os\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_PROJECT = pathlib.Path(\"/mnt/d/Data/kaggle/leash/leash-BELKA/\")\n",
    "PATH_BASELINE_INPUT = pathlib.Path(\"/mnt/d/Data/kaggle/leash/automl-baseline-input\")\n",
    "PATH_DATA = pathlib.Path(\"/mnt/d/Data/kaggle/leash/\")\n",
    "print(os.listdir(PATH_PROJECT))\n",
    "PATH_TRAIN = PATH_PROJECT / \"train.csv\"\n",
    "PATH_SUBMISSION_EXAMPLE = PATH_PROJECT / \"sample_submission.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = True\n",
    "TRAIN = True\n",
    "\n",
    "N_SAMPLES = 30000\n",
    "if DEBUG:\n",
    "    N_SAMPLES = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "papermill": {
     "duration": 0.013443,
     "end_time": "2024-05-02T00:45:30.996407",
     "exception": false,
     "start_time": "2024-05-02T00:45:30.982964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_path = f\"{PATH_PROJECT}/train.parquet\"\n",
    "test_path = f\"{PATH_PROJECT}/test.parquet\"\n",
    "\n",
    "if TRAIN:\n",
    "    con = duckdb.connect()\n",
    "    df = con.query(\n",
    "        f\"\"\"(SELECT *\n",
    "                        FROM parquet_scan('{train_path}')\n",
    "                        WHERE binds = 0\n",
    "                        ORDER BY random()\n",
    "                        LIMIT {N_SAMPLES})\n",
    "                        UNION ALL\n",
    "                        (SELECT *\n",
    "                        FROM parquet_scan('{train_path}')\n",
    "                        WHERE binds = 1\n",
    "                        ORDER BY random()\n",
    "                        LIMIT {N_SAMPLES})\"\"\"\n",
    "    ).df()\n",
    "    con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"binds\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -tlhr \"$PATH_DATA/automl-baseline-input/train_dicts/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "papermill": {
     "duration": 0.149572,
     "end_time": "2024-05-02T00:45:31.151945",
     "exception": false,
     "start_time": "2024-05-02T00:45:31.002373",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Assuming your DataFrame is named 'df' with columns 'molecule_smiles', 'protein_name', and 'binds'\n",
    "\n",
    "# Convert SMILES to RDKit molecules\n",
    "\n",
    "\n",
    "# Generate ECFPs\n",
    "def generate_ecfp(molecule, radius=2, bits=1024):\n",
    "    if molecule is None:\n",
    "        return None\n",
    "    return list(AllChem.GetMorganFingerprintAsBitVect(molecule, radius, nBits=bits))\n",
    "\n",
    "\n",
    "# One-hot encode the protein_name\n",
    "with open(f\"{PATH_DATA}/leash-bio-onehot-encoder/protein_name_encoder.pkl\", \"rb\") as f:\n",
    "    onehot_encoder = pickle.load(f)\n",
    "\n",
    "if TRAIN:\n",
    "    df[\"molecule\"] = df[\"molecule_smiles\"].apply(Chem.MolFromSmiles)\n",
    "    df[\"ecfp\"] = df[\"molecule\"].apply(generate_ecfp)\n",
    "    onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "    protein_onehot = onehot_encoder.fit_transform(\n",
    "        df[\"protein_name\"].values.reshape(-1, 1)\n",
    "    )\n",
    "\n",
    "    # Combine ECFPs and one-hot encoded protein_name\n",
    "    X = [\n",
    "        ecfp + protein\n",
    "        for ecfp, protein in zip(df[\"ecfp\"].tolist(), protein_onehot.tolist())\n",
    "    ]\n",
    "\n",
    "    data = pd.DataFrame(np.array(X), columns=[f\"col{i:04d}\" for i in range(len(X[0]))])\n",
    "    data[\"binds\"] = df[\"binds\"]\n",
    "    train, valid = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "    train = TabularDataset(train)\n",
    "    valid = TabularDataset(valid)\n",
    "\n",
    "    del X, data\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "papermill": {
     "duration": 0.016263,
     "end_time": "2024-05-02T00:45:31.174537",
     "exception": false,
     "start_time": "2024-05-02T00:45:31.158274",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    predictor = TabularPredictor(\n",
    "        label=\"binds\",\n",
    "        problem_type=\"binary\",\n",
    "        eval_metric=\"average_precision\",\n",
    "        path=\"predictor\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.014101,
     "end_time": "2024-05-02T00:45:31.194853",
     "exception": false,
     "start_time": "2024-05-02T00:45:31.180752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "if TRAIN:\n",
    "    predictor.fit(\n",
    "        train,\n",
    "        tuning_data=valid,\n",
    "        save_space=True,\n",
    "        presets=\"optimize_for_deployment\",\n",
    "        use_bag_holdout=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "papermill": {
     "duration": 0.566869,
     "end_time": "2024-05-02T00:45:31.767870",
     "exception": false,
     "start_time": "2024-05-02T00:45:31.201001",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_PATH = f\"{PATH_DATA}/predictor_3m\"\n",
    "MODEL_PATH = \"predictor\"\n",
    "predictor = TabularPredictor.load(path=MODEL_PATH, require_version_match=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "papermill": {
     "duration": 0.049829,
     "end_time": "2024-05-02T00:45:31.824622",
     "exception": false,
     "start_time": "2024-05-02T00:45:31.774793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.leaderboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {
    "papermill": {
     "duration": 0.006472,
     "end_time": "2024-05-02T00:45:31.837844",
     "exception": false,
     "start_time": "2024-05-02T00:45:31.831372",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "papermill": {
     "duration": 4583.88366,
     "end_time": "2024-05-02T02:01:55.728267",
     "exception": false,
     "start_time": "2024-05-02T00:45:31.844607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Process the test.parquet file chunk by chunk\n",
    "test_file = f\"{PATH_PROJECT}/test.csv\"\n",
    "output_file = \"submission.csv\"  # Specify the path and filename for the output file\n",
    "\n",
    "# Read the test.parquet file into a pandas DataFrame\n",
    "for seq, df_test in enumerate(tqdm(pd.read_csv(test_file, chunksize=100000))):\n",
    "    print(seq)\n",
    "    # Generate ECFPs for the molecule_smiles\n",
    "    df_test[\"molecule\"] = df_test[\"molecule_smiles\"].apply(Chem.MolFromSmiles)\n",
    "    df_test[\"ecfp\"] = df_test[\"molecule\"].apply(generate_ecfp)\n",
    "\n",
    "    # One-hot encode the protein_name\n",
    "    protein_onehot = onehot_encoder.transform(\n",
    "        df_test[\"protein_name\"].values.reshape(-1, 1)\n",
    "    )\n",
    "\n",
    "    # Combine ECFPs and one-hot encoded protein_name\n",
    "    X_test = [\n",
    "        ecfp + protein\n",
    "        for ecfp, protein in zip(df_test[\"ecfp\"].tolist(), protein_onehot.tolist())\n",
    "    ]\n",
    "    X_test = pd.DataFrame(\n",
    "        np.array(X_test), columns=[f\"col{i:04d}\" for i in range(len(X_test[0]))]\n",
    "    )\n",
    "    X_test = TabularDataset(X_test)\n",
    "\n",
    "    # Predict the probabilities\n",
    "    probabilities = predictor.predict_proba(X_test).iloc[:, 1].values\n",
    "\n",
    "    # Create a DataFrame with 'id' and 'probability' columns\n",
    "    output_df = pd.DataFrame({\"id\": df_test[\"id\"], \"binds\": probabilities})\n",
    "\n",
    "    # Save the output DataFrame to a CSV file\n",
    "    output_df.to_csv(\n",
    "        output_file, index=False, mode=\"a\", header=not os.path.exists(output_file)\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8006601,
     "sourceId": 67356,
     "sourceType": "competition"
    },
    {
     "datasetId": 4921138,
     "sourceId": 8285651,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 171529473,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30673,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4731.757715,
   "end_time": "2024-05-02T02:01:58.565766",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-02T00:43:06.808051",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
