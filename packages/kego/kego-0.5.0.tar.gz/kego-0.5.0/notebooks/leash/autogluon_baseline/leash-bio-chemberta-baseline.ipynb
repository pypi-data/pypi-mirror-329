{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update\n",
    "|version|update|cv|lb|\n",
    "|:--|:--|--:|--:|\n",
    "|v3|-|-|0.343|\n",
    "|v4|increase N_ROWS from 90M to 180M|0.573|0.465|\n",
    "|v5|increase N_SAMPLES from 1M to 2M<br>change to a larger model (5M -> 10M)|0.622|0.486|\n",
    "|v8|Add normalization commented by [@hengck23](https://www.kaggle.com/hengck23)|0.629|0.496|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# !pip install rdkit\n",
    "# !pip install -U /kaggle/input/lightning-2-2-1/lightning-2.2.1-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchmetrics import AveragePrecision\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import (\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    TQDMProgressBar,\n",
    ")\n",
    "from transformers import AutoConfig, AutoTokenizer, AutoModel, DataCollatorWithPadding\n",
    "import datasets\n",
    "from rdkit import Chem\n",
    "\n",
    "\n",
    "import os\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_PROJECT = pathlib.Path(\"/mnt/d/Data/kaggle/leash/leash-BELKA/\")\n",
    "print(os.listdir(PATH_PROJECT))\n",
    "PATH_TRAIN = PATH_PROJECT / \"train.csv\"\n",
    "PATH_SUBMISSION_EXAMPLE = PATH_PROJECT / \"sample_submission.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = True\n",
    "NORMALIZE = True\n",
    "# N_ROWS = 180_000_000\n",
    "N_ROWS = 120_000\n",
    "assert N_ROWS is None or N_ROWS % 3 == 0\n",
    "if DEBUG:\n",
    "    N_SAMPLES = 10_000\n",
    "else:\n",
    "    N_SAMPLES = 2_000_000\n",
    "PROTEIN_NAMES = [\"BRD4\", \"HSA\", \"sEH\"]\n",
    "data_dir = PATH_PROJECT\n",
    "model_name = \"DeepChem/ChemBERTa-10M-MTR\"\n",
    "batch_size = 256\n",
    "trainer_params = {\n",
    "    \"max_epochs\": 5,\n",
    "    \"enable_progress_bar\": True,\n",
    "    \"accelerator\": \"auto\",\n",
    "    \"precision\": \"16-mixed\",\n",
    "    \"gradient_clip_val\": None,\n",
    "    \"accumulate_grad_batches\": 1,\n",
    "    \"devices\": [0],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_parquet(\n",
    "    Path(data_dir, \"train.parquet\"),\n",
    "    columns=[\"molecule_smiles\", \"protein_name\", \"binds\"],\n",
    "    n_rows=N_ROWS,\n",
    ")\n",
    "test_df = pl.read_parquet(\n",
    "    Path(data_dir, \"test.parquet\"),\n",
    "    columns=[\"molecule_smiles\"],\n",
    "    n_rows=10000 if DEBUG else None,\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for i, protein_name in enumerate(PROTEIN_NAMES):\n",
    "    sub_df = df[i::3]\n",
    "    sub_df = sub_df.rename({\"binds\": protein_name})\n",
    "    if i == 0:\n",
    "        dfs.append(sub_df.drop([\"id\", \"protein_name\"]))\n",
    "    else:\n",
    "        dfs.append(sub_df[[protein_name]])\n",
    "df = pl.concat(dfs, how=\"horizontal\")\n",
    "df = df.sample(n=N_SAMPLES)\n",
    "print(df.head())\n",
    "print(df[PROTEIN_NAMES].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    mol = Chem.MolFromSmiles(x)\n",
    "    smiles = Chem.MolToSmiles(mol, canonical=True, isomericSmiles=False)\n",
    "    return smiles\n",
    "\n",
    "\n",
    "if NORMALIZE:\n",
    "    df = df.with_columns(\n",
    "        pl.col(\"molecule_smiles\").map_elements(normalize, return_dtype=pl.Utf8)\n",
    "    )\n",
    "    test_df = test_df.with_columns(\n",
    "        pl.col(\"molecule_smiles\").map_elements(normalize, return_dtype=pl.Utf8)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, val_idx = train_test_split(np.arange(len(df)), test_size=0.2)\n",
    "train_df, val_df = df[train_idx], df[val_idx]\n",
    "len(train_df), len(val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch, tokenizer):\n",
    "    output = tokenizer(batch[\"molecule_smiles\"], truncation=True)\n",
    "    return output\n",
    "\n",
    "\n",
    "class LMDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, stage=\"train\"):\n",
    "        assert stage in [\"train\", \"val\", \"test\"]\n",
    "        self.tokenizer = tokenizer\n",
    "        self.stage = stage\n",
    "        df = (\n",
    "            datasets.Dataset.from_pandas(df.to_pandas())\n",
    "            .map(tokenize, batched=True, fn_kwargs={\"tokenizer\": self.tokenizer})\n",
    "            .to_pandas()\n",
    "        )\n",
    "        self.df = pl.from_pandas(df)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = self._generate_data(index)\n",
    "        data[\"label\"] = self._generate_label(index)\n",
    "        return data\n",
    "\n",
    "    def _generate_data(self, index):\n",
    "        data = {\n",
    "            \"input_ids\": np.array(self.df[index, \"input_ids\"]),\n",
    "            \"attention_mask\": np.array(self.df[index, \"attention_mask\"]),\n",
    "        }\n",
    "        return data\n",
    "\n",
    "    def _generate_label(self, index):\n",
    "        if self.stage == \"test\":\n",
    "            return np.array([0, 0, 0])\n",
    "        else:\n",
    "            return self.df[index, PROTEIN_NAMES].to_numpy()[0]\n",
    "\n",
    "\n",
    "LMDataset(train_df[:100], tokenizer)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LBDataModule(L.LightningDataModule):\n",
    "    def __init__(self, train_df, val_df, test_df, tokenizer):\n",
    "        super().__init__()\n",
    "        self.train_df = train_df\n",
    "        self.val_df = val_df\n",
    "        self.test_df = test_df\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def _generate_dataset(self, stage):\n",
    "        if stage == \"train\":\n",
    "            df = self.train_df\n",
    "        elif stage == \"val\":\n",
    "            df = self.val_df\n",
    "        elif stage == \"test\":\n",
    "            df = self.test_df\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        dataset = LMDataset(df, self.tokenizer, stage=stage)\n",
    "        return dataset\n",
    "\n",
    "    def _generate_dataloader(self, stage):\n",
    "        dataset = self._generate_dataset(stage)\n",
    "        if stage == \"train\":\n",
    "            shuffle = True\n",
    "            drop_last = True\n",
    "        else:\n",
    "            shuffle = False\n",
    "            drop_last = False\n",
    "        return DataLoader(\n",
    "            dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle,\n",
    "            drop_last=drop_last,\n",
    "            pin_memory=True,\n",
    "            collate_fn=DataCollatorWithPadding(self.tokenizer),\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self._generate_dataloader(\"train\")\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self._generate_dataloader(\"val\")\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self._generate_dataloader(\"test\")\n",
    "\n",
    "\n",
    "datamodule = LBDataModule(train_df, val_df, test_df, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMModel(nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super().__init__()\n",
    "        self.config = AutoConfig.from_pretrained(model_name, num_labels=3)\n",
    "        self.lm = AutoModel.from_pretrained(model_name, add_pooling_layer=False)\n",
    "        self.dropout = nn.Dropout(self.config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(self.config.hidden_size, self.config.num_labels)\n",
    "        self.loss_fn = nn.BCEWithLogitsLoss(reduction=\"mean\")\n",
    "\n",
    "    def forward(self, batch):\n",
    "        last_hidden_state = self.lm(\n",
    "            batch[\"input_ids\"],\n",
    "            attention_mask=batch[\"attention_mask\"],\n",
    "        ).last_hidden_state\n",
    "        logits = self.classifier(self.dropout(last_hidden_state[:, 0]))\n",
    "        return {\n",
    "            \"logits\": logits,\n",
    "        }\n",
    "\n",
    "    def calculate_loss(self, batch):\n",
    "        output = self.forward(batch)\n",
    "        loss = self.loss_fn(output[\"logits\"], batch[\"labels\"].float())\n",
    "        output[\"loss\"] = loss\n",
    "        return output\n",
    "\n",
    "\n",
    "LMModel(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LBModelModule(L.LightningModule):\n",
    "    def __init__(self, model_name):\n",
    "        super().__init__()\n",
    "        self.model = LMModel(model_name)\n",
    "        self.map = AveragePrecision(task=\"binary\")\n",
    "\n",
    "    def forward(self, batch):\n",
    "        return self.model(batch)\n",
    "\n",
    "    def calculate_loss(self, batch, batch_idx):\n",
    "        return self.model.calculate_loss(batch)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        ret = self.calculate_loss(batch, batch_idx)\n",
    "        self.log(\n",
    "            \"train_loss\",\n",
    "            ret[\"loss\"],\n",
    "            on_step=True,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "            sync_dist=True,\n",
    "        )\n",
    "        return ret[\"loss\"]\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        ret = self.calculate_loss(batch, batch_idx)\n",
    "        self.log(\n",
    "            \"val_loss\",\n",
    "            ret[\"loss\"],\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "            sync_dist=True,\n",
    "        )\n",
    "        self.map.update(F.sigmoid(ret[\"logits\"]), batch[\"labels\"].long())\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        val_map = self.map.compute()\n",
    "        self.log(\n",
    "            \"val_map\",\n",
    "            val_map,\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "            sync_dist=True,\n",
    "        )\n",
    "        self.map.reset()\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        logits = self.forward(batch)[\"logits\"]\n",
    "        probs = F.sigmoid(logits)\n",
    "        return probs\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.0001)\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "        }\n",
    "\n",
    "\n",
    "modelmodule = LBModelModule(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filename=f\"model-{{val_map:.4f}}\",\n",
    "    save_weights_only=True,\n",
    "    monitor=\"val_map\",\n",
    "    mode=\"max\",\n",
    "    dirpath=\"/kaggle/working\",\n",
    "    save_top_k=1,\n",
    "    verbose=1,\n",
    ")\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_map\", mode=\"max\", patience=3)\n",
    "progress_bar_callback = TQDMProgressBar(refresh_rate=1)\n",
    "callbacks = [\n",
    "    checkpoint_callback,\n",
    "    early_stop_callback,\n",
    "    progress_bar_callback,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = L.Trainer(callbacks=callbacks, **trainer_params)\n",
    "trainer.fit(modelmodule, datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pl.read_parquet(\n",
    "    Path(data_dir, \"test.parquet\"),\n",
    "    columns=[\"molecule_smiles\"],\n",
    "    n_rows=10000 if DEBUG else None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = Path(\"/kaggle/working\")\n",
    "model_paths = working_dir.glob(\"*.ckpt\")\n",
    "test_dataloader = datamodule.test_dataloader()\n",
    "for model_path in model_paths:\n",
    "    print(model_path)\n",
    "    modelmodule = LBModelModule.load_from_checkpoint(\n",
    "        checkpoint_path=model_path,\n",
    "        model_name=model_name,\n",
    "    )\n",
    "    predictions = trainer.predict(modelmodule, test_dataloader)\n",
    "    predictions = torch.cat(predictions).numpy()\n",
    "    pred_dfs = []\n",
    "    for i, protein_name in enumerate(PROTEIN_NAMES):\n",
    "        pred_dfs.append(\n",
    "            test_df.with_columns(\n",
    "                pl.lit(protein_name).alias(\"protein_name\"),\n",
    "                pl.lit(predictions[:, i]).alias(\"binds\"),\n",
    "            )\n",
    "        )\n",
    "    pred_df = pl.concat(pred_dfs)\n",
    "    submit_df = (\n",
    "        pl.read_parquet(\n",
    "            Path(data_dir, \"test.parquet\"),\n",
    "            columns=[\"id\", \"molecule_smiles\", \"protein_name\"],\n",
    "        )\n",
    "        .join(pred_df, on=[\"molecule_smiles\", \"protein_name\"], how=\"left\")\n",
    "        .select([\"id\", \"binds\"])\n",
    "        .sort(\"id\")\n",
    "    )\n",
    "    submit_df.write_csv(Path(working_dir, f\"submission_{model_path.stem}.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_files = list(working_dir.glob(\"submission_*.csv\"))\n",
    "sub_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_dfs = []\n",
    "for sub_file in sub_files:\n",
    "    sub_dfs.append(pl.read_csv(sub_file))\n",
    "submit_df = pl.concat(sub_dfs).group_by(\"id\").agg(pl.col(\"binds\").mean()).sort(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -fr *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df.write_csv(Path(working_dir, \"submission.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Directions\n",
    "- Finding the optimal CV strategy\n",
    "- Increase data\n",
    "- Utilize buildingblock1 ~ buildingblock3\n",
    "- Large-scale models\n",
    "- Tune hyper-parameters\n",
    "- Ensemble\n",
    "- etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8006601,
     "sourceId": 67356,
     "sourceType": "competition"
    },
    {
     "datasetId": 4608382,
     "sourceId": 7856946,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
