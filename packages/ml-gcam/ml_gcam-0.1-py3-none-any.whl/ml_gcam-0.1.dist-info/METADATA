Metadata-Version: 2.1
Name: ml-gcam
Version: 0.1
Home-page: https://github.com/hutchresearch/ml_climate_gcam22/tree/pnnl_published
Author: matt jensen
Author-email: brian.hutchinson@wwu.edu
License: Apache-2.0
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3.10
Classifier: Operating System :: OS Independent
Requires-Python: >=3.10
Description-Content-Type: text/markdown
Requires-Dist: torch
Requires-Dist: pytorch-cuda (==12.1)
Requires-Dist: einops
Requires-Dist: accelerate
Requires-Dist: torchtyping
Requires-Dist: scikit-learn
Requires-Dist: seaborn
Requires-Dist: tensorboard
Requires-Dist: wandb
Requires-Dist: polars (>=0.20.19)
Requires-Dist: pandas
Requires-Dist: pyarrow
Requires-Dist: marimo
Requires-Dist: gcamreader (>=1.4.0)
Requires-Dist: pytest
Requires-Dist: pytest-cov
Requires-Dist: click
Requires-Dist: rich
Requires-Dist: tqdm
Requires-Dist: python-dotenv
Requires-Dist: python-configuration[toml]
Requires-Dist: lxml
Requires-Dist: geopandas (>=0.9.0)
Provides-Extra: test
Requires-Dist: pytest ; extra == 'test'

# GCAM Machine Learning Emulator

This repo contains an implemention of a flexible, machine learning-based Global Change Analysis Model (GCAM) emulator.

[Project Home](https://github.com/hutchresearch/ml_climate_gcam22)

## Project Scope

- Develop and train neural-network on data derived from experiments defined in [Woodward (2023)](https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2022EF003442) (commonly references as "exp 1 jr.").
- Compare and contrast the performance of the emulator and the 'core' GCAM model performance.
- Compare and contract the sensitivity of the emulator and the 'core' GCAM model performance.
- Experiment with the sensitivity of emulator performance as a function of the amount of training data.
- Use emulator outputs and different world futures to explore the range of possible scenarios.

## People

**Researchers**

- Brian Hutchinson [email](mailto:Brian.Hutchinson@wwu.edu)
- Abigail Snyder [email](mailto:abigail.snyder@pnnl.gov)
- Claudia Tebaldi [email](mailto:claudia.tebaldi@pnnl.gov)

**Students**

- Matt Jensen
- Hidemi Mitani Shen
- Andrew Holmes
- Sarah Coffland
- Logan Sizemore
- Brenn Nieva
- Seth Bassetti

**Water Scarcity Modeling**

- Jonathan Lamontagne [email](mailto:jonathan.lamontagne@tufts.edu)
- Flannery Dolan [email](mailto:flannery.dolan@tufts.edu)
- Dawn Woodard [email](mailto:dawn.woodard@pnnl.gov)

## GCAM Background

- [GCAM core repo](https://github.com/JGCRI/gcam-core)
- [GCAM build process](http://jgcri.github.io/gcam-doc/gcam-build.html)
- [GCAMDATA build process](https://jgcri.github.io/gcamdata/articles/getting-started/getting-started.html)
- [GCAM background paper](https://gmd.copernicus.org/articles/12/677/2019/gmd-12-677-2019.pdf)
- [GCAM post processing](https://github.com/JGCRI/gcamreader/)
- [GACM video - intro](https://www.youtube.com/watch?v=xRF9lFwtMr0)
- [GACM video - tutorial](https://www.youtube.com/watch?v=S7vAShH-dbs)

## Setup


### Conda Environment

To set up your environment using Conda, follow these steps:

- First, ensure you have [Conda](https://docs.anaconda.com/free/miniconda/) installed on your system.
- Clone the repository to your local machine:

```
git clone https://github.com/JGCRI/gcam-emulator.git
cd gcam-emulator
```

- Create a Conda environment using the environment.yml file provided in the repository:

```
conda env create -f environment.yml
# or with the Makefile:
# make conda_update
```

- Activate the newly created environment:

```
conda activate ml_climate_gcam22
```

### Virtualenv Environment

To set up your environment using venv, follow these steps:

- Clone the repository to your local machine:

```
git clone https://github.com/JGCRI/gcam-emulator.git
cd gcam-emulator
```

- Create a virtualenv environment using `venv` and the requirements.txt file provided in the repository:

```
# install virtualenv
python3 -m venv .venv

# load the python environment
source .venv/bin/activate
pip install -r requirements.txt
python3 -m ml_gcam --help

# or reference it directly
.venv/bin/pip install -r requirements.txt
.venv/bin/python3 -m ml_gcam --help

```

- After activating the environment, you can proceed with the rest of the setup.

### Configuration

Configuration variables can be set one of three ways via the package [python-configuration](https://github.com/tr11/python-configuration) and are used to in the config module to modify behaviors of the entire training and running process:

1. via the system environment

```
# prefix the key with 'ML_GCAM', then separate each nesting with two underscores:

os.environ['ML_GCAM__MODEL__HIDDEN_SIZE'] = 16
config.reload()
assert config.model.hidden_size == 16

```

2. via the `.env` file in the project directory root

copy .env.example and change default values to match your preferences and system:

```cp .env.example .env```


3. via .toml files in `ml_gcam/config` directory


Once modified, the can be accessed via the `config` object in `ml_gcam.__init__.py`:

```
# from ml_gcam/training/train.py:
from ml_gcam import config

...

emulator = ANN(
    in_size=len(config.data.input_keys),
    hidden_size=int(config.model.hidden_size),
    depth=int(config.model.depth),
    n_heads=n_heads,
    n_features=len(config.data.output_keys),
)

```

### Wandb

We use weights and biases for logging. To use it, you will need to make an account: https://wandb.ai/site

Then set the appropriate config variables:

```
# .env:

WANDB_API_KEY="[replace with api key]"
ML_GCAM__WANDB__ENTITY="wandb username/entity"
ML_GCAM__WANDB__TAGS="test,perfect"
ML_GCAM__WANDB__GROUP="dd_mm_name_is_good"

```


## Dataset Generation

### Sources

| Sampling   | Range        |   Training Scenarios |   Validation Scenarios |   Test Scenarios | New GCAM Samples?   |
|:-----------|:-------------|---------------------:|-----------------------:|-----------------:|:--------------------|
| Sobol      | x \in [0, 1] |                    0 |                   2047 |                0 | Yes                 |
| Binary     | x \in {0, 1} |                 3268 |                    409 |              409 | Yes                 |
| Hypercube  | x \in [0, 1] |                 3265 |                    408 |              408 | Yes                 |
| Random     | x \in [0, 1] |                 3277 |                    409 |              410 | Yes                 |

### Inputs

| Input           | Description                                                    | Key    | Interpolated?   |
|:----------------|:---------------------------------------------------------------|:-------|:----------------|
| Backups         | Systems needed to backup solar and wind                        | back   | Yes             |
| Bioenergy       | Tax applied to bioenergy                                       | bio    | No              |
| Carbon Capture  | Cost to store CO2                                              | ccs    | Yes             |
| Electrification | Share of buildings, industries and transport using electricity | elec   | No              |
| Emissions       | CO2 emssions                                                   | emiss  | No              |
| Energy          | Demand - GDP and population assumptions                        | energy | Yes             |
| Fossil Fuel     | Costs of oil, natural gas and coal                             | ff     | Yes             |
| Nuclear         | Cost of nuclear energy                                         | nuc    | Yes             |
| Solar Storage   | Solar storage capacity                                         | solarS | Yes             |
| Solar Tech      | Cost to install and use solar                                  | solarT | Yes             |
| Wind Storage    | Wind storage capacity                                          | windS  | Yes             |
| Wind Tech       | Cost to install and use wind                                   | windT  | Yes             |

### Outputs

| Resource   | Metric             | Sector      | Units        | Query                                       |
|:-----------|:-------------------|:------------|:-------------|:--------------------------------------------|
| energy     | demand_elecricity  | building    | EJ           | elec_consumption_by_demand_sector           |
| energy     | demand_elecricity  | industry    | EJ           | elec_consumption_by_demand_sector           |
| energy     | demand_elecricity  | transport   | EJ           | elec_consumption_by_demand_sector           |
| energy     | demand_fuel        | building    | EJ           | final_energy_consumption_by_sector_and_fuel |
| energy     | demand_fuel        | building    | EJ           | final_energy_consumption_by_sector_and_fuel |
| energy     | demand_fuel        | hydrogen    | EJ           | final_energy_consumption_by_sector_and_fuel |
| energy     | demand_fuel        | industry    | EJ           | final_energy_consumption_by_sector_and_fuel |
| energy     | demand_fuel        | industry    | EJ           | final_energy_consumption_by_sector_and_fuel |
| energy     | demand_fuel        | transport   | EJ           | final_energy_consumption_by_sector_and_fuel |
| energy     | price              | coal        | 1975$/GJ     | final_energy_prices                         |
| energy     | price              | electricity | 1975$/GJ     | final_energy_prices                         |
| energy     | price              | transport   | 1975$/GJ     | final_energy_prices                         |
| energy     | price              | transport   | 1975$/GJ     | final_energy_prices                         |
| energy     | supply_electricity | biomass     | EJ           | elec_gen_by_subsector                       |
| energy     | supply_electricity | coal        | EJ           | elec_gen_by_subsector                       |
| energy     | supply_electricity | gas         | EJ           | elec_gen_by_subsector                       |
| energy     | supply_electricity | nuclear     | EJ           | elec_gen_by_subsector                       |
| energy     | supply_electricity | oil         | EJ           | elec_gen_by_subsector                       |
| energy     | supply_electricity | other       | EJ           | elec_gen_by_subsector                       |
| energy     | supply_electricity | solar       | EJ           | elec_gen_by_subsector                       |
| energy     | supply_electricity | wind        | EJ           | elec_gen_by_subsector                       |
| energy     | supply_primary     | biomass     | EJ           | primary_energy_consumption_by_region        |
| energy     | supply_primary     | coal        | EJ           | primary_energy_consumption_by_region        |
| energy     | supply_primary     | gas         | EJ           | primary_energy_consumption_by_region        |
| energy     | supply_primary     | nuclear     | EJ           | primary_energy_consumption_by_region        |
| energy     | supply_primary     | oil         | EJ           | primary_energy_consumption_by_region        |
| energy     | supply_primary     | other       | EJ           | primary_energy_consumption_by_region        |
| energy     | supply_primary     | solar       | EJ           | primary_energy_consumption_by_region        |
| energy     | supply_primary     | wind        | EJ           | primary_energy_consumption_by_region        |
| land       | allocation         | biomass     | thousand km2 | aggregated_land_allocation                  |
| land       | allocation         | forest      | thousand km2 | aggregated_land_allocation                  |
| land       | allocation         | grass       | thousand km2 | aggregated_land_allocation                  |
| land       | allocation         | other       | thousand km2 | aggregated_land_allocation                  |
| land       | allocation         | pasture     | thousand km2 | aggregated_land_allocation                  |
| land       | demand             | feed        | Mt           | demand_balances_by_crop_commodity           |
| land       | demand             | food        | Mt           | demand_balances_by_crop_commodity           |
| land       | price              | biomass     | 1975$/GJ     | prices_by_sector                            |
| land       | price              | forest      | 1975$/m3     | prices_by_sector                            |
| land       | production         | biomass     | EJ           | ag_production_by_crop_type                  |
| land       | production         | forest      | billion m3   | ag_production_by_crop_type                  |
| land       | production         | grass       | Mt           | ag_production_by_crop_type                  |
| land       | production         | other       | Mt           | ag_production_by_crop_type                  |
| land       | production         | pasture     | Mt           | ag_production_by_crop_type                  |
| water      | demand             | crops       | km3          | water_withdrawls_by_tech                    |
| water      | demand             | electricity | km3          | water_withdrawls_by_tech                    |

To generate the raw data used in the supervised learning task, runs of [GCAM core](https://github.com/JGCRI/gcam-core) with the specific set of configurations outlined in [Woodward (2023)](https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2022EF003442) are required.
In this study, GCAM core was run 2^12 times, one for each permutation of the 12 input variables.
Reference configuration files are provided in the `ml_gcam/core/configs/*.xml` files.
This process will generate a set of basex files, one for each configuration.

### Interpolation

To complete the interpolation study, these configuration files need to be modified.
Scripts for doing so are available:

```
> python -m ml_gcam --help | grep interpolate
core-interpolate:make-configs  create configs from set of interpolated...
core-interpolate:make-inputs   create paths containing interpolated inputs
core-interpolate:sample        creates a metadata.csv with [--sample]...
```

### Extraction

GCAM core outputs, in the form of basex files, can be extracted to .csv using either the [ModelInterface](https://github.com/JGCRI/modelinterface/) tool, or the python [gcamreader](https://github.com/JGCRI/gcamreader/) package.
Both tools rely on query .xml files to define the data to extract from the basex files.
Reference query files are available in the `ml_gcam/core/queries/*.xml` files.
A typical run to extract a query using `gcamreader` looks something like this:

```
> python3 -m gcamreader local --help
Usage: python -m gcamreader local [OPTIONS]

  query gcam scenario databases

Options:
  -d, --database_path DIRECTORY  path to database file (i.e. parent of *.basex
                                 dir)  [required]
  -q, --query_path FILE          path to xml with queries to run (i.e:
                                 Main_queries.xml)  [required]
  -o, --output_path DIRECTORY    path to output (i.e. where .csv files should
                                 be created)
  -f, --force BOOLEAN            overwrite existing .csv in output path
  --help                         Show this message and exit.

> python3 -m gcamreader local \
 --query_path ml_gcam/core/queries/Main_queries.xml \
 --database_path /path/to/.basex/parent \
 --outpub_path data/query_outputs

...
```

Once extracted, individual queries are aggregated to generate the targets for the emulator.
A scripts for going so are available:
```
> python -m ml_gcam data:create-extracts --help
Usage: python -m ml_gcam data:create-extracts [OPTIONS]

  aggregated raw extract csv from all experiments via sql templates

Options:
  -e, --experiment [dawn_exp1_jr|interp_random|interp_hypercube|interp_sobol|wwu_exp1_jr]
  -q, --queries [agriculture_prices|electricity_supply|emissions_capture|energy_demand_share_electricity|energy_demand_share_primary|energy_prices|energy_supply_share_electricity|energy_supply_share_primary|land_demand|land_prices|land_supply_allocation|land_supply_production|water_demand|water_consumption]
  -g, --gcamreader-outputs DIRECTORY
                                  directory with the .csv outputs from
                                  gcamreader  [required]
  --save_path DIRECTORY           directory to save {experiment}.csv outputs
                                  (/path/to/data/targets/)
  -f, --force
  --pretend / --no-pretend
  --help                          Show this message and exit.
```

To turn these extracts into an aggregated version for training, run the following command:

```
> python3 -m ml_gcam data:create-targets --help
Usage: python -m ml_gcam data:create-targets [OPTIONS]

  create meta.scenarios table

Options:
  -e, --experiment [dawn_exp1_jr|interp_random|interp_hypercube|interp_sobol|wwu_exp1_jr]
  --targets_path DIRECTORY        /path/to/targets/
  --scenarios_path FILE           path to scenarios.csv
  -s, --save_path FILE            /path/to/targets/targets.parquet (output
                                  partitioned by experiment and split)
  -f, --force
  --help                          Show this message and exit.
```

This will create a [parquet](https://parquet.apache.org/) file named `targets.parquet` that is used by all downstream tasks for training and validation.

## Training

To train the emulator
Our project uses a command-line interface (CLI) to manage various training loops for machine learning models using PyTorch and Weights & Biases (wandb). Below, you'll find detailed instructions on how to use each command in the training module.

### General Usage

All training loop commands are executed as a module argument to Python and require specific options depending on the task:

`python -m ml_gcam <command> [OPTIONS]`

Commands Overview

- `training:run`: Main training loop.
- `training:sample-size`: Training loop for experimenting with different sample sizes.
- `training:cartesian`: Training loop for experimenting with combination of different sampling strategies.
- `training:sweep-init`: Initial setup for hyperparameter sweeps.
- `training:sweep-run`: Execution of hyperparameter sweeps.

### Example Command
```bash
python -m ml_gcam --no-wandb training:run \
  --targets_path /path/to/targets.parquet \
  --train_source dawn_exp1_jr \
  --dev_source dawn_exp1_jr \
  --checkpoint_path /path/to/checkpoint
```

### Command Help

```bash
> python -m ml_gcam training:run --help
Usage: python -m ml_gcam training:run [OPTIONS]

  main training loop

Options:
  -n, --normalization-strategy [z_score|min_max|robust]
                                  how to handle normalization of target before
                                  training  [required]
  -c, --checkpoint_path FILE      /path/to/model/checkpoint/name/
  -d, --dev_source [mixed|dawn_exp1_jr|interp_random|interp_hypercube|interp_sobol|wwu_exp1_jr]
                                  name of experiment(s) to use as dev_source
                                  [default: interp_sobol; required]
  -t, --train_source [mixed|dawn_exp1_jr|interp_random|interp_hypercube|wwu_exp1_jr]
                                  name of experiment(s) to use as train_source
                                  [default: dawn_exp1_jr; required]
  --targets_path FILE             /path/to/targets.parquet  [default: /path/to
                                  /targets.parquet; required]
  --help                          Show this message and exit.
```

```bash
> python -m ml_gcam training:sample-size --help
Usage: python -m ml_gcam training:sample-size [OPTIONS]

  training loop for sample size experiments

Options:
  --targets_path FILE             /path/to/targets.parquet  [default: /path/to
                                  /targets.parquet; required]
  -t, --train_source [mixed|dawn_exp1_jr|interp_random|interp_hypercube|wwu_exp1_jr]
                                  name of experiment(s) to use as train_source
                                  [default: dawn_exp1_jr; required]
  -d, --dev_source [mixed|dawn_exp1_jr|interp_random|interp_hypercube|interp_sobol|wwu_exp1_jr]
                                  name of experiment(s) to use as dev_source
                                  [default: interp_sobol; required]
  -c, --checkpoint_path DIRECTORY
                                  /path/to/model/checkpoint/name/
  -s, --splits FLOAT              samples to use for training, in percent of
                                  train_set  [default: 0.01, 0.02, 0.05,
                                  0.075, 0.1, 0.15, 0.2, 0.3, 0.5, 0.6, 0.65,
                                  0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0;
                                  required]
  --help                          Show this message and exit.
```

```bash
> python -m ml_gcam training:cartesian --help
Usage: python -m ml_gcam training:cartesian [OPTIONS]

  configure a wandb hyperparameter sweep and make a sweep id

Options:
  --targets_path FILE             /path/to/targets.parquet  [default: /path/to
                                  /targets.parquet; required]
  -t, --train_source [mixed|dawn_exp1_jr|interp_random|interp_hypercube|wwu_exp1_jr]
                                  name of experiment(s) to use as train_source
                                  [default: mixed, dawn_exp1_jr,
                                  interp_random, interp_hypercube,
                                  wwu_exp1_jr; required]
  -d, --dev_source [mixed|dawn_exp1_jr|interp_random|interp_hypercube|interp_sobol|wwu_exp1_jr]
                                  name of experiment(s) to use as dev_source
                                  [default: mixed, dawn_exp1_jr,
                                  interp_random, interp_hypercube,
                                  interp_sobol, wwu_exp1_jr; required]
  -c, --checkpoint_path DIRECTORY
                                  /path/to/model/checkpoint/name/
  --help                          Show this message and exit.
```

## Evaluation

We picked r2 scores as the more important evaluation metric for these experiment.
During training, some aggregate statistics are logged to the console and to wandb if enabled.
To generate these metrics from a saved model checkpoint, use the following commands:

```bash
Usage: python -m ml_gcam evaluate:sample-size [OPTIONS]

  load and create r2 scores for training size sweep

Options:
  -c, --checkpoint_path DIRECTORY
                                  /path/to/model/checkpoints/for-sample-size-sweep/
                                  [required]
  -t, --train_source [mixed|dawn_exp1_jr|interp_random|interp_hypercube]
                                  [required]
  -o, --save_path FILE            path to save score.csv  [required]
  -f, --force                     forces the --save_path to overwrite existing
                                  data
  --targets_path FILE             /path/to/targets.parquet  [default: /path/to
                                  /targets.parquet; required]
  --help                          Show this message and exit.
```

```bash
> python -m ml_gcam evaluate:cartesian --help
Usage: python -m ml_gcam evaluate:cartesian [OPTIONS]

  load and create r2 scores for cartesian sweep

Options:
  -c, --checkpoint_path DIRECTORY
                                  /path/to/model/checkpoints/for-cartesian-sweep/
                                  [required]
  -o, --save_path FILE            path to save score.csv  [required]
  -f, --force                     forces the --save_path to overwrite existing
                                  data
  --targets_path FILE             /path/to/targets.parquet  [default:
                                  /path/to/targets.parquet; required]
  --help                          Show this message and exit.``

```
## Plots and Tables

```bash
> python -m ml_gcam plot:cartesian --help
Usage: python -m ml_gcam plot:cartesian [OPTIONS]

  plot the cartesian product of training x dev sets

Options:
  -f, --force                     forces the --save_path to overwrite existing
                                  data
  -o, --save_path FILE            path to save figure.png  [required]
  -a, --aggregation [median|mean|above_0_9|above_0_95|overall]
  -s, --score_path FILE           /path/to/cartesian/r2_scores.csv  [required]
  --help                          Show this message and exit.
```

```bash
> python -m ml_gcam plot:sample-size --help
Usage: python -m ml_gcam plot:sample-size [OPTIONS]

  plot r2 vs. training size from previously generated data

Options:
  -f, --force                     forces the --save_path to overwrite existing
                                  data
  -o, --save_path FILE            path to save figure.png  [required]
  -a, --aggregation [median|mean|above_0_9|above_0_95|overall]
  -s, --score_path FILE           /path/to//sample-size/scores.csv  [required]
  --help                          Show this message and exit.
```

## Results

### Sample Size Experiment

|   Samples |   R2 > 0.9 |   R2 > 0.95 |   Median R2 |   Mean R2 |
|----------:|-----------:|------------:|------------:|----------:|
|        32 |   0.2008   |   0.0336    |    0.7859   |  0.7035   |
|        65 |   0.3674   |   0.1519    |    0.8685   |  0.8190   |
|       163 |   0.6490   |   0.3501    |    0.9273   |  0.8845   |
|       244 |   0.6347   |   0.3451    |    0.9264   |  0.8835   |
|       326 |   0.8769   |   0.6871    |    0.9692   |  0.9373   |
|       489 |   0.9135   |   0.7478    |    0.9778   |  0.9481   |
|       652 |   0.9634   |   0.8775    |    0.9865   |  0.9634   |
|       978 |   0.9740   |   0.9235    |    0.9899   |  0.9691   |
|      1630 |   0.9838   |   0.9692    |    0.9949   |  0.9736   |
|      1956 |   0.9848   |   0.9739    |    0.9956   |  0.9745   |
|      2119 |   0.9847   |   0.9766    |    0.9957   |  0.9753   |
|      2282 |   0.9848   |   0.9745    |    0.9959   |  0.9752   |
|      2445 |   0.9852   |   0.9789    |    0.9963   |  0.9757   |
|      2608 |   0.9854   |   0.9789    |    0.9967   |  0.9760   |
|      2771 |   0.9855   |   0.9790    |    0.9968   |  0.9772   |
|      2934 |   0.9855   |   0.9790    |    0.9968   |  0.9763   |
|      3097 |   0.9855   |   0.9802    |    0.9968   |  0.9766   |
|      3260 |   0.9859   |   0.9816    |    0.9970   |  0.9760   |

### Cartesian Experiment


| train     | test      |    region |      year |   quantity |   overall |
|:----------|:----------|----------:|----------:|-----------:|----------:|
| binary    | binary    |  0.9971   |  0.9970   |   0.9967   |  0.9971   |
| binary    | hypercube | -0.5469   | -0.5577   |  -0.5695   | -0.5643   |
| binary    | random    | -0.4784   | -0.4920   |  -0.4645   | -0.4933   |
| binary    | sobol     | -0.5380   | -0.5478   |  -0.5129   | -0.5452   |
| binary    | mixed     |  0.4368   |  0.4665   |   0.4214   |  0.4359   |
| hypercube | binary    |  0.1964   |  0.2302   |   0.1721   |  0.1771   |
| hypercube | hypercube |  0.9966   |  0.9965   |   0.9967   |  0.9966   |
| hypercube | random    |  0.9955   |  0.9953   |   0.9953   |  0.9954   |
| hypercube | sobol     |  0.9977   |  0.9979   |   0.9977   |  0.9976   |
| hypercube | mixed     |  0.2281   |  0.2542   |   0.1763   |  0.2298   |
| random    | binary    |  0.1967   |  0.2295   |   0.1533   |  0.1749   |
| random    | hypercube |  0.9971   |  0.9970   |   0.9969   |  0.9970   |
| random    | random    |  0.9954   |  0.9953   |   0.9951   |  0.9952   |
| random    | sobol     |  0.9975   |  0.9976   |   0.9976   |  0.9973   |
| random    | mixed     |  0.2230   |  0.2540   |   0.1756   |  0.2229   |
| mixed     | binary    |  0.8531   |  0.8681   |   0.8574   |  0.8560   |
| mixed     | hypercube | -1.3173   | -1.3482   |  -1.4658   | -1.2666   |
| mixed     | random    | -1.4405   | -1.5286   |  -1.4627   | -1.4196   |
| mixed     | mixed     |  0.9844   |  0.9848   |   0.9853   |  0.9847   |
